<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>13.1 Meta-analysis | An Introduction to Bayesian Data Analysis for Cognitive Science</title>
  <meta name="description" content="An introduction to Bayesian data analysis for Cognitive Science." />
  <meta name="generator" content="bookdown 0.21.6 and GitBook 2.6.7" />

  <meta property="og:title" content="13.1 Meta-analysis | An Introduction to Bayesian Data Analysis for Cognitive Science" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://vasishth.github.io/Bayes_CogSci/" />
  <meta property="og:image" content="https://vasishth.github.io/Bayes_CogSci//images/temporarycover.jpg" />
  <meta property="og:description" content="An introduction to Bayesian data analysis for Cognitive Science." />
  <meta name="github-repo" content="https://github.com/vasishth/Bayes_CogSci" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="13.1 Meta-analysis | An Introduction to Bayesian Data Analysis for Cognitive Science" />
  
  <meta name="twitter:description" content="An introduction to Bayesian data analysis for Cognitive Science." />
  <meta name="twitter:image" content="https://vasishth.github.io/Bayes_CogSci//images/temporarycover.jpg" />

<meta name="author" content="Bruno Nicenboim, Daniel Schad, and Shravan Vasishth" />


<meta name="date" content="2021-06-09" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="ch-remame.html"/>
<link rel="next" href="measurement-error-models.html"/>
<script src="libs/jquery/jquery.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections/anchor-sections.js"></script>



<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Bayesian Data Analysis for Cognitive Science</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="0.1" data-path="prerequisites.html"><a href="prerequisites.html"><i class="fa fa-check"></i><b>0.1</b> Prerequisites</a></li>
<li class="chapter" data-level="0.2" data-path="developing-the-right-mindset-for-this-book.html"><a href="developing-the-right-mindset-for-this-book.html"><i class="fa fa-check"></i><b>0.2</b> Developing the right mindset for this book</a></li>
<li class="chapter" data-level="0.3" data-path="how-to-read-this-book.html"><a href="how-to-read-this-book.html"><i class="fa fa-check"></i><b>0.3</b> How to read this book</a></li>
<li class="chapter" data-level="0.4" data-path="online-materials.html"><a href="online-materials.html"><i class="fa fa-check"></i><b>0.4</b> Online materials</a></li>
<li class="chapter" data-level="0.5" data-path="software-needed.html"><a href="software-needed.html"><i class="fa fa-check"></i><b>0.5</b> Software needed</a></li>
<li class="chapter" data-level="0.6" data-path="acknowledgments.html"><a href="acknowledgments.html"><i class="fa fa-check"></i><b>0.6</b> Acknowledgments</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="about-the-authors.html"><a href="about-the-authors.html"><i class="fa fa-check"></i>About the Authors</a></li>
<li class="part"><span><b>I Foundational ideas</b></span></li>
<li class="chapter" data-level="1" data-path="ch-intro.html"><a href="ch-intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="introprob.html"><a href="introprob.html"><i class="fa fa-check"></i><b>1.1</b> Probability</a></li>
<li class="chapter" data-level="1.2" data-path="conditional-probability.html"><a href="conditional-probability.html"><i class="fa fa-check"></i><b>1.2</b> Conditional probability</a></li>
<li class="chapter" data-level="1.3" data-path="the-law-of-total-probability.html"><a href="the-law-of-total-probability.html"><i class="fa fa-check"></i><b>1.3</b> The law of total probability</a></li>
<li class="chapter" data-level="1.4" data-path="sec-binomialcloze.html"><a href="sec-binomialcloze.html"><i class="fa fa-check"></i><b>1.4</b> Discrete random variables: An example using the Binomial distribution</a><ul>
<li class="chapter" data-level="1.4.1" data-path="sec-binomialcloze.html"><a href="sec-binomialcloze.html#the-mean-and-variance-of-the-binomial-distribution"><i class="fa fa-check"></i><b>1.4.1</b> The mean and variance of the Binomial distribution</a></li>
<li class="chapter" data-level="1.4.2" data-path="sec-binomialcloze.html"><a href="sec-binomialcloze.html#what-information-does-a-probability-distribution-provide"><i class="fa fa-check"></i><b>1.4.2</b> What information does a probability distribution provide?</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="continuous-random-variables-an-example-using-the-normal-distribution.html"><a href="continuous-random-variables-an-example-using-the-normal-distribution.html"><i class="fa fa-check"></i><b>1.5</b> Continuous random variables: An example using the Normal distribution</a><ul>
<li class="chapter" data-level="1.5.1" data-path="continuous-random-variables-an-example-using-the-normal-distribution.html"><a href="continuous-random-variables-an-example-using-the-normal-distribution.html#an-important-distinction-probability-vs.density-in-a-continuous-random-variable"><i class="fa fa-check"></i><b>1.5.1</b> An important distinction: probability vs. density in a continuous random variable</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="bivariate-and-multivariate-distributions.html"><a href="bivariate-and-multivariate-distributions.html"><i class="fa fa-check"></i><b>1.6</b> Bivariate and multivariate distributions</a><ul>
<li class="chapter" data-level="1.6.1" data-path="bivariate-and-multivariate-distributions.html"><a href="bivariate-and-multivariate-distributions.html#example-1-discrete-bivariate-distributions"><i class="fa fa-check"></i><b>1.6.1</b> Example 1: Discrete bivariate distributions</a></li>
<li class="chapter" data-level="1.6.2" data-path="bivariate-and-multivariate-distributions.html"><a href="bivariate-and-multivariate-distributions.html#example-2-continuous-bivariate-distributions"><i class="fa fa-check"></i><b>1.6.2</b> Example 2: Continuous bivariate distributions</a></li>
<li class="chapter" data-level="1.6.3" data-path="bivariate-and-multivariate-distributions.html"><a href="bivariate-and-multivariate-distributions.html#sec:generatebivariatedata"><i class="fa fa-check"></i><b>1.6.3</b> Generate simulated bivariate (multivariate) data</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="sec-marginal.html"><a href="sec-marginal.html"><i class="fa fa-check"></i><b>1.7</b> An important concept: The marginal likelihood (integrating out a parameter)</a></li>
<li class="chapter" data-level="1.8" data-path="summary-of-useful-r-functions-relating-to-distributions.html"><a href="summary-of-useful-r-functions-relating-to-distributions.html"><i class="fa fa-check"></i><b>1.8</b> Summary of useful R functions relating to distributions</a></li>
<li class="chapter" data-level="1.9" data-path="summary.html"><a href="summary.html"><i class="fa fa-check"></i><b>1.9</b> Summary</a></li>
<li class="chapter" data-level="1.10" data-path="further-reading.html"><a href="further-reading.html"><i class="fa fa-check"></i><b>1.10</b> Further reading</a></li>
<li class="chapter" data-level="1.11" data-path="sec-Foundationsexercises.html"><a href="sec-Foundationsexercises.html"><i class="fa fa-check"></i><b>1.11</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="ch-introBDA.html"><a href="ch-introBDA.html"><i class="fa fa-check"></i><b>2</b> Introduction to Bayesian data analysis</a><ul>
<li class="chapter" data-level="2.1" data-path="bayes-rule.html"><a href="bayes-rule.html"><i class="fa fa-check"></i><b>2.1</b> Bayes’ rule</a></li>
<li class="chapter" data-level="2.2" data-path="sec-analytical.html"><a href="sec-analytical.html"><i class="fa fa-check"></i><b>2.2</b> Deriving the posterior using Bayes’ rule: An analytical example</a><ul>
<li class="chapter" data-level="2.2.1" data-path="sec-analytical.html"><a href="sec-analytical.html#choosing-a-likelihood"><i class="fa fa-check"></i><b>2.2.1</b> Choosing a likelihood</a></li>
<li class="chapter" data-level="2.2.2" data-path="sec-analytical.html"><a href="sec-analytical.html#sec:choosepriortheta"><i class="fa fa-check"></i><b>2.2.2</b> Choosing a prior for <span class="math inline">\(\theta\)</span></a></li>
<li class="chapter" data-level="2.2.3" data-path="sec-analytical.html"><a href="sec-analytical.html#using-bayes-rule-to-compute-the-posterior-pthetank"><i class="fa fa-check"></i><b>2.2.3</b> Using Bayes’ rule to compute the posterior <span class="math inline">\(p(\theta|n,k)\)</span></a></li>
<li class="chapter" data-level="2.2.4" data-path="sec-analytical.html"><a href="sec-analytical.html#summary-of-the-procedure"><i class="fa fa-check"></i><b>2.2.4</b> Summary of the procedure</a></li>
<li class="chapter" data-level="2.2.5" data-path="sec-analytical.html"><a href="sec-analytical.html#visualizing-the-prior-likelihood-and-the-posterior"><i class="fa fa-check"></i><b>2.2.5</b> Visualizing the prior, likelihood, and the posterior</a></li>
<li class="chapter" data-level="2.2.6" data-path="sec-analytical.html"><a href="sec-analytical.html#the-posterior-distribution-is-a-compromise-between-the-prior-and-the-likelihood"><i class="fa fa-check"></i><b>2.2.6</b> The posterior distribution is a compromise between the prior and the likelihood</a></li>
<li class="chapter" data-level="2.2.7" data-path="sec-analytical.html"><a href="sec-analytical.html#incremental-knowledge-gain-using-prior-knowledge"><i class="fa fa-check"></i><b>2.2.7</b> Incremental knowledge gain using prior knowledge</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="summary-1.html"><a href="summary-1.html"><i class="fa fa-check"></i><b>2.3</b> Summary</a></li>
<li class="chapter" data-level="2.4" data-path="further-reading-1.html"><a href="further-reading-1.html"><i class="fa fa-check"></i><b>2.4</b> Further reading</a></li>
<li class="chapter" data-level="2.5" data-path="sec-BDAexercises.html"><a href="sec-BDAexercises.html"><i class="fa fa-check"></i><b>2.5</b> Exercises</a></li>
</ul></li>
<li class="part"><span><b>II Regression models with brms</b></span></li>
<li class="chapter" data-level="3" data-path="ch-compbda.html"><a href="ch-compbda.html"><i class="fa fa-check"></i><b>3</b> Computational Bayesian data analysis</a><ul>
<li class="chapter" data-level="3.1" data-path="sec-sampling.html"><a href="sec-sampling.html"><i class="fa fa-check"></i><b>3.1</b> Deriving the posterior through sampling</a><ul>
<li class="chapter" data-level="3.1.1" data-path="sec-sampling.html"><a href="sec-sampling.html#bayesian-regression-models-using-stan-brms"><i class="fa fa-check"></i><b>3.1.1</b> Bayesian Regression Models using ‘Stan’: brms</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="sec-priorpred.html"><a href="sec-priorpred.html"><i class="fa fa-check"></i><b>3.2</b> Prior predictive distribution</a></li>
<li class="chapter" data-level="3.3" data-path="sec-sensitivity.html"><a href="sec-sensitivity.html"><i class="fa fa-check"></i><b>3.3</b> The influence of priors: sensitivity analysis</a><ul>
<li class="chapter" data-level="3.3.1" data-path="sec-sensitivity.html"><a href="sec-sensitivity.html#flat-uninformative-priors"><i class="fa fa-check"></i><b>3.3.1</b> Flat uninformative priors</a></li>
<li class="chapter" data-level="3.3.2" data-path="sec-sensitivity.html"><a href="sec-sensitivity.html#regularizing-priors"><i class="fa fa-check"></i><b>3.3.2</b> Regularizing priors</a></li>
<li class="chapter" data-level="3.3.3" data-path="sec-sensitivity.html"><a href="sec-sensitivity.html#principled-priors"><i class="fa fa-check"></i><b>3.3.3</b> Principled priors</a></li>
<li class="chapter" data-level="3.3.4" data-path="sec-sensitivity.html"><a href="sec-sensitivity.html#informative-priors"><i class="fa fa-check"></i><b>3.3.4</b> Informative priors</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="sec-revisit.html"><a href="sec-revisit.html"><i class="fa fa-check"></i><b>3.4</b> Revisiting the button-pressing example with different priors</a></li>
<li class="chapter" data-level="3.5" data-path="sec-ppd.html"><a href="sec-ppd.html"><i class="fa fa-check"></i><b>3.5</b> Posterior predictive distribution</a><ul>
<li class="chapter" data-level="3.5.1" data-path="sec-ppd.html"><a href="sec-ppd.html#comparing-different-likelihoods"><i class="fa fa-check"></i><b>3.5.1</b> Comparing different likelihoods</a></li>
<li class="chapter" data-level="3.5.2" data-path="sec-ppd.html"><a href="sec-ppd.html#sec:lnfirst"><i class="fa fa-check"></i><b>3.5.2</b> The log-normal likelihood</a></li>
<li class="chapter" data-level="3.5.3" data-path="sec-ppd.html"><a href="sec-ppd.html#sec:lognormal"><i class="fa fa-check"></i><b>3.5.3</b> Re-fitting a single participant pressing a button repeatedly with a log-normal likelihood</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="summary-2.html"><a href="summary-2.html"><i class="fa fa-check"></i><b>3.6</b> Summary</a></li>
<li class="chapter" data-level="3.7" data-path="further-reading-2.html"><a href="further-reading-2.html"><i class="fa fa-check"></i><b>3.7</b> Further reading</a></li>
<li class="chapter" data-level="3.8" data-path="ex-compbda.html"><a href="ex-compbda.html"><i class="fa fa-check"></i><b>3.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="ch-reg.html"><a href="ch-reg.html"><i class="fa fa-check"></i><b>4</b> Bayesian regression models</a><ul>
<li class="chapter" data-level="4.1" data-path="sec-pupil.html"><a href="sec-pupil.html"><i class="fa fa-check"></i><b>4.1</b> A first linear regression: Does attentional load affect pupil size?</a><ul>
<li class="chapter" data-level="4.1.1" data-path="sec-pupil.html"><a href="sec-pupil.html#likelihood-and-priors"><i class="fa fa-check"></i><b>4.1.1</b> Likelihood and priors</a></li>
<li class="chapter" data-level="4.1.2" data-path="sec-pupil.html"><a href="sec-pupil.html#the-brms-model"><i class="fa fa-check"></i><b>4.1.2</b> The <code>brms</code> model</a></li>
<li class="chapter" data-level="4.1.3" data-path="sec-pupil.html"><a href="sec-pupil.html#how-to-communicate-the-results"><i class="fa fa-check"></i><b>4.1.3</b> How to communicate the results?</a></li>
<li class="chapter" data-level="4.1.4" data-path="sec-pupil.html"><a href="sec-pupil.html#sec:pupiladq"><i class="fa fa-check"></i><b>4.1.4</b> Descriptive adequacy</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="sec-trial.html"><a href="sec-trial.html"><i class="fa fa-check"></i><b>4.2</b> Log-normal model: Does trial affect reaction times?</a><ul>
<li class="chapter" data-level="4.2.1" data-path="sec-trial.html"><a href="sec-trial.html#likelihood-and-priors-for-the-log-normal-model"><i class="fa fa-check"></i><b>4.2.1</b> Likelihood and priors for the log-normal model</a></li>
<li class="chapter" data-level="4.2.2" data-path="sec-trial.html"><a href="sec-trial.html#the-brms-model-1"><i class="fa fa-check"></i><b>4.2.2</b> The <code>brms</code> model</a></li>
<li class="chapter" data-level="4.2.3" data-path="sec-trial.html"><a href="sec-trial.html#how-to-communicate-the-results-1"><i class="fa fa-check"></i><b>4.2.3</b> How to communicate the results?</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="sec-logistic.html"><a href="sec-logistic.html"><i class="fa fa-check"></i><b>4.3</b> Logistic regression: Does set size affect free recall?</a><ul>
<li class="chapter" data-level="4.3.1" data-path="sec-logistic.html"><a href="sec-logistic.html#the-likelihood-for-the-logistic-regression-model"><i class="fa fa-check"></i><b>4.3.1</b> The likelihood for the logistic regression model</a></li>
<li class="chapter" data-level="4.3.2" data-path="sec-logistic.html"><a href="sec-logistic.html#priors-for-the-logistic-regression"><i class="fa fa-check"></i><b>4.3.2</b> Priors for the logistic regression</a></li>
<li class="chapter" data-level="4.3.3" data-path="sec-logistic.html"><a href="sec-logistic.html#the-brms-model-2"><i class="fa fa-check"></i><b>4.3.3</b> The <code>brms</code> model</a></li>
<li class="chapter" data-level="4.3.4" data-path="sec-logistic.html"><a href="sec-logistic.html#sec:comlogis"><i class="fa fa-check"></i><b>4.3.4</b> How to communicate the results?</a></li>
<li class="chapter" data-level="4.3.5" data-path="sec-logistic.html"><a href="sec-logistic.html#descriptive-adequacy"><i class="fa fa-check"></i><b>4.3.5</b> Descriptive adequacy</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="summary-3.html"><a href="summary-3.html"><i class="fa fa-check"></i><b>4.4</b> Summary</a></li>
<li class="chapter" data-level="4.5" data-path="further-reading-3.html"><a href="further-reading-3.html"><i class="fa fa-check"></i><b>4.5</b> Further reading</a></li>
<li class="chapter" data-level="4.6" data-path="sec-LMexercises.html"><a href="sec-LMexercises.html"><i class="fa fa-check"></i><b>4.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html"><i class="fa fa-check"></i><b>5</b> Bayesian hierarchical models</a><ul>
<li class="chapter" data-level="5.1" data-path="sec-N400hierarchical.html"><a href="sec-N400hierarchical.html"><i class="fa fa-check"></i><b>5.1</b> A hierarchical normal model: The N400 effect</a><ul>
<li class="chapter" data-level="5.1.1" data-path="sec-N400hierarchical.html"><a href="sec-N400hierarchical.html#complete-pooling-model-m_cp"><i class="fa fa-check"></i><b>5.1.1</b> Complete-pooling model (<span class="math inline">\(M_{cp}\)</span>)</a></li>
<li class="chapter" data-level="5.1.2" data-path="sec-N400hierarchical.html"><a href="sec-N400hierarchical.html#no-pooling-model-m_np"><i class="fa fa-check"></i><b>5.1.2</b> No-pooling model (<span class="math inline">\(M_{np}\)</span>)</a></li>
<li class="chapter" data-level="5.1.3" data-path="sec-N400hierarchical.html"><a href="sec-N400hierarchical.html#sec:uncorrelated"><i class="fa fa-check"></i><b>5.1.3</b> Varying intercept and varying slopes model (<span class="math inline">\(M_{v}\)</span>)</a></li>
<li class="chapter" data-level="5.1.4" data-path="sec-N400hierarchical.html"><a href="sec-N400hierarchical.html#sec:mcvivs"><i class="fa fa-check"></i><b>5.1.4</b> Correlated varying intercept varying slopes model (<span class="math inline">\(M_{h}\)</span>)</a></li>
<li class="chapter" data-level="5.1.5" data-path="sec-N400hierarchical.html"><a href="sec-N400hierarchical.html#sec:sih"><i class="fa fa-check"></i><b>5.1.5</b> By-subjects and by-items correlated varying intercept varying slopes model (<span class="math inline">\(M_{sih}\)</span>)</a></li>
<li class="chapter" data-level="5.1.6" data-path="sec-N400hierarchical.html"><a href="sec-N400hierarchical.html#sec:distrmodel"><i class="fa fa-check"></i><b>5.1.6</b> Beyond the so-called maximal models–Distributional regression models</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="sec-stroop.html"><a href="sec-stroop.html"><i class="fa fa-check"></i><b>5.2</b> A hierarchical log-normal model: The Stroop effect</a><ul>
<li class="chapter" data-level="5.2.1" data-path="sec-stroop.html"><a href="sec-stroop.html#a-correlated-varying-intercept-varying-slopes-log-normal-model"><i class="fa fa-check"></i><b>5.2.1</b> A correlated varying intercept varying slopes log-normal model</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="why-fitting-a-bayesian-hierarchical-model-is-worth-the-effort.html"><a href="why-fitting-a-bayesian-hierarchical-model-is-worth-the-effort.html"><i class="fa fa-check"></i><b>5.3</b> Why fitting a Bayesian hierarchical model is worth the effort</a></li>
<li class="chapter" data-level="5.4" data-path="summary-4.html"><a href="summary-4.html"><i class="fa fa-check"></i><b>5.4</b> Summary</a></li>
<li class="chapter" data-level="5.5" data-path="further-reading-4.html"><a href="further-reading-4.html"><i class="fa fa-check"></i><b>5.5</b> Further reading</a></li>
<li class="chapter" data-level="5.6" data-path="sec-HLMexercises.html"><a href="sec-HLMexercises.html"><i class="fa fa-check"></i><b>5.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="ch-priors.html"><a href="ch-priors.html"><i class="fa fa-check"></i><b>6</b> The Art and Science of Prior Elicitation</a><ul>
<li class="chapter" data-level="6.1" data-path="a-simple-example-of-eliciting-priors-from-oneself.html"><a href="a-simple-example-of-eliciting-priors-from-oneself.html"><i class="fa fa-check"></i><b>6.1</b> A simple example of eliciting priors from oneself</a></li>
<li class="chapter" data-level="6.2" data-path="eliciting-priors-from-experts.html"><a href="eliciting-priors-from-experts.html"><i class="fa fa-check"></i><b>6.2</b> Eliciting priors from experts</a></li>
<li class="chapter" data-level="6.3" data-path="deriving-priors-from-meta-analyses.html"><a href="deriving-priors-from-meta-analyses.html"><i class="fa fa-check"></i><b>6.3</b> Deriving priors from meta-analyses</a></li>
<li class="chapter" data-level="6.4" data-path="using-previous-experiments-posteriors-as-priors-for-a-new-study.html"><a href="using-previous-experiments-posteriors-as-priors-for-a-new-study.html"><i class="fa fa-check"></i><b>6.4</b> Using previous experiments’ posteriors as priors for a new study</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="ch-workflow.html"><a href="ch-workflow.html"><i class="fa fa-check"></i><b>7</b> Workflow</a></li>
<li class="chapter" data-level="8" data-path="ch-contr.html"><a href="ch-contr.html"><i class="fa fa-check"></i><b>8</b> Contrast coding</a><ul>
<li class="chapter" data-level="8.1" data-path="basic-concepts-illustrated-using-a-two-level-factor.html"><a href="basic-concepts-illustrated-using-a-two-level-factor.html"><i class="fa fa-check"></i><b>8.1</b> Basic concepts illustrated using a two-level factor</a><ul>
<li class="chapter" data-level="8.1.1" data-path="basic-concepts-illustrated-using-a-two-level-factor.html"><a href="basic-concepts-illustrated-using-a-two-level-factor.html#treatmentcontrasts"><i class="fa fa-check"></i><b>8.1.1</b> Default contrast coding: Treatment contrasts</a></li>
<li class="chapter" data-level="8.1.2" data-path="basic-concepts-illustrated-using-a-two-level-factor.html"><a href="basic-concepts-illustrated-using-a-two-level-factor.html#inverseMatrix"><i class="fa fa-check"></i><b>8.1.2</b> Defining hypotheses</a></li>
<li class="chapter" data-level="8.1.3" data-path="basic-concepts-illustrated-using-a-two-level-factor.html"><a href="basic-concepts-illustrated-using-a-two-level-factor.html#effectcoding"><i class="fa fa-check"></i><b>8.1.3</b> Sum contrasts</a></li>
<li class="chapter" data-level="8.1.4" data-path="basic-concepts-illustrated-using-a-two-level-factor.html"><a href="basic-concepts-illustrated-using-a-two-level-factor.html#sec:cellMeans"><i class="fa fa-check"></i><b>8.1.4</b> Cell means parameterization and posterior comparisons</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="the-hypothesis-matrix-illustrated-with-a-three-level-factor.html"><a href="the-hypothesis-matrix-illustrated-with-a-three-level-factor.html"><i class="fa fa-check"></i><b>8.2</b> The hypothesis matrix illustrated with a three-level factor</a><ul>
<li class="chapter" data-level="8.2.1" data-path="the-hypothesis-matrix-illustrated-with-a-three-level-factor.html"><a href="the-hypothesis-matrix-illustrated-with-a-three-level-factor.html#sumcontrasts"><i class="fa fa-check"></i><b>8.2.1</b> Sum contrasts</a></li>
<li class="chapter" data-level="8.2.2" data-path="the-hypothesis-matrix-illustrated-with-a-three-level-factor.html"><a href="the-hypothesis-matrix-illustrated-with-a-three-level-factor.html#the-hypothesis-matrix"><i class="fa fa-check"></i><b>8.2.2</b> The hypothesis matrix</a></li>
<li class="chapter" data-level="8.2.3" data-path="the-hypothesis-matrix-illustrated-with-a-three-level-factor.html"><a href="the-hypothesis-matrix-illustrated-with-a-three-level-factor.html#generating-contrasts-the-hypr-package"><i class="fa fa-check"></i><b>8.2.3</b> Generating contrasts: The <code>hypr</code> package</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="sec-4levelFactor.html"><a href="sec-4levelFactor.html"><i class="fa fa-check"></i><b>8.3</b> Other types of contrasts: illustration with a factor with four levels</a><ul>
<li class="chapter" data-level="8.3.1" data-path="sec-4levelFactor.html"><a href="sec-4levelFactor.html#repeatedcontrasts"><i class="fa fa-check"></i><b>8.3.1</b> Repeated contrasts</a></li>
<li class="chapter" data-level="8.3.2" data-path="sec-4levelFactor.html"><a href="sec-4levelFactor.html#helmertcontrasts"><i class="fa fa-check"></i><b>8.3.2</b> Helmert contrasts</a></li>
<li class="chapter" data-level="8.3.3" data-path="sec-4levelFactor.html"><a href="sec-4levelFactor.html#contrasts-in-linear-regression-analysis-the-design-or-model-matrix"><i class="fa fa-check"></i><b>8.3.3</b> Contrasts in linear regression analysis: The design or model matrix</a></li>
<li class="chapter" data-level="8.3.4" data-path="sec-4levelFactor.html"><a href="sec-4levelFactor.html#polynomialContrasts"><i class="fa fa-check"></i><b>8.3.4</b> Polynomial contrasts</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="nonOrthogonal.html"><a href="nonOrthogonal.html"><i class="fa fa-check"></i><b>8.4</b> What makes a good set of contrasts?</a><ul>
<li class="chapter" data-level="8.4.1" data-path="nonOrthogonal.html"><a href="nonOrthogonal.html#centered-contrasts"><i class="fa fa-check"></i><b>8.4.1</b> Centered contrasts</a></li>
<li class="chapter" data-level="8.4.2" data-path="nonOrthogonal.html"><a href="nonOrthogonal.html#orthogonal-contrasts"><i class="fa fa-check"></i><b>8.4.2</b> Orthogonal contrasts</a></li>
<li class="chapter" data-level="8.4.3" data-path="nonOrthogonal.html"><a href="nonOrthogonal.html#the-role-of-the-intercept-in-non-centered-contrasts"><i class="fa fa-check"></i><b>8.4.3</b> The role of the intercept in non-centered contrasts</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="computing-condition-means-from-estimated-contrasts.html"><a href="computing-condition-means-from-estimated-contrasts.html"><i class="fa fa-check"></i><b>8.5</b> Computing condition means from estimated contrasts</a></li>
<li class="chapter" data-level="8.6" data-path="summary-5.html"><a href="summary-5.html"><i class="fa fa-check"></i><b>8.6</b> Summary</a></li>
<li class="chapter" data-level="8.7" data-path="further-reading-5.html"><a href="further-reading-5.html"><i class="fa fa-check"></i><b>8.7</b> Further reading</a></li>
<li class="chapter" data-level="8.8" data-path="sec-Contrastsexercises.html"><a href="sec-Contrastsexercises.html"><i class="fa fa-check"></i><b>8.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="ch-coding2x2.html"><a href="ch-coding2x2.html"><i class="fa fa-check"></i><b>9</b> Contrast coding for designs with two predictor variables</a><ul>
<li class="chapter" data-level="9.1" data-path="sec-MR-ANOVA.html"><a href="sec-MR-ANOVA.html"><i class="fa fa-check"></i><b>9.1</b> Contrast coding in a factorial 2 x 2 design</a><ul>
<li class="chapter" data-level="9.1.1" data-path="sec-MR-ANOVA.html"><a href="sec-MR-ANOVA.html#nestedEffects"><i class="fa fa-check"></i><b>9.1.1</b> Nested effects</a></li>
<li class="chapter" data-level="9.1.2" data-path="sec-MR-ANOVA.html"><a href="sec-MR-ANOVA.html#interactions-between-contrasts"><i class="fa fa-check"></i><b>9.1.2</b> Interactions between contrasts</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="sec-contrast-covariate.html"><a href="sec-contrast-covariate.html"><i class="fa fa-check"></i><b>9.2</b> One factor and one covariate</a><ul>
<li class="chapter" data-level="9.2.1" data-path="sec-contrast-covariate.html"><a href="sec-contrast-covariate.html#estimating-a-group-difference-and-controlling-for-a-covariate"><i class="fa fa-check"></i><b>9.2.1</b> Estimating a group difference and controlling for a covariate</a></li>
<li class="chapter" data-level="9.2.2" data-path="sec-contrast-covariate.html"><a href="sec-contrast-covariate.html#estimating-differences-in-slopes"><i class="fa fa-check"></i><b>9.2.2</b> Estimating differences in slopes</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="sec-interactions-NLM.html"><a href="sec-interactions-NLM.html"><i class="fa fa-check"></i><b>9.3</b> Interactions in generalized linear models (with non-linear link functions)</a></li>
<li class="chapter" data-level="9.4" data-path="summary-6.html"><a href="summary-6.html"><i class="fa fa-check"></i><b>9.4</b> Summary</a></li>
<li class="chapter" data-level="9.5" data-path="further-readings.html"><a href="further-readings.html"><i class="fa fa-check"></i><b>9.5</b> Further readings</a></li>
<li class="chapter" data-level="9.6" data-path="sec-Contrasts2x2exercises.html"><a href="sec-Contrasts2x2exercises.html"><i class="fa fa-check"></i><b>9.6</b> Exercises</a></li>
</ul></li>
<li class="part"><span><b>III Advanced models with Stan</b></span></li>
<li class="chapter" data-level="10" data-path="ch-introstan.html"><a href="ch-introstan.html"><i class="fa fa-check"></i><b>10</b> Introduction to the probabilistic programming language Stan</a><ul>
<li class="chapter" data-level="10.1" data-path="stan-syntax.html"><a href="stan-syntax.html"><i class="fa fa-check"></i><b>10.1</b> Stan syntax</a></li>
<li class="chapter" data-level="10.2" data-path="sec-firststan.html"><a href="sec-firststan.html"><i class="fa fa-check"></i><b>10.2</b> A first simple example with Stan: Normal likelihood</a></li>
<li class="chapter" data-level="10.3" data-path="sec-clozestan.html"><a href="sec-clozestan.html"><i class="fa fa-check"></i><b>10.3</b> Another simple example: Cloze probability with Stan: Binomial likelihood</a></li>
<li class="chapter" data-level="10.4" data-path="regression-models-in-stan.html"><a href="regression-models-in-stan.html"><i class="fa fa-check"></i><b>10.4</b> Regression models in Stan</a><ul>
<li class="chapter" data-level="10.4.1" data-path="regression-models-in-stan.html"><a href="regression-models-in-stan.html#sec:pupilstan"><i class="fa fa-check"></i><b>10.4.1</b> A first linear regression in Stan: Does attentional load affect pupil size?</a></li>
<li class="chapter" data-level="10.4.2" data-path="regression-models-in-stan.html"><a href="regression-models-in-stan.html#sec:interstan"><i class="fa fa-check"></i><b>10.4.2</b> Interactions in Stan: Does attentional load interact with trial number affecting pupil size?</a></li>
<li class="chapter" data-level="10.4.3" data-path="regression-models-in-stan.html"><a href="regression-models-in-stan.html#sec:logisticstan"><i class="fa fa-check"></i><b>10.4.3</b> Logistic regression in Stan: Does set size and trial affect free recall?</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="summary-7.html"><a href="summary-7.html"><i class="fa fa-check"></i><b>10.5</b> Summary</a></li>
<li class="chapter" data-level="10.6" data-path="further-reading-6.html"><a href="further-reading-6.html"><i class="fa fa-check"></i><b>10.6</b> Further reading</a></li>
<li class="chapter" data-level="10.7" data-path="exercises.html"><a href="exercises.html"><i class="fa fa-check"></i><b>10.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="ch-complexstan.html"><a href="ch-complexstan.html"><i class="fa fa-check"></i><b>11</b> Complex models and reparametrization</a><ul>
<li class="chapter" data-level="11.1" data-path="hierarchical-models-with-stan.html"><a href="hierarchical-models-with-stan.html"><i class="fa fa-check"></i><b>11.1</b> Hierarchical models with Stan</a><ul>
<li class="chapter" data-level="11.1.1" data-path="hierarchical-models-with-stan.html"><a href="hierarchical-models-with-stan.html#varying-intercept-model-with-stan"><i class="fa fa-check"></i><b>11.1.1</b> Varying intercept model with Stan</a></li>
<li class="chapter" data-level="11.1.2" data-path="hierarchical-models-with-stan.html"><a href="hierarchical-models-with-stan.html#sec:uncorrstan"><i class="fa fa-check"></i><b>11.1.2</b> Uncorrelated varying intercept and slopes model with Stan</a></li>
<li class="chapter" data-level="11.1.3" data-path="hierarchical-models-with-stan.html"><a href="hierarchical-models-with-stan.html#sec:corrstan"><i class="fa fa-check"></i><b>11.1.3</b> Correlated varying intercept varying slopes model</a></li>
<li class="chapter" data-level="11.1.4" data-path="hierarchical-models-with-stan.html"><a href="hierarchical-models-with-stan.html#sec:crosscorrstan"><i class="fa fa-check"></i><b>11.1.4</b> By-subject and by-items correlated varying intercept varying slopes model</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="summary-8.html"><a href="summary-8.html"><i class="fa fa-check"></i><b>11.2</b> Summary</a></li>
<li class="chapter" data-level="11.3" data-path="further-reading-7.html"><a href="further-reading-7.html"><i class="fa fa-check"></i><b>11.3</b> Further reading</a></li>
<li class="chapter" data-level="11.4" data-path="exercises-1.html"><a href="exercises-1.html"><i class="fa fa-check"></i><b>11.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="ch-custom.html"><a href="ch-custom.html"><i class="fa fa-check"></i><b>12</b> Custom likelihoods in Stan</a></li>
<li class="part"><span><b>IV Other useful models</b></span></li>
<li class="chapter" data-level="13" data-path="ch-remame.html"><a href="ch-remame.html"><i class="fa fa-check"></i><b>13</b> Meta-analysis and measurement error models</a><ul>
<li class="chapter" data-level="13.1" data-path="meta-analysis.html"><a href="meta-analysis.html"><i class="fa fa-check"></i><b>13.1</b> Meta-analysis</a><ul>
<li class="chapter" data-level="13.1.1" data-path="meta-analysis.html"><a href="meta-analysis.html#a-meta-analysis-of-similarity-based-interference-in-sentence-comprehension"><i class="fa fa-check"></i><b>13.1.1</b> A meta-analysis of similarity-based interference in sentence comprehension</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="measurement-error-models.html"><a href="measurement-error-models.html"><i class="fa fa-check"></i><b>13.2</b> Measurement-error models</a><ul>
<li class="chapter" data-level="13.2.1" data-path="measurement-error-models.html"><a href="measurement-error-models.html#accounting-for-measurement-error-in-a-voice-onset-time-model"><i class="fa fa-check"></i><b>13.2.1</b> Accounting for measurement error in a voice onset time model</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="summary-9.html"><a href="summary-9.html"><i class="fa fa-check"></i><b>13.3</b> Summary</a></li>
<li class="chapter" data-level="13.4" data-path="further-reading-8.html"><a href="further-reading-8.html"><i class="fa fa-check"></i><b>13.4</b> Further reading</a></li>
<li class="chapter" data-level="13.5" data-path="sec-REMAMEexercises.html"><a href="sec-REMAMEexercises.html"><i class="fa fa-check"></i><b>13.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="ch-sat.html"><a href="ch-sat.html"><i class="fa fa-check"></i><b>14</b> SAT</a></li>
<li class="part"><span><b>V Model comparison and hypothesis testing</b></span></li>
<li class="chapter" data-level="15" data-path="ch-comparison.html"><a href="ch-comparison.html"><i class="fa fa-check"></i><b>15</b> Introduction to model comparison</a></li>
<li class="chapter" data-level="16" data-path="ch-bf.html"><a href="ch-bf.html"><i class="fa fa-check"></i><b>16</b> Bayes factors</a><ul>
<li class="chapter" data-level="16.1" data-path="hypothesis-testing-using-the-bayes-factor.html"><a href="hypothesis-testing-using-the-bayes-factor.html"><i class="fa fa-check"></i><b>16.1</b> Hypothesis testing using the Bayes factor</a><ul>
<li class="chapter" data-level="16.1.1" data-path="hypothesis-testing-using-the-bayes-factor.html"><a href="hypothesis-testing-using-the-bayes-factor.html#marginal-likelihood"><i class="fa fa-check"></i><b>16.1.1</b> Marginal likelihood</a></li>
<li class="chapter" data-level="16.1.2" data-path="hypothesis-testing-using-the-bayes-factor.html"><a href="hypothesis-testing-using-the-bayes-factor.html#bayes-factor"><i class="fa fa-check"></i><b>16.1.2</b> Bayes factor</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="sec-N400BF.html"><a href="sec-N400BF.html"><i class="fa fa-check"></i><b>16.2</b> Examining the N400 effect with Bayes factor</a><ul>
<li class="chapter" data-level="16.2.1" data-path="sec-N400BF.html"><a href="sec-N400BF.html#sensitivity-analysis-1"><i class="fa fa-check"></i><b>16.2.1</b> Sensitivity analysis</a></li>
<li class="chapter" data-level="16.2.2" data-path="sec-N400BF.html"><a href="sec-N400BF.html#sec:BFnonnested"><i class="fa fa-check"></i><b>16.2.2</b> Non-nested models</a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="the-influence-of-the-priors-on-bayes-factors-beyond-the-effect-of-interest.html"><a href="the-influence-of-the-priors-on-bayes-factors-beyond-the-effect-of-interest.html"><i class="fa fa-check"></i><b>16.3</b> The influence of the priors on Bayes factors: beyond the effect of interest</a><ul>
<li class="chapter" data-level="16.3.1" data-path="the-influence-of-the-priors-on-bayes-factors-beyond-the-effect-of-interest.html"><a href="the-influence-of-the-priors-on-bayes-factors-beyond-the-effect-of-interest.html#bayes-factor-in-stan"><i class="fa fa-check"></i><b>16.3.1</b> Bayes factor in Stan</a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="bayes-factors-in-theory-and-in-practice.html"><a href="bayes-factors-in-theory-and-in-practice.html"><i class="fa fa-check"></i><b>16.4</b> Bayes factors in theory and in practice</a><ul>
<li class="chapter" data-level="16.4.1" data-path="bayes-factors-in-theory-and-in-practice.html"><a href="bayes-factors-in-theory-and-in-practice.html#bayes-factors-in-theory-stability-and-accuracy"><i class="fa fa-check"></i><b>16.4.1</b> Bayes factors in theory: Stability and accuracy</a></li>
<li class="chapter" data-level="16.4.2" data-path="bayes-factors-in-theory-and-in-practice.html"><a href="bayes-factors-in-theory-and-in-practice.html#bayes-factors-in-practice-variability-with-the-data"><i class="fa fa-check"></i><b>16.4.2</b> Bayes factors in practice: Variability with the data</a></li>
</ul></li>
<li class="chapter" data-level="16.5" data-path="summary-10.html"><a href="summary-10.html"><i class="fa fa-check"></i><b>16.5</b> Summary</a></li>
<li class="chapter" data-level="16.6" data-path="further-reading-9.html"><a href="further-reading-9.html"><i class="fa fa-check"></i><b>16.6</b> Further reading</a></li>
<li class="chapter" data-level="16.7" data-path="exercises-2.html"><a href="exercises-2.html"><i class="fa fa-check"></i><b>16.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="ch-cv.html"><a href="ch-cv.html"><i class="fa fa-check"></i><b>17</b> Cross-validation</a><ul>
<li class="chapter" data-level="17.1" data-path="expected-log-predictive-density-of-a-model.html"><a href="expected-log-predictive-density-of-a-model.html"><i class="fa fa-check"></i><b>17.1</b> Expected log predictive density of a model</a></li>
<li class="chapter" data-level="17.2" data-path="k-fold-and-leave-one-out-cross-validation.html"><a href="k-fold-and-leave-one-out-cross-validation.html"><i class="fa fa-check"></i><b>17.2</b> K-fold and leave-one-out cross-validation</a></li>
<li class="chapter" data-level="17.3" data-path="testing-the-n400-effect-using-cross-validation.html"><a href="testing-the-n400-effect-using-cross-validation.html"><i class="fa fa-check"></i><b>17.3</b> Testing the N400 effect using cross-validation</a><ul>
<li class="chapter" data-level="17.3.1" data-path="testing-the-n400-effect-using-cross-validation.html"><a href="testing-the-n400-effect-using-cross-validation.html#cross-validation-in-stan"><i class="fa fa-check"></i><b>17.3.1</b> cross-validation in Stan</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="summary-11.html"><a href="summary-11.html"><i class="fa fa-check"></i><b>17.4</b> Summary</a></li>
<li class="chapter" data-level="17.5" data-path="further-reading-10.html"><a href="further-reading-10.html"><i class="fa fa-check"></i><b>17.5</b> Further reading</a></li>
<li class="chapter" data-level="17.6" data-path="exercises-3.html"><a href="exercises-3.html"><i class="fa fa-check"></i><b>17.6</b> Exercises</a></li>
</ul></li>
<li class="part"><span><b>VI Computational cognitive modeling with Stan</b></span></li>
<li class="chapter" data-level="18" data-path="ch-cogmod.html"><a href="ch-cogmod.html"><i class="fa fa-check"></i><b>18</b> Introduction to computational cognitive modeling</a><ul>
<li class="chapter" data-level="18.1" data-path="further-reading-11.html"><a href="further-reading-11.html"><i class="fa fa-check"></i><b>18.1</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="ch-MPT.html"><a href="ch-MPT.html"><i class="fa fa-check"></i><b>19</b> Multinomial processing trees</a><ul>
<li class="chapter" data-level="19.1" data-path="modeling-multiple-categorical-responses.html"><a href="modeling-multiple-categorical-responses.html"><i class="fa fa-check"></i><b>19.1</b> Modeling multiple categorical responses</a><ul>
<li class="chapter" data-level="19.1.1" data-path="modeling-multiple-categorical-responses.html"><a href="modeling-multiple-categorical-responses.html#sec:mult"><i class="fa fa-check"></i><b>19.1.1</b> A model for multiple responses using the multinomial likelihood</a></li>
<li class="chapter" data-level="19.1.2" data-path="modeling-multiple-categorical-responses.html"><a href="modeling-multiple-categorical-responses.html#sec:cat"><i class="fa fa-check"></i><b>19.1.2</b> A model for multiple responses using the categorical distribution</a></li>
</ul></li>
<li class="chapter" data-level="19.2" data-path="multinomial-processing-tree-mpt-models.html"><a href="multinomial-processing-tree-mpt-models.html"><i class="fa fa-check"></i><b>19.2</b> Multinomial processing tree (MPT) models</a><ul>
<li class="chapter" data-level="19.2.1" data-path="multinomial-processing-tree-mpt-models.html"><a href="multinomial-processing-tree-mpt-models.html#mpts-for-modeling-picture-naming-abilities-in-aphasia"><i class="fa fa-check"></i><b>19.2.1</b> MPTs for modeling picture naming abilities in aphasia</a></li>
</ul></li>
<li class="chapter" data-level="19.3" data-path="further-reading-12.html"><a href="further-reading-12.html"><i class="fa fa-check"></i><b>19.3</b> Further reading</a></li>
<li class="chapter" data-level="19.4" data-path="exercises-4.html"><a href="exercises-4.html"><i class="fa fa-check"></i><b>19.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="ch-mixture.html"><a href="ch-mixture.html"><i class="fa fa-check"></i><b>20</b> Mixture models</a><ul>
<li class="chapter" data-level="20.1" data-path="a-mixture-model-of-the-speed-accuracy-trade-off.html"><a href="a-mixture-model-of-the-speed-accuracy-trade-off.html"><i class="fa fa-check"></i><b>20.1</b> A mixture model of the speed-accuracy trade-off</a><ul>
<li class="chapter" data-level="20.1.1" data-path="a-mixture-model-of-the-speed-accuracy-trade-off.html"><a href="a-mixture-model-of-the-speed-accuracy-trade-off.html#a-fast-guess-model-account-of-the-global-motion-detection-task"><i class="fa fa-check"></i><b>20.1.1</b> A fast guess model account of the global motion detection task</a></li>
</ul></li>
<li class="chapter" data-level="20.2" data-path="summary-12.html"><a href="summary-12.html"><i class="fa fa-check"></i><b>20.2</b> Summary</a></li>
<li class="chapter" data-level="20.3" data-path="further-reading-13.html"><a href="further-reading-13.html"><i class="fa fa-check"></i><b>20.3</b> Further reading</a></li>
<li class="chapter" data-level="20.4" data-path="exercises-5.html"><a href="exercises-5.html"><i class="fa fa-check"></i><b>20.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="ch-lognormal.html"><a href="ch-lognormal.html"><i class="fa fa-check"></i><b>21</b> A simple accumulator model to account for choice response time</a></li>
<li class="part"><span><b>VII Appendix</b></span></li>
<li class="chapter" data-level="22" data-path="ch-distr.html"><a href="ch-distr.html"><i class="fa fa-check"></i><b>22</b> Important distributions</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="_blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">An Introduction to Bayesian Data Analysis for Cognitive Science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="meta-analysis" class="section level2">
<h2><span class="header-section-number">13.1</span> Meta-analysis</h2>
<p>Once a number of studies have accumulated on a particular topic, it can be very informative to synthesize the data. Here is a commonly used approach: a random-effects meta-analysis.</p>
<div id="a-meta-analysis-of-similarity-based-interference-in-sentence-comprehension" class="section level3">
<h3><span class="header-section-number">13.1.1</span> A meta-analysis of similarity-based interference in sentence comprehension</h3>
<p>The model is set up as follows. For each study <span class="math inline">\(n\)</span>, let effect<span class="math inline">\(_n\)</span> be the effect of interest, and let <span class="math inline">\(SE_n\)</span> be the standard error of the effect. A concrete example from a recent meta-analysis is the effect of similarity-based interference in sentence comprehension <span class="citation">(Jäger, Engelmann, and Vasishth <a href="#ref-JaegerEngelmannVasishth2017">2017</a>)</span>; when two nouns are more similar to each other, there is greater processing difficulty (i.e., longer reading times in milliseconds) when an attempt is made to retrieve one of the nouns to complete a linguistic dependency. The estimate of the effect and its standard error is the information we have from each study <span class="math inline">\(n\)</span>.</p>
<p>First, we load the data, and we add an id that identifies each experiment.</p>
<div class="sourceCode" id="cb674"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb674-1" data-line-number="1"><span class="kw">data</span>(<span class="st">&quot;df_sbi&quot;</span>)</a>
<a class="sourceLine" id="cb674-2" data-line-number="2">(df_sbi &lt;-<span class="st"> </span>df_sbi <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb674-3" data-line-number="3"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">study_id =</span> <span class="dv">1</span><span class="op">:</span><span class="kw">n</span>()))</a></code></pre></div>
<pre><code>## # A tibble: 12 x 4
##   publication         effect    SE study_id
##   &lt;chr&gt;                &lt;int&gt; &lt;int&gt;    &lt;int&gt;
## 1 VanDyke07E1LoSem        13    30        1
## 2 VanDyke07E2LoSem        37    21        2
## 3 VanDyke07E3LoSem        20    11        3
## 4 VanDykeEtal03E4         56    25        4
## 5 VanDykeEtAl11E2bPro      7     9        5
## # … with 7 more rows</code></pre>
<p>We begin with the assumption that there is a true (unknown) effect <span class="math inline">\(\zeta_n\)</span> that lies behind each of these studies. Each of the observed effects has an uncertainty associated with it, <span class="math inline">\(SE_n\)</span>. We can therefore assume that each observed effect, effect<span class="math inline">\(_n\)</span>, is generated as follows:</p>
<p><span class="math display">\[\begin{equation}
\text{effect}_n \sim Normal(\zeta_n,SE_n)
\end{equation}\]</span></p>
<p>Each study is assumed to have a different true effect <span class="math inline">\(\zeta_n\)</span> because each study will have been carried out under different conditions: in a different lab with different protocols and workflows, with different subjects, with different languages, with slightly different experimental designs, etc.</p>
<p>Further, each of the true underlying effects <span class="math inline">\(\zeta_n\)</span> has behind it some true unknown value <span class="math inline">\(\zeta\)</span>. We can write this as:</p>
<p><span class="math display">\[\begin{equation}
\zeta_n \sim Normal(\zeta,\tau)
\end{equation}\]</span></p>
<p><span class="math inline">\(\tau\)</span> is the between-study standard deviation; this expresses the assumption that there will be some variability between the true effects <span class="math inline">\(\zeta_n\)</span>, simply because of differences between the way the different experiments were conducted.</p>
<p>To summarize the model:</p>
<ul>
<li>effect<span class="math inline">\(_n\)</span> is the observed effect (in this example, in milliseconds) in the <span class="math inline">\(n\)</span>-th study.</li>
<li><span class="math inline">\(\zeta_n\)</span> is the true (unknown) effect in each study.</li>
<li><span class="math inline">\(\zeta\)</span> is the true (unknown) effect, to be estimated by the model.</li>
<li><span class="math inline">\(SE_{n}\)</span> is the true standard deviation of the sampling distribution; each <span class="math inline">\(SE_n\)</span> is estimated from the standard error available from the study <span class="math inline">\(n\)</span>.</li>
<li>The parameter <span class="math inline">\(\tau\)</span> represents between-study standard deviation.</li>
</ul>
<p>We can construct a hierarchical model as follows:</p>
<p><span class="math display" id="eq:ma0">\[\begin{equation}
\begin{aligned}
\text{effect}_n \sim &amp; Normal(\zeta_n, SE_n) \quad n=1,\dots, N_{studies}\\
\zeta_n \sim &amp; Normal(\zeta, \tau) \\
\zeta \sim &amp; Normal(0,100)\\
 \tau \sim &amp; Normal_+(0,100) 
\end{aligned}
\tag{13.1}
\end{equation}\]</span></p>
<p>The priors are based on domain knowledge; we know that the interference effect is unlikely to be larger than 100 ms. Of course, a sensitivity analysis is necessary (but skipped here).</p>
<p>This model can be implemented in brms in a relatively straightforward way as shown below. We show the Stan version later in the chapter, since it presents some interesting challenges that can be useful for the reader interested in deepening their Stan modeling knowledge.</p>
<div id="brms-version-of-the-meta-analysis-model" class="section level4">
<h4><span class="header-section-number">13.1.1.1</span> brms version of the meta-analysis model</h4>
<p>First, define the priors:</p>
<div class="sourceCode" id="cb676"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb676-1" data-line-number="1">priors &lt;-<span class="st"> </span><span class="kw">c</span>(</a>
<a class="sourceLine" id="cb676-2" data-line-number="2">  <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">100</span>), <span class="dt">class =</span> Intercept),</a>
<a class="sourceLine" id="cb676-3" data-line-number="3">  <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">100</span>), <span class="dt">class =</span> sd)</a>
<a class="sourceLine" id="cb676-4" data-line-number="4">)</a></code></pre></div>
<p>Fit the model as follows. Because of our relatively uninformative priors and the few data points, the models of this chapter require us to tune the <code>control</code> parameter, increasing <code>adapt_delta</code> and <code>max_treedepth</code>.</p>
<div class="sourceCode" id="cb677"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb677-1" data-line-number="1">fit_sbi &lt;-<span class="st"> </span><span class="kw">brm</span>(effect <span class="op">|</span><span class="st"> </span><span class="kw">resp_se</span>(<span class="st">`</span><span class="dt">SE</span><span class="st">`</span>, <span class="dt">sigma =</span> <span class="ot">FALSE</span>) <span class="op">~</span><span class="st"> </span><span class="dv">1</span></a>
<a class="sourceLine" id="cb677-2" data-line-number="2">               <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>study_id),</a>
<a class="sourceLine" id="cb677-3" data-line-number="3">  <span class="dt">data =</span> df_sbi,</a>
<a class="sourceLine" id="cb677-4" data-line-number="4">  <span class="dt">prior =</span> priors,</a>
<a class="sourceLine" id="cb677-5" data-line-number="5">  <span class="dt">control =</span> <span class="kw">list</span>(</a>
<a class="sourceLine" id="cb677-6" data-line-number="6">    <span class="dt">adapt_delta =</span> <span class="fl">.999</span>,</a>
<a class="sourceLine" id="cb677-7" data-line-number="7">    <span class="dt">max_treedepth =</span> <span class="dv">12</span></a>
<a class="sourceLine" id="cb677-8" data-line-number="8">  )</a>
<a class="sourceLine" id="cb677-9" data-line-number="9">)</a></code></pre></div>
<p>The posterior of <span class="math inline">\(\zeta\)</span> and <span class="math inline">\(\tau\)</span> are summarized below as <code>Intercept</code> and <code>sd(Intercept)</code>.</p>
<div class="sourceCode" id="cb678"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb678-1" data-line-number="1">fit_sbi</a></code></pre></div>
<pre><code>## ...
## Group-Level Effects: 
## ~study_id (Number of levels: 12) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS
## sd(Intercept)    11.76      7.73     0.66    29.33 1.00      970
##               Tail_ESS
## sd(Intercept)     1335
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept    13.74      6.61     3.20    29.30 1.00     1540     1341
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma     0.00      0.00     0.00     0.00 1.00     4000     4000
## 
## ...</code></pre>
<p>The <code>sigma</code> parameter does not play any role in this model, but appears in the brms output anyway. In the model specification, <code>sigma</code> was explicitly removed by writing <code>sigma = FALSE</code>. For this reason, we can ignore that parameter in the model summary output above. Box <a href="meta-analysis.html#thm:sigmatrue">13.1</a> explains what happens if we set <code>sigma = TRUE</code>.</p>
<p>As theory predicts, the overall effect from these studies has a positive sign.</p>
<p>One advantage of such a meta-analysis is that the posterior can now be used as an informative prior for a future study. This is especially important when doing an analysis using Bayes factors. But this meta-analysis posterior could also be used as an informative prior in a future experiment; that would allow the researcher to build on what is known so far from published studies.</p>

<div class="extra">

<div class="theorem">
<span id="thm:sigmatrue" class="theorem"><strong>Box 13.1  </strong></span><strong>What happens if we set <code>sigma = TRUE</code>?</strong>
</div>
<p>If we set <code>sigma = TRUE</code>, we won’t be able to get estimates for <span class="math inline">\(\zeta_{n}\)</span>, since they are implicitly handled. The model presented formally in <a href="meta-analysis.html#eq:ma0">(13.1)</a> is equivalent to the following one in <a href="meta-analysis.html#eq:ma2">(13.2)</a>. We derive it later in section <a href="meta-analysis.html#sec:stanma">13.1.1.2</a>. A critical difference is that <span class="math inline">\(\zeta_n\)</span> does not appear anymore.</p>
<p><span class="math display" id="eq:ma2">\[\begin{equation}
\begin{aligned}
\text{effect}_n \sim &amp; Normal(\zeta_n, \sqrt{\tau^2 + SE_n^2} )\\
\zeta \sim &amp; Normal(0,100)\\
 \tau \sim &amp; Normal_+(0,100) 
\end{aligned}
\tag{13.2}
\end{equation}\]</span></p>
<p>We can fit this in <code>brms</code> as follows. Importantly, in this model specification, one should not include the + <code>(1 | study_id)</code>, and the prior for <span class="math inline">\(\tau\)</span> should now be specified to <code>sigma</code>.</p>
<div class="sourceCode" id="cb680"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb680-1" data-line-number="1">priors2 &lt;-<span class="st"> </span><span class="kw">c</span>(</a>
<a class="sourceLine" id="cb680-2" data-line-number="2">  <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">100</span>), <span class="dt">class =</span> Intercept),</a>
<a class="sourceLine" id="cb680-3" data-line-number="3">  <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">100</span>), <span class="dt">class =</span> sigma)</a>
<a class="sourceLine" id="cb680-4" data-line-number="4">)</a>
<a class="sourceLine" id="cb680-5" data-line-number="5">fit_sbi_sigma &lt;-<span class="st"> </span><span class="kw">brm</span>(effect <span class="op">|</span><span class="st"> </span><span class="kw">resp_se</span>(<span class="st">`</span><span class="dt">SE</span><span class="st">`</span>, <span class="dt">sigma =</span> <span class="ot">TRUE</span>) <span class="op">~</span><span class="st"> </span><span class="dv">1</span>,</a>
<a class="sourceLine" id="cb680-6" data-line-number="6">  <span class="dt">data =</span> df_sbi,</a>
<a class="sourceLine" id="cb680-7" data-line-number="7">  <span class="dt">prior =</span> priors2,</a>
<a class="sourceLine" id="cb680-8" data-line-number="8">  <span class="dt">control =</span> <span class="kw">list</span>(</a>
<a class="sourceLine" id="cb680-9" data-line-number="9">    <span class="dt">adapt_delta =</span> <span class="fl">.999</span>,</a>
<a class="sourceLine" id="cb680-10" data-line-number="10">    <span class="dt">max_treedepth =</span> <span class="dv">12</span></a>
<a class="sourceLine" id="cb680-11" data-line-number="11">  )</a>
<a class="sourceLine" id="cb680-12" data-line-number="12">)</a></code></pre></div>
<p>There are slight differences with <code>fit_sbi</code> due to the different parametrization and the sampling process, but the results are very similar:</p>
<div class="sourceCode" id="cb681"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb681-1" data-line-number="1"><span class="kw">posterior_summary</span>(fit_sbi_sigma,</a>
<a class="sourceLine" id="cb681-2" data-line-number="2">                  <span class="dt">pars =</span> <span class="kw">c</span>(<span class="st">&quot;b_Intercept&quot;</span>, <span class="st">&quot;sigma&quot;</span>))</a></code></pre></div>
<pre><code>##             Estimate Est.Error  Q2.5 Q97.5
## b_Intercept     13.7      6.86 2.611  30.3
## sigma           12.1      8.04 0.861  31.7</code></pre>
<p>If we are not interested in the underlying effects in each study, this parametrization of the meta analysis can be faster and more robust (i.e., it has less potential convergence issues). A major drawback is that we can no longer display a forest plot as we do in <a href="meta-analysis.html#fig:forest">13.1</a>.</p>
</div>
<p>Another interesting by-product of a random-effects meta-analysis is the possibility of displaying a forest plot (Figure <a href="meta-analysis.html#fig:forest">13.1</a>). A forest plot shows the meta analytic estimate (the parameter <code>b_Intercept</code> in brms) alongside the original estimates effect<span class="math inline">\(_n\)</span> (and their SE<span class="math inline">\(_n\)</span>) and the posterior distributions of the <span class="math inline">\(\zeta_n\)</span> for each study (we reconstruct these estimates by adding <code>b_Intercept</code> to the parameters starting with <code>r_</code> in <code>brms</code>). The original estimates are the ones fed to the model as data and the posterior distributions of the <span class="math inline">\(\zeta_n\)</span> are calculated, as in previous hierarchical models, after the information from all studies is pooled together. The <span class="math inline">\(\zeta_n\)</span> estimates are shrunken estimates of each study’s (unknown) true effect, shrunken towards the grand mean <span class="math inline">\(\zeta\)</span>, and weighted by the standard error observed in each study <span class="math inline">\(n\)</span>. The <span class="math inline">\(\zeta_n\)</span> for a particular study is shrunk more towards the grand mean <span class="math inline">\(\zeta\)</span> when the study’s standard error is large (i.e., when the estimate is very imprecise). The code below shows how to build a forest plot step by step.</p>

<div class="sourceCode" id="cb683"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb683-1" data-line-number="1"><span class="co"># First, change the format of the data</span></a>
<a class="sourceLine" id="cb683-2" data-line-number="2"><span class="co"># so that it looks like the output of brms</span></a>
<a class="sourceLine" id="cb683-3" data-line-number="3">df_sbi &lt;-<span class="st"> </span>df_sbi <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb683-4" data-line-number="4"><span class="st">  </span><span class="kw">mutate</span>(</a>
<a class="sourceLine" id="cb683-5" data-line-number="5">    <span class="dt">Q2.5 =</span> effect <span class="op">-</span><span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>SE,</a>
<a class="sourceLine" id="cb683-6" data-line-number="6">    <span class="dt">Q97.5 =</span> effect <span class="op">+</span><span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>SE,</a>
<a class="sourceLine" id="cb683-7" data-line-number="7">    <span class="dt">Estimate =</span> effect,</a>
<a class="sourceLine" id="cb683-8" data-line-number="8">    <span class="dt">type =</span> <span class="st">&quot;original&quot;</span></a>
<a class="sourceLine" id="cb683-9" data-line-number="9">  )</a>
<a class="sourceLine" id="cb683-10" data-line-number="10"></a>
<a class="sourceLine" id="cb683-11" data-line-number="11"><span class="co"># Extract the meta-analytical estimate:</span></a>
<a class="sourceLine" id="cb683-12" data-line-number="12">df_Intercept &lt;-<span class="st"> </span><span class="kw">posterior_summary</span>(fit_sbi,</a>
<a class="sourceLine" id="cb683-13" data-line-number="13">                                  <span class="dt">pars =</span> <span class="kw">c</span>(<span class="st">&quot;b_Intercept&quot;</span>)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb683-14" data-line-number="14"><span class="st">  </span><span class="kw">as.data.frame</span>() <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb683-15" data-line-number="15"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">publication =</span> <span class="st">&quot;M.A. estimate&quot;</span>, <span class="dt">type =</span> <span class="st">&quot;&quot;</span>)</a>
<a class="sourceLine" id="cb683-16" data-line-number="16"></a>
<a class="sourceLine" id="cb683-17" data-line-number="17"><span class="co"># For the pooled estimated effect of the individual studies</span></a>
<a class="sourceLine" id="cb683-18" data-line-number="18"><span class="co"># we need to do the following:</span></a>
<a class="sourceLine" id="cb683-19" data-line-number="19"><span class="co"># meta-analytical estimate (intercept) + adjustments:</span></a>
<a class="sourceLine" id="cb683-20" data-line-number="20"><span class="co"># 1. extract the meta-analytical estimate:</span></a>
<a class="sourceLine" id="cb683-21" data-line-number="21">intercept &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw">posterior_samples</span>(fit_sbi)<span class="op">$</span>b_Intercept)</a>
<a class="sourceLine" id="cb683-22" data-line-number="22"><span class="co"># 2. extract the adjustments</span></a>
<a class="sourceLine" id="cb683-23" data-line-number="23">adj_names &lt;-<span class="st"> </span><span class="kw">paste0</span>(<span class="st">&quot;r_study_id[&quot;</span>,</a>
<a class="sourceLine" id="cb683-24" data-line-number="24">                    <span class="kw">unique</span>(df_sbi<span class="op">$</span>study_id),</a>
<a class="sourceLine" id="cb683-25" data-line-number="25">                    <span class="st">&quot;,Intercept]&quot;</span>)</a>
<a class="sourceLine" id="cb683-26" data-line-number="26">adj &lt;-<span class="st"> </span><span class="kw">as.matrix</span>(<span class="kw">posterior_samples</span>(fit_sbi)[adj_names])</a>
<a class="sourceLine" id="cb683-27" data-line-number="27"><span class="co"># 3. add them:</span></a>
<a class="sourceLine" id="cb683-28" data-line-number="28">by_study &lt;-<span class="st"> </span><span class="kw">as_tibble</span>(intercept <span class="op">+</span><span class="st"> </span>adj)</a>
<a class="sourceLine" id="cb683-29" data-line-number="29"><span class="co"># Summarize them by getting a table with the mean and the</span></a>
<a class="sourceLine" id="cb683-30" data-line-number="30"><span class="co"># quantiles for each column and then binding them.</span></a>
<a class="sourceLine" id="cb683-31" data-line-number="31">df_model &lt;-<span class="st"> </span><span class="kw">lapply</span>(by_study, <span class="cf">function</span>(x) {</a>
<a class="sourceLine" id="cb683-32" data-line-number="32">  <span class="kw">tibble</span>(</a>
<a class="sourceLine" id="cb683-33" data-line-number="33">    <span class="dt">Estimate =</span> <span class="kw">mean</span>(x),</a>
<a class="sourceLine" id="cb683-34" data-line-number="34">    <span class="dt">Q2.5 =</span> <span class="kw">quantile</span>(x, <span class="fl">.025</span>),</a>
<a class="sourceLine" id="cb683-35" data-line-number="35">    <span class="dt">Q97.5 =</span> <span class="kw">quantile</span>(x, <span class="fl">.975</span>)</a>
<a class="sourceLine" id="cb683-36" data-line-number="36">  )</a>
<a class="sourceLine" id="cb683-37" data-line-number="37">}) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb683-38" data-line-number="38"><span class="st">  </span><span class="kw">bind_rows</span>() <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb683-39" data-line-number="39"><span class="st">  </span><span class="co"># Add a column to identify the posteriors,</span></a>
<a class="sourceLine" id="cb683-40" data-line-number="40"><span class="st">  </span><span class="co"># and another column to id the publication:</span></a>
<a class="sourceLine" id="cb683-41" data-line-number="41"><span class="st">  </span><span class="kw">mutate</span>(</a>
<a class="sourceLine" id="cb683-42" data-line-number="42">    <span class="dt">type =</span> <span class="st">&quot;adjusted&quot;</span>,</a>
<a class="sourceLine" id="cb683-43" data-line-number="43">    <span class="dt">publication =</span> df_sbi<span class="op">$</span>publication</a>
<a class="sourceLine" id="cb683-44" data-line-number="44">  )</a>
<a class="sourceLine" id="cb683-45" data-line-number="45"><span class="co"># Bind the original data,</span></a>
<a class="sourceLine" id="cb683-46" data-line-number="46"><span class="co"># the adjusted estimates and the m.a. estimate:</span></a>
<a class="sourceLine" id="cb683-47" data-line-number="47"><span class="kw">bind_rows</span>(df_sbi, df_model, df_Intercept) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb683-48" data-line-number="48"><span class="st">  </span><span class="co"># Plot:</span></a>
<a class="sourceLine" id="cb683-49" data-line-number="49"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(</a>
<a class="sourceLine" id="cb683-50" data-line-number="50">    <span class="dt">x =</span> Estimate,</a>
<a class="sourceLine" id="cb683-51" data-line-number="51">    <span class="dt">y =</span> publication,</a>
<a class="sourceLine" id="cb683-52" data-line-number="52">    <span class="dt">xmin =</span> Q2<span class="fl">.5</span>,</a>
<a class="sourceLine" id="cb683-53" data-line-number="53">    <span class="dt">xmax =</span> Q97<span class="fl">.5</span>,</a>
<a class="sourceLine" id="cb683-54" data-line-number="54">    <span class="dt">color =</span> type</a>
<a class="sourceLine" id="cb683-55" data-line-number="55">  )) <span class="op">+</span></a>
<a class="sourceLine" id="cb683-56" data-line-number="56"><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">position =</span> <span class="kw">position_dodge</span>(.<span class="dv">5</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb683-57" data-line-number="57"><span class="st">  </span><span class="kw">geom_errorbarh</span>(<span class="dt">position =</span> <span class="kw">position_dodge</span>(.<span class="dv">5</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb683-58" data-line-number="58"><span class="st">  </span><span class="co"># Add the meta-analytical estimate and CrI</span></a>
<a class="sourceLine" id="cb683-59" data-line-number="59"><span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> df_Intercept<span class="op">$</span>Q2<span class="fl">.5</span>,</a>
<a class="sourceLine" id="cb683-60" data-line-number="60">             <span class="dt">linetype =</span> <span class="st">&quot;dashed&quot;</span>,</a>
<a class="sourceLine" id="cb683-61" data-line-number="61">             <span class="dt">alpha =</span> <span class="fl">.3</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb683-62" data-line-number="62"><span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> df_Intercept<span class="op">$</span>Q97<span class="fl">.5</span>,</a>
<a class="sourceLine" id="cb683-63" data-line-number="63">             <span class="dt">linetype =</span> <span class="st">&quot;dashed&quot;</span>,</a>
<a class="sourceLine" id="cb683-64" data-line-number="64">             <span class="dt">alpha =</span> <span class="fl">.3</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb683-65" data-line-number="65"><span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> df_Intercept<span class="op">$</span>Estimate,</a>
<a class="sourceLine" id="cb683-66" data-line-number="66">             <span class="dt">linetype =</span> <span class="st">&quot;dashed&quot;</span>,</a>
<a class="sourceLine" id="cb683-67" data-line-number="67">             <span class="dt">alpha =</span> <span class="fl">.5</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb683-68" data-line-number="68"><span class="st">  </span><span class="kw">scale_color_discrete</span>(<span class="dt">breaks =</span> <span class="kw">c</span>(<span class="st">&quot;adjusted&quot;</span>,<span class="st">&quot;original&quot;</span>))</a></code></pre></div>
<div class="figure"><span id="fig:forest"></span>
<img src="bookdown_files/figure-html/forest-1.svg" alt="Forest plot showing the original and the adjusted estimates computed from each study from the random-effects meta-analysis. The error bars on the original estimates show 95% confidence intervals, and those on the adjusted estimates show 95% credible intervals." width="672" />
<p class="caption">
FIGURE 13.1: Forest plot showing the original and the adjusted estimates computed from each study from the random-effects meta-analysis. The error bars on the original estimates show 95% confidence intervals, and those on the adjusted estimates show 95% credible intervals.
</p>
</div>
<p>It is important to keep in mind that a meta-analysis is always going to yield biased estimates as long as we have publication bias: if a field has a tendency to allow only “big news” studies to be published, then the literature that will appear in the public domain will be biased, and any meta-analysis based on such information will be biased. Despite this limitation, a meta-analysis is still a useful way to synthesize the known evidence; one just has to remember that the estimate from the meta-analysis is likely to be biased.</p>
</div>
<div id="sec:stanma" class="section level4">
<h4><span class="header-section-number">13.1.1.2</span> Stan version of the meta-analysis model</h4>
<p>Even though <code>brms</code> can handle meta-analyses, fitting them in Stan allows us for more flexibility, which might be necessary in some cases. As a first attempt we could build a model that follows closely the formal specification given in <a href="meta-analysis.html#eq:ma0">(13.1)</a>.</p>
<pre class="stan"><code>data {
  int&lt;lower=1&gt; N;
  vector[N] effect;
  vector[N] SE;
  vector[N] study_id;
}
parameters {
  real zeta;
  real&lt;lower = 0&gt; tau;
  vector[N] zeta_n;
}
model {
  target += normal_lpdf(effect| zeta_n, SE);
  target += normal_lpdf(zeta_n | zeta, tau);
  target += normal_lpdf(zeta | 0, 100);
  target += normal_lpdf(tau | 0, 100)
    - normal_lccdf(0 | 0, 100);
}</code></pre>
<p>Fit the model as follows:</p>
<div class="sourceCode" id="cb685"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb685-1" data-line-number="1">ma0 &lt;-<span class="st"> </span><span class="kw">system.file</span>(<span class="st">&quot;stan_models&quot;</span>,</a>
<a class="sourceLine" id="cb685-2" data-line-number="2">                   <span class="st">&quot;meta-analysis0.stan&quot;</span>,</a>
<a class="sourceLine" id="cb685-3" data-line-number="3">                   <span class="dt">package =</span> <span class="st">&quot;bcogsci&quot;</span>)</a>
<a class="sourceLine" id="cb685-4" data-line-number="4">ls_sbi &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">N =</span> <span class="kw">nrow</span>(df_sbi),</a>
<a class="sourceLine" id="cb685-5" data-line-number="5">               <span class="dt">effect =</span> df_sbi<span class="op">$</span>effect,</a>
<a class="sourceLine" id="cb685-6" data-line-number="6">               <span class="dt">SE =</span> df_sbi<span class="op">$</span>SE,</a>
<a class="sourceLine" id="cb685-7" data-line-number="7">               <span class="dt">study_id =</span> df_sbi<span class="op">$</span>study_id)</a>
<a class="sourceLine" id="cb685-8" data-line-number="8">fit_sbi0 &lt;-<span class="st"> </span><span class="kw">stan</span>(</a>
<a class="sourceLine" id="cb685-9" data-line-number="9">  <span class="dt">file =</span> ma0,</a>
<a class="sourceLine" id="cb685-10" data-line-number="10">  <span class="dt">data =</span> ls_sbi,</a>
<a class="sourceLine" id="cb685-11" data-line-number="11">   <span class="dt">control =</span> <span class="kw">list</span>(</a>
<a class="sourceLine" id="cb685-12" data-line-number="12">    <span class="dt">adapt_delta =</span> <span class="fl">.999</span>,</a>
<a class="sourceLine" id="cb685-13" data-line-number="13">    <span class="dt">max_treedepth =</span> <span class="dv">12</span></a>
<a class="sourceLine" id="cb685-14" data-line-number="14">  )</a>
<a class="sourceLine" id="cb685-15" data-line-number="15">)</a></code></pre></div>
<pre><code>## Warning: There were 175 divergent transitions after warmup. See
## http://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup
## to find out why this is a problem and how to eliminate them.</code></pre>
<pre><code>## Warning: There were 17 transitions after warmup that exceeded the maximum treedepth. Increase max_treedepth above 12. See
## http://mc-stan.org/misc/warnings.html#maximum-treedepth-exceeded</code></pre>
<pre><code>## Warning: There were 1 chains where the estimated Bayesian Fraction of Missing Information was low. See
## http://mc-stan.org/misc/warnings.html#bfmi-low</code></pre>
<pre><code>## Warning: Examine the pairs() plot to diagnose sampling problems</code></pre>
<pre><code>## Warning: The largest R-hat is 1.07, indicating chains have not mixed.
## Running the chains for more iterations may help. See
## http://mc-stan.org/misc/warnings.html#r-hat</code></pre>
<pre><code>## Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable.
## Running the chains for more iterations may help. See
## http://mc-stan.org/misc/warnings.html#bulk-ess</code></pre>
<pre><code>## Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable.
## Running the chains for more iterations may help. See
## http://mc-stan.org/misc/warnings.html#tail-ess</code></pre>
<p>We see that there are warnings. We can use pairs plots as in <a href="hierarchical-models-with-stan.html#sec:uncorrstan">11.1.2</a> to uncover pathologies in the sampling. Here we see the samples of <code>zeta</code> and <code>tau</code> are highly correlated:</p>
<div class="sourceCode" id="cb693"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb693-1" data-line-number="1"><span class="kw">pairs</span>(fit_sbi0, <span class="dt">pars =</span> <span class="kw">c</span>(<span class="st">&quot;zeta&quot;</span>, <span class="st">&quot;tau&quot;</span>))</a></code></pre></div>
<p><img src="bookdown_files/figure-html/unnamed-chunk-374-1.svg" width="672" /></p>
<p>We face a similar problem as we faced in <a href="hierarchical-models-with-stan.html#sec:uncorrstan">11.1.2</a>, namely, the sampler cannot properly explore the neck of the funnel-shaped space because, because of the strong correlation between the parameters. The solution is, as in <a href="hierarchical-models-with-stan.html#sec:uncorrstan">11.1.2</a>, a non-centered parametrization. We re-write <a href="meta-analysis.html#eq:ma0">(13.1)</a> as follows:</p>
<p><span class="math display" id="eq:ma1">\[\begin{equation}
\begin{aligned}
z_n &amp; \sim Normal(0, 1)\\
\zeta_n &amp;= z_n \cdot \tau + \zeta \\
\text{effect}_n &amp; \sim  Normal(\zeta_n, SE_n)\\ 
\zeta &amp;\sim Normal(0,100)\\
\tau &amp;\sim  Normal_+(0,100) 
\end{aligned}
\tag{13.3}
\end{equation}\]</span></p>
<p>This works because if <span class="math inline">\(X \sim Normal(a, b)\)</span> and <span class="math inline">\(Y \sim Normal(0, 1)\)</span>, then <span class="math inline">\(X = a + Y \cdot b\)</span>. You can re-visit chapter <a href="hierarchical-models-with-stan.html#sec:uncorrstan">11.1.2</a> for more details.</p>
<p>We translate <a href="meta-analysis.html#eq:ma1">(13.3)</a> into Stan code as follows in <code>meta-analysis1.stan</code>:</p>
<pre class="stan"><code>data {
  int&lt;lower=1&gt; N;
  vector[N] effect;
  vector[N] SE;
  vector[N] study_id;
}
parameters {
  real zeta;
  real&lt;lower = 0&gt; tau;
  vector[N] z;
}
transformed parameters {
  vector[N] zeta_n = z * tau + zeta;
}
model {
  target += normal_lpdf(effect| zeta_n, SE);
  target += std_normal_lpdf(z);
  target += normal_lpdf(zeta | 0, 100);
  target += normal_lpdf(tau | 0, 100)
    - normal_lccdf(0 | 0, 100);
}</code></pre>
<p>The model converges with values virtually identical to the ones of the <code>brms</code> model.</p>
<div class="sourceCode" id="cb695"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb695-1" data-line-number="1">ma1 &lt;-<span class="st"> </span><span class="kw">system.file</span>(<span class="st">&quot;stan_models&quot;</span>,</a>
<a class="sourceLine" id="cb695-2" data-line-number="2">                   <span class="st">&quot;meta-analysis1.stan&quot;</span>,</a>
<a class="sourceLine" id="cb695-3" data-line-number="3">                   <span class="dt">package =</span> <span class="st">&quot;bcogsci&quot;</span>) </a>
<a class="sourceLine" id="cb695-4" data-line-number="4">fit_sbi1 &lt;-<span class="st"> </span><span class="kw">stan</span>(</a>
<a class="sourceLine" id="cb695-5" data-line-number="5">  <span class="dt">file =</span> ma1,</a>
<a class="sourceLine" id="cb695-6" data-line-number="6">  <span class="dt">data =</span> ls_sbi,</a>
<a class="sourceLine" id="cb695-7" data-line-number="7">   <span class="dt">control =</span> <span class="kw">list</span>(</a>
<a class="sourceLine" id="cb695-8" data-line-number="8">    <span class="dt">adapt_delta =</span> <span class="fl">.999</span>,</a>
<a class="sourceLine" id="cb695-9" data-line-number="9">    <span class="dt">max_treedepth =</span> <span class="dv">12</span></a>
<a class="sourceLine" id="cb695-10" data-line-number="10">  )</a>
<a class="sourceLine" id="cb695-11" data-line-number="11">)</a></code></pre></div>
<div class="sourceCode" id="cb696"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb696-1" data-line-number="1"><span class="kw">print</span>(fit_sbi1, <span class="dt">pars =</span> <span class="kw">c</span>(<span class="st">&quot;zeta&quot;</span>, <span class="st">&quot;tau&quot;</span>))</a></code></pre></div>
<pre><code>##      mean 2.5% 97.5% n_eff Rhat
## zeta 13.2 3.03  27.0  1306    1
## tau  11.5 0.60  29.2   996    1</code></pre>
<p>We can also reparametrize the model slightly differently, if we set <span class="math inline">\(U_{n} \sim Normal(0 , SE_n)\)</span> then,</p>
<p><span class="math display">\[\begin{equation}
\text{effect}_n \sim  U_n + \zeta_n 
\end{equation}\]</span></p>
<p>Then, given that <span class="math inline">\(\zeta_n \sim Normal(\zeta, \tau)\)</span>,</p>
<p><span class="math display" id="eq:ma2-again">\[\begin{equation}
\text{effect}_n \sim Normal(\zeta, \sqrt{SE^2 + \tau^2}) \tag{13.4}
\end{equation}\]</span></p>
<p>This is equivalent to the <code>brms</code> model where <code>sigma = TRUE</code>. This is possible because of the following property of the normal distribution:</p>
<p><span class="math display" id="eq:masquare">\[\begin{equation}
\begin{aligned}
 X &amp;\sim Normal(\mu_{X}, \sigma_X)\\
 Y &amp;\sim Normal(\mu _{Y},\sigma _{Y})\\
 Z &amp; = X + Y \text{then}\\
 Z &amp;\sim Normal(\mu _{X}+\mu _{Y},\sqrt{\sigma_{X}^{2}+\sigma_{Y}^{2}})
 \end{aligned}
\tag{13.5}
 \end{equation}\]</span></p>
<p>As with <code>brms</code>, we lose the possibility of estimating the posterior of the true effect of the individual studies.</p>
<p>We write this in Stan as follows in <code>meta-analysis2.stan</code>:</p>
<pre class="stan"><code>data {
  int&lt;lower=1&gt; N;
  vector[N] effect;
  vector[N] SE;
  vector[N] study_id;
}
parameters {
  real zeta;
  real&lt;lower = 0&gt; tau;
}
model {
  target += normal_lpdf(effect| zeta, sqrt(square(SE) + square(tau)));
  target += normal_lpdf(zeta | 0, 100);
  target += normal_lpdf(tau | 0, 100)
    - normal_lccdf(0 | 0, 100);
}</code></pre>
<p>Fit it below:</p>
<div class="sourceCode" id="cb699"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb699-1" data-line-number="1">ma2 &lt;-<span class="st"> </span><span class="kw">system.file</span>(<span class="st">&quot;stan_models&quot;</span>,</a>
<a class="sourceLine" id="cb699-2" data-line-number="2">                   <span class="st">&quot;meta-analysis2.stan&quot;</span>,</a>
<a class="sourceLine" id="cb699-3" data-line-number="3">                   <span class="dt">package =</span> <span class="st">&quot;bcogsci&quot;</span>)</a>
<a class="sourceLine" id="cb699-4" data-line-number="4">fit_sbi2 &lt;-<span class="st"> </span><span class="kw">stan</span>(</a>
<a class="sourceLine" id="cb699-5" data-line-number="5">  <span class="dt">file =</span> ma2,</a>
<a class="sourceLine" id="cb699-6" data-line-number="6">  <span class="dt">data =</span> ls_sbi,</a>
<a class="sourceLine" id="cb699-7" data-line-number="7">  <span class="dt">control =</span> <span class="kw">list</span>(<span class="dt">adapt_delta =</span> <span class="fl">.9</span>)</a>
<a class="sourceLine" id="cb699-8" data-line-number="8">)</a></code></pre></div>
<div class="sourceCode" id="cb700"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb700-1" data-line-number="1"><span class="kw">print</span>(fit_sbi2, <span class="dt">pars =</span> <span class="kw">c</span>(<span class="st">&quot;zeta&quot;</span>, <span class="st">&quot;tau&quot;</span>))</a></code></pre></div>
<pre><code>##      mean 2.5% 97.5% n_eff Rhat
## zeta 12.9 2.51  26.3  1078    1
## tau  11.2 0.45  28.6  1250    1</code></pre>
</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-JaegerEngelmannVasishth2017">
<p>Jäger, Lena A., Felix Engelmann, and Shravan Vasishth. 2017. “Similarity-Based Interference in Sentence Comprehension: Literature review and Bayesian meta-analysis.” <em>Journal of Memory and Language</em> 94: 316–39. <a href="https://doi.org/https://doi.org/10.1016/j.jml.2017.01.004" class="uri">https://doi.org/https://doi.org/10.1016/j.jml.2017.01.004</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="ch-remame.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="measurement-error-models.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/lunr.js"></script>
<script src="libs/gitbook/js/clipboard.min.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script src="libs/gitbook/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown/edit/master/inst/examples/13-REMA-ME.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown.pdf", "bookdown.epub", "bookdown.mobi"],
"toc": {
"collapse": "none"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
