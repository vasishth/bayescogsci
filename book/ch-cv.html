<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 16 Cross-validation | An Introduction to Bayesian Data Analysis for Cognitive Science</title>
  <meta name="description" content="An introduction to Bayesian data analysis for Cognitive Science." />
  <meta name="generator" content="bookdown 0.28 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 16 Cross-validation | An Introduction to Bayesian Data Analysis for Cognitive Science" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="https://vasishth.github.io/Bayes_CogSci//images/temporarycover.jpg" />
  <meta property="og:description" content="An introduction to Bayesian data analysis for Cognitive Science." />
  <meta name="github-repo" content="https://github.com/vasishth/Bayes_CogSci" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 16 Cross-validation | An Introduction to Bayesian Data Analysis for Cognitive Science" />
  
  <meta name="twitter:description" content="An introduction to Bayesian data analysis for Cognitive Science." />
  <meta name="twitter:image" content="https://vasishth.github.io/Bayes_CogSci//images/temporarycover.jpg" />

<meta name="author" content="Bruno Nicenboim, Daniel Schad, and Shravan Vasishth" />


<meta name="date" content="2023-02-18" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="ch-bf.html"/>
<link rel="next" href="ch-cogmod.html"/>
<script src="libs/jquery/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections/anchor-sections.js"></script>
<script>
// FOLD code from 
// https://github.com/bblodfon/rtemps/blob/master/docs/bookdown-lite/hide_code.html
/* ========================================================================
 * Bootstrap: transition.js v3.3.7
 * http://getbootstrap.com/javascript/#transitions
 * ========================================================================
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 * ======================================================================== */


+function ($) {
  'use strict';

  // CSS TRANSITION SUPPORT (Shoutout: http://www.modernizr.com/)
  // ============================================================

  function transitionEnd() {
    var el = document.createElement('bootstrap')

    var transEndEventNames = {
      WebkitTransition : 'webkitTransitionEnd',
      MozTransition    : 'transitionend',
      OTransition      : 'oTransitionEnd otransitionend',
      transition       : 'transitionend'
    }

    for (var name in transEndEventNames) {
      if (el.style[name] !== undefined) {
        return { end: transEndEventNames[name] }
      }
    }

    return false // explicit for ie8 (  ._.)
  }

  // http://blog.alexmaccaw.com/css-transitions
  $.fn.emulateTransitionEnd = function (duration) {
    var called = false
    var $el = this
    $(this).one('bsTransitionEnd', function () { called = true })
    var callback = function () { if (!called) $($el).trigger($.support.transition.end) }
    setTimeout(callback, duration)
    return this
  }

  $(function () {
    $.support.transition = transitionEnd()

    if (!$.support.transition) return

    $.event.special.bsTransitionEnd = {
      bindType: $.support.transition.end,
      delegateType: $.support.transition.end,
      handle: function (e) {
        if ($(e.target).is(this)) return e.handleObj.handler.apply(this, arguments)
      }
    }
  })

}(jQuery);
</script>
<script>
/* ========================================================================
 * Bootstrap: collapse.js v3.3.7
 * http://getbootstrap.com/javascript/#collapse
 * ========================================================================
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 * ======================================================================== */

/* jshint latedef: false */

+function ($) {
  'use strict';

  // COLLAPSE PUBLIC CLASS DEFINITION
  // ================================

  var Collapse = function (element, options) {
    this.$element      = $(element)
    this.options       = $.extend({}, Collapse.DEFAULTS, options)
    this.$trigger      = $('[data-toggle="collapse"][href="#' + element.id + '"],' +
                           '[data-toggle="collapse"][data-target="#' + element.id + '"]')
    this.transitioning = null

    if (this.options.parent) {
      this.$parent = this.getParent()
    } else {
      this.addAriaAndCollapsedClass(this.$element, this.$trigger)
    }

    if (this.options.toggle) this.toggle()
  }

  Collapse.VERSION  = '3.3.7'

  Collapse.TRANSITION_DURATION = 350

  Collapse.DEFAULTS = {
    toggle: true
  }

  Collapse.prototype.dimension = function () {
    var hasWidth = this.$element.hasClass('width')
    return hasWidth ? 'width' : 'height'
  }

  Collapse.prototype.show = function () {
    if (this.transitioning || this.$element.hasClass('in')) return

    var activesData
    var actives = this.$parent && this.$parent.children('.panel').children('.in, .collapsing')

    if (actives && actives.length) {
      activesData = actives.data('bs.collapse')
      if (activesData && activesData.transitioning) return
    }

    var startEvent = $.Event('show.bs.collapse')
    this.$element.trigger(startEvent)
    if (startEvent.isDefaultPrevented()) return

    if (actives && actives.length) {
      Plugin.call(actives, 'hide')
      activesData || actives.data('bs.collapse', null)
    }

    var dimension = this.dimension()

    this.$element
      .removeClass('collapse')
      .addClass('collapsing')[dimension](0)
      .attr('aria-expanded', true)

    this.$trigger
      .removeClass('collapsed')
      .attr('aria-expanded', true)

    this.transitioning = 1

    var complete = function () {
      this.$element
        .removeClass('collapsing')
        .addClass('collapse in')[dimension]('')
      this.transitioning = 0
      this.$element
        .trigger('shown.bs.collapse')
    }

    if (!$.support.transition) return complete.call(this)

    var scrollSize = $.camelCase(['scroll', dimension].join('-'))

    this.$element
      .one('bsTransitionEnd', $.proxy(complete, this))
      .emulateTransitionEnd(Collapse.TRANSITION_DURATION)[dimension](this.$element[0][scrollSize])
  }

  Collapse.prototype.hide = function () {
    if (this.transitioning || !this.$element.hasClass('in')) return

    var startEvent = $.Event('hide.bs.collapse')
    this.$element.trigger(startEvent)
    if (startEvent.isDefaultPrevented()) return

    var dimension = this.dimension()

    this.$element[dimension](this.$element[dimension]())[0].offsetHeight

    this.$element
      .addClass('collapsing')
      .removeClass('collapse in')
      .attr('aria-expanded', false)

    this.$trigger
      .addClass('collapsed')
      .attr('aria-expanded', false)

    this.transitioning = 1

    var complete = function () {
      this.transitioning = 0
      this.$element
        .removeClass('collapsing')
        .addClass('collapse')
        .trigger('hidden.bs.collapse')
    }

    if (!$.support.transition) return complete.call(this)

    this.$element
      [dimension](0)
      .one('bsTransitionEnd', $.proxy(complete, this))
      .emulateTransitionEnd(Collapse.TRANSITION_DURATION)
  }

  Collapse.prototype.toggle = function () {
    this[this.$element.hasClass('in') ? 'hide' : 'show']()
  }

  Collapse.prototype.getParent = function () {
    return $(this.options.parent)
      .find('[data-toggle="collapse"][data-parent="' + this.options.parent + '"]')
      .each($.proxy(function (i, element) {
        var $element = $(element)
        this.addAriaAndCollapsedClass(getTargetFromTrigger($element), $element)
      }, this))
      .end()
  }

  Collapse.prototype.addAriaAndCollapsedClass = function ($element, $trigger) {
    var isOpen = $element.hasClass('in')

    $element.attr('aria-expanded', isOpen)
    $trigger
      .toggleClass('collapsed', !isOpen)
      .attr('aria-expanded', isOpen)
  }

  function getTargetFromTrigger($trigger) {
    var href
    var target = $trigger.attr('data-target')
      || (href = $trigger.attr('href')) && href.replace(/.*(?=#[^\s]+$)/, '') // strip for ie7

    return $(target)
  }


  // COLLAPSE PLUGIN DEFINITION
  // ==========================

  function Plugin(option) {
    return this.each(function () {
      var $this   = $(this)
      var data    = $this.data('bs.collapse')
      var options = $.extend({}, Collapse.DEFAULTS, $this.data(), typeof option == 'object' && option)

      if (!data && options.toggle && /show|hide/.test(option)) options.toggle = false
      if (!data) $this.data('bs.collapse', (data = new Collapse(this, options)))
      if (typeof option == 'string') data[option]()
    })
  }

  var old = $.fn.collapse

  $.fn.collapse             = Plugin
  $.fn.collapse.Constructor = Collapse


  // COLLAPSE NO CONFLICT
  // ====================

  $.fn.collapse.noConflict = function () {
    $.fn.collapse = old
    return this
  }


  // COLLAPSE DATA-API
  // =================

  $(document).on('click.bs.collapse.data-api', '[data-toggle="collapse"]', function (e) {
    var $this   = $(this)

    if (!$this.attr('data-target')) e.preventDefault()

    var $target = getTargetFromTrigger($this)
    var data    = $target.data('bs.collapse')
    var option  = data ? 'toggle' : $this.data()

    Plugin.call($target, option)
  })

}(jQuery);
</script>
<script>
window.initializeCodeFolding = function(show) {

  // handlers for show-all and hide all
  $("#rmd-show-all-code").click(function() {
    // close the dropdown menu when an option is clicked
    $("#allCodeButton").dropdown("toggle");
    $('div.r-code-collapse').each(function() {
      $(this).collapse('show');
    });
  });
  $("#rmd-hide-all-code").click(function() {
    // close the dropdown menu when an option is clicked
    $("#allCodeButton").dropdown("toggle");
    $('div.r-code-collapse').each(function() {
      $(this).collapse('hide');
    });
  });

  // index for unique code element ids
  var currentIndex = 1;

  // select all R code blocks
  var rCodeBlocks = $('pre.sourceCode, pre.r, pre.python, pre.bash, pre.sql, pre.cpp, pre.stan');
  rCodeBlocks.each(function() {

    // if code block has been labeled with class `fold-show`, show the code on init!
    var classList = $(this).attr('class').split(/\s+/);
    for (var i = 0; i < classList.length; i++) {
    if (classList[i] === 'fold-show') {
        show = true;
      }
    }

    // create a collapsable div to wrap the code in
    var div = $('<div class="collapse r-code-collapse"></div>');
    if (show)
      div.addClass('in');
    var id = 'rcode-643E0F36' + currentIndex++;
    div.attr('id', id);
    $(this).before(div);
    $(this).detach().appendTo(div);

    // add a show code button right above
    var showCodeText = $('<span>' + (show ? 'Hide' : 'Code') + '</span>');
    var showCodeButton = $('<button type="button" class="btn btn-default btn-xs code-folding-btn pull-right"></button>');
    showCodeButton.append(showCodeText);
    showCodeButton
        .attr('data-toggle', 'collapse')
        .attr('data-target', '#' + id)
        .attr('aria-expanded', show)
        .attr('aria-controls', id);

    var buttonRow = $('<div class="row"></div>');
    var buttonCol = $('<div class="col-md-12"></div>');

    buttonCol.append(showCodeButton);
    buttonRow.append(buttonCol);

    div.before(buttonRow);

    // hack: return show to false, otherwise all next codeBlocks will be shown!
    show = false;

    // update state of button on show/hide
    div.on('hidden.bs.collapse', function () {
      showCodeText.text('Code');
    });
    div.on('show.bs.collapse', function () {
      showCodeText.text('Hide');
    });
  });

}
</script>
<script>
/* ========================================================================
 * Bootstrap: dropdown.js v3.3.7
 * http://getbootstrap.com/javascript/#dropdowns
 * ========================================================================
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 * ======================================================================== */


+function ($) {
  'use strict';

  // DROPDOWN CLASS DEFINITION
  // =========================

  var backdrop = '.dropdown-backdrop'
  var toggle   = '[data-toggle="dropdown"]'
  var Dropdown = function (element) {
    $(element).on('click.bs.dropdown', this.toggle)
  }

  Dropdown.VERSION = '3.3.7'

  function getParent($this) {
    var selector = $this.attr('data-target')

    if (!selector) {
      selector = $this.attr('href')
      selector = selector && /#[A-Za-z]/.test(selector) && selector.replace(/.*(?=#[^\s]*$)/, '') // strip for ie7
    }

    var $parent = selector && $(selector)

    return $parent && $parent.length ? $parent : $this.parent()
  }

  function clearMenus(e) {
    if (e && e.which === 3) return
    $(backdrop).remove()
    $(toggle).each(function () {
      var $this         = $(this)
      var $parent       = getParent($this)
      var relatedTarget = { relatedTarget: this }

      if (!$parent.hasClass('open')) return

      if (e && e.type == 'click' && /input|textarea/i.test(e.target.tagName) && $.contains($parent[0], e.target)) return

      $parent.trigger(e = $.Event('hide.bs.dropdown', relatedTarget))

      if (e.isDefaultPrevented()) return

      $this.attr('aria-expanded', 'false')
      $parent.removeClass('open').trigger($.Event('hidden.bs.dropdown', relatedTarget))
    })
  }

  Dropdown.prototype.toggle = function (e) {
    var $this = $(this)

    if ($this.is('.disabled, :disabled')) return

    var $parent  = getParent($this)
    var isActive = $parent.hasClass('open')

    clearMenus()

    if (!isActive) {
      if ('ontouchstart' in document.documentElement && !$parent.closest('.navbar-nav').length) {
        // if mobile we use a backdrop because click events don't delegate
        $(document.createElement('div'))
          .addClass('dropdown-backdrop')
          .insertAfter($(this))
          .on('click', clearMenus)
      }

      var relatedTarget = { relatedTarget: this }
      $parent.trigger(e = $.Event('show.bs.dropdown', relatedTarget))

      if (e.isDefaultPrevented()) return

      $this
        .trigger('focus')
        .attr('aria-expanded', 'true')

      $parent
        .toggleClass('open')
        .trigger($.Event('shown.bs.dropdown', relatedTarget))
    }

    return false
  }

  Dropdown.prototype.keydown = function (e) {
    if (!/(38|40|27|32)/.test(e.which) || /input|textarea/i.test(e.target.tagName)) return

    var $this = $(this)

    e.preventDefault()
    e.stopPropagation()

    if ($this.is('.disabled, :disabled')) return

    var $parent  = getParent($this)
    var isActive = $parent.hasClass('open')

    if (!isActive && e.which != 27 || isActive && e.which == 27) {
      if (e.which == 27) $parent.find(toggle).trigger('focus')
      return $this.trigger('click')
    }

    var desc = ' li:not(.disabled):visible a'
    var $items = $parent.find('.dropdown-menu' + desc)

    if (!$items.length) return

    var index = $items.index(e.target)

    if (e.which == 38 && index > 0)                 index--         // up
    if (e.which == 40 && index < $items.length - 1) index++         // down
    if (!~index)                                    index = 0

    $items.eq(index).trigger('focus')
  }


  // DROPDOWN PLUGIN DEFINITION
  // ==========================

  function Plugin(option) {
    return this.each(function () {
      var $this = $(this)
      var data  = $this.data('bs.dropdown')

      if (!data) $this.data('bs.dropdown', (data = new Dropdown(this)))
      if (typeof option == 'string') data[option].call($this)
    })
  }

  var old = $.fn.dropdown

  $.fn.dropdown             = Plugin
  $.fn.dropdown.Constructor = Dropdown


  // DROPDOWN NO CONFLICT
  // ====================

  $.fn.dropdown.noConflict = function () {
    $.fn.dropdown = old
    return this
  }


  // APPLY TO STANDARD DROPDOWN ELEMENTS
  // ===================================

  $(document)
    .on('click.bs.dropdown.data-api', clearMenus)
    .on('click.bs.dropdown.data-api', '.dropdown form', function (e) { e.stopPropagation() })
    .on('click.bs.dropdown.data-api', toggle, Dropdown.prototype.toggle)
    .on('keydown.bs.dropdown.data-api', toggle, Dropdown.prototype.keydown)
    .on('keydown.bs.dropdown.data-api', '.dropdown-menu', Dropdown.prototype.keydown)

}(jQuery);
</script>
<style type="text/css">
.code-folding-btn {
  margin-bottom: 4px;
}

.row { display: flex; }
.collapse { display: none; }
.in { display:block }
.pull-right > .dropdown-menu {
    right: 0;
    left: auto;
}

.dropdown-menu {
    position: absolute;
    top: 100%;
    left: 0;
    z-index: 1000;
    display: none;
    float: left;
    min-width: 160px;
    padding: 5px 0;
    margin: 2px 0 0;
    font-size: 14px;
    text-align: left;
    list-style: none;
    background-color: #fff;
    -webkit-background-clip: padding-box;
    background-clip: padding-box;
    border: 1px solid #ccc;
    border: 1px solid rgba(0,0,0,.15);
    border-radius: 4px;
    -webkit-box-shadow: 0 6px 12px rgba(0,0,0,.175);
    box-shadow: 0 6px 12px rgba(0,0,0,.175);
}

.open > .dropdown-menu {
    display: block;
    color: #ffffff;
    background-color: #ffffff;
    background-image: none;
    border-color: #92897e;
}

.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: 400;
  line-height: 1.42857143;
  color: #000000;
  white-space: nowrap;
}

.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  color: #ffffff;
  text-decoration: none;
  background-color: #e95420;
}

.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #ffffff;
  text-decoration: none;
  background-color: #e95420;
  outline: 0;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #aea79f;
}

.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  cursor: not-allowed;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
}

.btn {
  display: inline-block;
  margin-bottom: 1;
  font-weight: normal;
  text-align: center;
  white-space: nowrap;
  vertical-align: middle;
  -ms-touch-action: manipulation;
      touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  padding: 4px 8px;
  font-size: 14px;
  line-height: 1.42857143;
  border-radius: 4px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #ffffff;
  text-decoration: none;
}
.btn:active,
.btn.active {
  background-image: none;
  outline: 0;
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  filter: alpha(opacity=65);
  opacity: 0.65;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #ffffff;
  background-color: #aea79f; #important
  border-color: #aea79f;
}

.btn-default:focus,
.btn-default.focus {
  color: #ffffff;
  background-color: #978e83;
  border-color: #6f675e;
}

.btn-default:hover {
  color: #ffffff;
  background-color: #978e83;
  border-color: #92897e;
}
.btn-default:active,
.btn-default.active,
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-top-right-radius: 0;
  border-bottom-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-top-left-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-top-right-radius: 0;
  border-bottom-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-left-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-right: 8px;
  padding-left: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-right: 12px;
  padding-left: 12px;
}
.btn-group.open .dropdown-toggle {
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  box-shadow: none;
}

</style>
<script>
var str = '<div class="btn-group pull-right" style="position: fixed; right: 50px; top: 10px; z-index: 200"><button type="button" class="btn btn-default btn-xs dropdown-toggle" id="allCodeButton" data-toggle="dropdown" aria-haspopup="true" aria-expanded="true" data-_extension-text-contrast=""><span>Code</span> <span class="caret"></span></button><ul class="dropdown-menu" style="min-width: 50px;"><li><a id="rmd-show-all-code" href="#">Show All Code</a></li><li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li></ul></div>';
document.write(str);
</script>
<script>
$(document).ready(function () {
  window.initializeCodeFolding("show" === "hide");
});
</script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="css/style.css" type="text/css" />
<link rel="stylesheet" href="css/toc.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Bayesian Data Analysis for Cognitive Science (DRAFT)</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#why-read-this-book-and-what-is-its-target-audience"><i class="fa fa-check"></i>Why read this book, and what is its target audience?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#developing-the-right-mindset-for-this-book"><i class="fa fa-check"></i>Developing the right mindset for this book</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#how-to-read-this-book"><i class="fa fa-check"></i>How to read this book</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#some-conventions-used-in-this-book"><i class="fa fa-check"></i>Some conventions used in this book</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#online-materials"><i class="fa fa-check"></i>Online materials</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#software-needed"><i class="fa fa-check"></i>Software needed</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgments"><i class="fa fa-check"></i>Acknowledgments</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="about-the-authors.html"><a href="about-the-authors.html"><i class="fa fa-check"></i>About the Authors</a></li>
<li class="part"><span><b>I Foundational ideas</b></span></li>
<li class="chapter" data-level="1" data-path="ch-intro.html"><a href="ch-intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="ch-intro.html"><a href="ch-intro.html#introprob"><i class="fa fa-check"></i><b>1.1</b> Probability</a></li>
<li class="chapter" data-level="1.2" data-path="ch-intro.html"><a href="ch-intro.html#condprob"><i class="fa fa-check"></i><b>1.2</b> Conditional probability</a></li>
<li class="chapter" data-level="1.3" data-path="ch-intro.html"><a href="ch-intro.html#the-law-of-total-probability"><i class="fa fa-check"></i><b>1.3</b> The law of total probability</a></li>
<li class="chapter" data-level="1.4" data-path="ch-intro.html"><a href="ch-intro.html#sec-binomialcloze"><i class="fa fa-check"></i><b>1.4</b> Discrete random variables: An example using the binomial distribution</a><ul>
<li class="chapter" data-level="1.4.1" data-path="ch-intro.html"><a href="ch-intro.html#the-mean-and-variance-of-the-binomial-distribution"><i class="fa fa-check"></i><b>1.4.1</b> The mean and variance of the binomial distribution</a></li>
<li class="chapter" data-level="1.4.2" data-path="ch-intro.html"><a href="ch-intro.html#what-information-does-a-probability-distribution-provide"><i class="fa fa-check"></i><b>1.4.2</b> What information does a probability distribution provide?</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="ch-intro.html"><a href="ch-intro.html#continuous-random-variables-an-example-using-the-normal-distribution"><i class="fa fa-check"></i><b>1.5</b> Continuous random variables: An example using the normal distribution</a><ul>
<li class="chapter" data-level="1.5.1" data-path="ch-intro.html"><a href="ch-intro.html#an-important-distinction-probability-vs.density-in-a-continuous-random-variable"><i class="fa fa-check"></i><b>1.5.1</b> An important distinction: probability vs. density in a continuous random variable</a></li>
<li class="chapter" data-level="1.5.2" data-path="ch-intro.html"><a href="ch-intro.html#truncating-a-normal-distribution"><i class="fa fa-check"></i><b>1.5.2</b> Truncating a normal distribution</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="ch-intro.html"><a href="ch-intro.html#bivariate-and-multivariate-distributions"><i class="fa fa-check"></i><b>1.6</b> Bivariate and multivariate distributions</a><ul>
<li class="chapter" data-level="1.6.1" data-path="ch-intro.html"><a href="ch-intro.html#example-1-discrete-bivariate-distributions"><i class="fa fa-check"></i><b>1.6.1</b> Example 1: Discrete bivariate distributions</a></li>
<li class="chapter" data-level="1.6.2" data-path="ch-intro.html"><a href="ch-intro.html#sec-contbivar"><i class="fa fa-check"></i><b>1.6.2</b> Example 2: Continuous bivariate distributions</a></li>
<li class="chapter" data-level="1.6.3" data-path="ch-intro.html"><a href="ch-intro.html#sec-generatebivariatedata"><i class="fa fa-check"></i><b>1.6.3</b> Generate simulated bivariate (multivariate) data</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="ch-intro.html"><a href="ch-intro.html#sec-marginal"><i class="fa fa-check"></i><b>1.7</b> An important concept: The marginal likelihood (integrating out a parameter)</a></li>
<li class="chapter" data-level="1.8" data-path="ch-intro.html"><a href="ch-intro.html#summary-of-useful-r-functions-relating-to-distributions"><i class="fa fa-check"></i><b>1.8</b> Summary of useful R functions relating to distributions</a></li>
<li class="chapter" data-level="1.9" data-path="ch-intro.html"><a href="ch-intro.html#summary"><i class="fa fa-check"></i><b>1.9</b> Summary</a></li>
<li class="chapter" data-level="1.10" data-path="ch-intro.html"><a href="ch-intro.html#further-reading"><i class="fa fa-check"></i><b>1.10</b> Further reading</a></li>
<li class="chapter" data-level="1.11" data-path="ch-intro.html"><a href="ch-intro.html#sec-Foundationsexercises"><i class="fa fa-check"></i><b>1.11</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="ch-introBDA.html"><a href="ch-introBDA.html"><i class="fa fa-check"></i><b>2</b> Introduction to Bayesian data analysis</a><ul>
<li class="chapter" data-level="2.1" data-path="ch-introBDA.html"><a href="ch-introBDA.html#bayes-rule"><i class="fa fa-check"></i><b>2.1</b> Bayes’ rule</a></li>
<li class="chapter" data-level="2.2" data-path="ch-introBDA.html"><a href="ch-introBDA.html#sec-analytical"><i class="fa fa-check"></i><b>2.2</b> Deriving the posterior using Bayes’ rule: An analytical example</a><ul>
<li class="chapter" data-level="2.2.1" data-path="ch-introBDA.html"><a href="ch-introBDA.html#choosing-a-likelihood"><i class="fa fa-check"></i><b>2.2.1</b> Choosing a likelihood</a></li>
<li class="chapter" data-level="2.2.2" data-path="ch-introBDA.html"><a href="ch-introBDA.html#sec-choosepriortheta"><i class="fa fa-check"></i><b>2.2.2</b> Choosing a prior for <span class="math inline">\(\theta\)</span></a></li>
<li class="chapter" data-level="2.2.3" data-path="ch-introBDA.html"><a href="ch-introBDA.html#using-bayes-rule-to-compute-the-posterior-pthetank"><i class="fa fa-check"></i><b>2.2.3</b> Using Bayes’ rule to compute the posterior <span class="math inline">\(p(\theta|n,k)\)</span></a></li>
<li class="chapter" data-level="2.2.4" data-path="ch-introBDA.html"><a href="ch-introBDA.html#summary-of-the-procedure"><i class="fa fa-check"></i><b>2.2.4</b> Summary of the procedure</a></li>
<li class="chapter" data-level="2.2.5" data-path="ch-introBDA.html"><a href="ch-introBDA.html#visualizing-the-prior-likelihood-and-posterior"><i class="fa fa-check"></i><b>2.2.5</b> Visualizing the prior, likelihood, and posterior</a></li>
<li class="chapter" data-level="2.2.6" data-path="ch-introBDA.html"><a href="ch-introBDA.html#the-posterior-distribution-is-a-compromise-between-the-prior-and-the-likelihood"><i class="fa fa-check"></i><b>2.2.6</b> The posterior distribution is a compromise between the prior and the likelihood</a></li>
<li class="chapter" data-level="2.2.7" data-path="ch-introBDA.html"><a href="ch-introBDA.html#incremental-knowledge-gain-using-prior-knowledge"><i class="fa fa-check"></i><b>2.2.7</b> Incremental knowledge gain using prior knowledge</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="ch-introBDA.html"><a href="ch-introBDA.html#summary-1"><i class="fa fa-check"></i><b>2.3</b> Summary</a></li>
<li class="chapter" data-level="2.4" data-path="ch-introBDA.html"><a href="ch-introBDA.html#further-reading-1"><i class="fa fa-check"></i><b>2.4</b> Further reading</a></li>
<li class="chapter" data-level="2.5" data-path="ch-introBDA.html"><a href="ch-introBDA.html#sec-BDAexercises"><i class="fa fa-check"></i><b>2.5</b> Exercises</a></li>
</ul></li>
<li class="part"><span><b>II Regression models with brms</b></span></li>
<li class="chapter" data-level="3" data-path="ch-compbda.html"><a href="ch-compbda.html"><i class="fa fa-check"></i><b>3</b> Computational Bayesian data analysis</a><ul>
<li class="chapter" data-level="3.1" data-path="ch-compbda.html"><a href="ch-compbda.html#sec-sampling"><i class="fa fa-check"></i><b>3.1</b> Deriving the posterior through sampling</a></li>
<li class="chapter" data-level="3.2" data-path="ch-compbda.html"><a href="ch-compbda.html#bayesian-regression-models-using-stan-brms"><i class="fa fa-check"></i><b>3.2</b> Bayesian Regression Models using Stan: brms</a><ul>
<li class="chapter" data-level="3.2.1" data-path="ch-compbda.html"><a href="ch-compbda.html#sec-simplenormal"><i class="fa fa-check"></i><b>3.2.1</b> A simple linear model: A single subject pressing a button repeatedly (a finger tapping task)</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="ch-compbda.html"><a href="ch-compbda.html#sec-priorpred"><i class="fa fa-check"></i><b>3.3</b> Prior predictive distribution</a></li>
<li class="chapter" data-level="3.4" data-path="ch-compbda.html"><a href="ch-compbda.html#sec-sensitivity"><i class="fa fa-check"></i><b>3.4</b> The influence of priors: sensitivity analysis</a><ul>
<li class="chapter" data-level="3.4.1" data-path="ch-compbda.html"><a href="ch-compbda.html#flat-uninformative-priors"><i class="fa fa-check"></i><b>3.4.1</b> Flat, uninformative priors</a></li>
<li class="chapter" data-level="3.4.2" data-path="ch-compbda.html"><a href="ch-compbda.html#regularizing-priors"><i class="fa fa-check"></i><b>3.4.2</b> Regularizing priors</a></li>
<li class="chapter" data-level="3.4.3" data-path="ch-compbda.html"><a href="ch-compbda.html#principled-priors"><i class="fa fa-check"></i><b>3.4.3</b> Principled priors</a></li>
<li class="chapter" data-level="3.4.4" data-path="ch-compbda.html"><a href="ch-compbda.html#informative-priors"><i class="fa fa-check"></i><b>3.4.4</b> Informative priors</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="ch-compbda.html"><a href="ch-compbda.html#sec-revisit"><i class="fa fa-check"></i><b>3.5</b> Revisiting the button-pressing example with different priors</a></li>
<li class="chapter" data-level="3.6" data-path="ch-compbda.html"><a href="ch-compbda.html#sec-ppd"><i class="fa fa-check"></i><b>3.6</b> Posterior predictive distribution</a></li>
<li class="chapter" data-level="3.7" data-path="ch-compbda.html"><a href="ch-compbda.html#the-influence-of-the-likelihood"><i class="fa fa-check"></i><b>3.7</b> The influence of the likelihood</a><ul>
<li class="chapter" data-level="3.7.1" data-path="ch-compbda.html"><a href="ch-compbda.html#sec-lnfirst"><i class="fa fa-check"></i><b>3.7.1</b> The log-normal likelihood</a></li>
<li class="chapter" data-level="3.7.2" data-path="ch-compbda.html"><a href="ch-compbda.html#sec-lognormal"><i class="fa fa-check"></i><b>3.7.2</b> Using a log-normal likelihood to fit data from a single subject pressing a button repeatedly</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="ch-compbda.html"><a href="ch-compbda.html#list-of-the-most-important-commands"><i class="fa fa-check"></i><b>3.8</b> List of the most important commands</a></li>
<li class="chapter" data-level="3.9" data-path="ch-compbda.html"><a href="ch-compbda.html#summary-2"><i class="fa fa-check"></i><b>3.9</b> Summary</a></li>
<li class="chapter" data-level="3.10" data-path="ch-compbda.html"><a href="ch-compbda.html#sec-ch3furtherreading"><i class="fa fa-check"></i><b>3.10</b> Further reading</a></li>
<li class="chapter" data-level="3.11" data-path="ch-compbda.html"><a href="ch-compbda.html#ex:compbda"><i class="fa fa-check"></i><b>3.11</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="ch-reg.html"><a href="ch-reg.html"><i class="fa fa-check"></i><b>4</b> Bayesian regression models</a><ul>
<li class="chapter" data-level="4.1" data-path="ch-reg.html"><a href="ch-reg.html#sec-pupil"><i class="fa fa-check"></i><b>4.1</b> A first linear regression: Does attentional load affect pupil size?</a><ul>
<li class="chapter" data-level="4.1.1" data-path="ch-reg.html"><a href="ch-reg.html#likelihood-and-priors"><i class="fa fa-check"></i><b>4.1.1</b> Likelihood and priors</a></li>
<li class="chapter" data-level="4.1.2" data-path="ch-reg.html"><a href="ch-reg.html#the-brms-model"><i class="fa fa-check"></i><b>4.1.2</b> The <code>brms</code> model</a></li>
<li class="chapter" data-level="4.1.3" data-path="ch-reg.html"><a href="ch-reg.html#how-to-communicate-the-results"><i class="fa fa-check"></i><b>4.1.3</b> How to communicate the results?</a></li>
<li class="chapter" data-level="4.1.4" data-path="ch-reg.html"><a href="ch-reg.html#sec-pupiladq"><i class="fa fa-check"></i><b>4.1.4</b> Descriptive adequacy</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="ch-reg.html"><a href="ch-reg.html#sec-trial"><i class="fa fa-check"></i><b>4.2</b> Log-normal model: Does trial affect finger tapping times?</a><ul>
<li class="chapter" data-level="4.2.1" data-path="ch-reg.html"><a href="ch-reg.html#likelihood-and-priors-for-the-log-normal-model"><i class="fa fa-check"></i><b>4.2.1</b> Likelihood and priors for the log-normal model</a></li>
<li class="chapter" data-level="4.2.2" data-path="ch-reg.html"><a href="ch-reg.html#the-brms-model-1"><i class="fa fa-check"></i><b>4.2.2</b> The <code>brms</code> model</a></li>
<li class="chapter" data-level="4.2.3" data-path="ch-reg.html"><a href="ch-reg.html#how-to-communicate-the-results-1"><i class="fa fa-check"></i><b>4.2.3</b> How to communicate the results?</a></li>
<li class="chapter" data-level="4.2.4" data-path="ch-reg.html"><a href="ch-reg.html#descriptive-adequacy"><i class="fa fa-check"></i><b>4.2.4</b> Descriptive adequacy</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="ch-reg.html"><a href="ch-reg.html#sec-logistic"><i class="fa fa-check"></i><b>4.3</b> Logistic regression: Does set size affect free recall?</a><ul>
<li class="chapter" data-level="4.3.1" data-path="ch-reg.html"><a href="ch-reg.html#the-likelihood-for-the-logistic-regression-model"><i class="fa fa-check"></i><b>4.3.1</b> The likelihood for the logistic regression model</a></li>
<li class="chapter" data-level="4.3.2" data-path="ch-reg.html"><a href="ch-reg.html#sec-priorslogisticregression"><i class="fa fa-check"></i><b>4.3.2</b> Priors for the logistic regression</a></li>
<li class="chapter" data-level="4.3.3" data-path="ch-reg.html"><a href="ch-reg.html#the-brms-model-2"><i class="fa fa-check"></i><b>4.3.3</b> The <code>brms</code> model</a></li>
<li class="chapter" data-level="4.3.4" data-path="ch-reg.html"><a href="ch-reg.html#sec-comlogis"><i class="fa fa-check"></i><b>4.3.4</b> How to communicate the results?</a></li>
<li class="chapter" data-level="4.3.5" data-path="ch-reg.html"><a href="ch-reg.html#descriptive-adequacy-1"><i class="fa fa-check"></i><b>4.3.5</b> Descriptive adequacy</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="ch-reg.html"><a href="ch-reg.html#summary-3"><i class="fa fa-check"></i><b>4.4</b> Summary</a></li>
<li class="chapter" data-level="4.5" data-path="ch-reg.html"><a href="ch-reg.html#sec-ch4furtherreading"><i class="fa fa-check"></i><b>4.5</b> Further reading</a></li>
<li class="chapter" data-level="4.6" data-path="ch-reg.html"><a href="ch-reg.html#sec-LMexercises"><i class="fa fa-check"></i><b>4.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html"><i class="fa fa-check"></i><b>5</b> Bayesian hierarchical models</a><ul>
<li class="chapter" data-level="5.1" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#exchangeability-and-hierarchical-models"><i class="fa fa-check"></i><b>5.1</b> Exchangeability and hierarchical models</a></li>
<li class="chapter" data-level="5.2" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#sec-N400hierarchical"><i class="fa fa-check"></i><b>5.2</b> A hierarchical model with a normal likelihood: The N400 effect</a><ul>
<li class="chapter" data-level="5.2.1" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#sec-Mcp"><i class="fa fa-check"></i><b>5.2.1</b> Complete pooling model (<span class="math inline">\(M_{cp}\)</span>)</a></li>
<li class="chapter" data-level="5.2.2" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#no-pooling-model-m_np"><i class="fa fa-check"></i><b>5.2.2</b> No pooling model (<span class="math inline">\(M_{np}\)</span>)</a></li>
<li class="chapter" data-level="5.2.3" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#sec-uncorrelated"><i class="fa fa-check"></i><b>5.2.3</b> Varying intercepts and varying slopes model (<span class="math inline">\(M_{v}\)</span>)</a></li>
<li class="chapter" data-level="5.2.4" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#sec-mcvivs"><i class="fa fa-check"></i><b>5.2.4</b> Correlated varying intercept varying slopes model (<span class="math inline">\(M_{h}\)</span>)</a></li>
<li class="chapter" data-level="5.2.5" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#sec-sih"><i class="fa fa-check"></i><b>5.2.5</b> By-subjects and by-items correlated varying intercept varying slopes model (<span class="math inline">\(M_{sih}\)</span>)</a></li>
<li class="chapter" data-level="5.2.6" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#sec-distrmodel"><i class="fa fa-check"></i><b>5.2.6</b> Beyond the maximal model–Distributional regression models</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#sec-stroop"><i class="fa fa-check"></i><b>5.3</b> A hierarchical log-normal model: The Stroop effect</a><ul>
<li class="chapter" data-level="5.3.1" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#a-correlated-varying-intercept-varying-slopes-log-normal-model"><i class="fa fa-check"></i><b>5.3.1</b> A correlated varying intercept varying slopes log-normal model</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#why-fitting-a-bayesian-hierarchical-model-is-worth-the-effort"><i class="fa fa-check"></i><b>5.4</b> Why fitting a Bayesian hierarchical model is worth the effort</a></li>
<li class="chapter" data-level="5.5" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#summary-4"><i class="fa fa-check"></i><b>5.5</b> Summary</a></li>
<li class="chapter" data-level="5.6" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#further-reading-2"><i class="fa fa-check"></i><b>5.6</b> Further reading</a></li>
<li class="chapter" data-level="5.7" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#sec-HLMexercises"><i class="fa fa-check"></i><b>5.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="ch-priors.html"><a href="ch-priors.html"><i class="fa fa-check"></i><b>6</b> The Art and Science of Prior Elicitation</a><ul>
<li class="chapter" data-level="6.1" data-path="ch-priors.html"><a href="ch-priors.html#sec-simpleexamplepriors"><i class="fa fa-check"></i><b>6.1</b> Eliciting priors from oneself for a self-paced reading study: A simple example</a><ul>
<li class="chapter" data-level="6.1.1" data-path="ch-priors.html"><a href="ch-priors.html#an-example-english-relative-clauses"><i class="fa fa-check"></i><b>6.1.1</b> An example: English relative clauses</a></li>
<li class="chapter" data-level="6.1.2" data-path="ch-priors.html"><a href="ch-priors.html#eliciting-a-prior-for-the-intercept"><i class="fa fa-check"></i><b>6.1.2</b> Eliciting a prior for the intercept</a></li>
<li class="chapter" data-level="6.1.3" data-path="ch-priors.html"><a href="ch-priors.html#eliciting-a-prior-for-the-slope"><i class="fa fa-check"></i><b>6.1.3</b> Eliciting a prior for the slope</a></li>
<li class="chapter" data-level="6.1.4" data-path="ch-priors.html"><a href="ch-priors.html#sec-varcomppriors"><i class="fa fa-check"></i><b>6.1.4</b> Eliciting priors for the variance components</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="ch-priors.html"><a href="ch-priors.html#eliciting-priors-from-experts"><i class="fa fa-check"></i><b>6.2</b> Eliciting priors from experts</a></li>
<li class="chapter" data-level="6.3" data-path="ch-priors.html"><a href="ch-priors.html#deriving-priors-from-meta-analyses"><i class="fa fa-check"></i><b>6.3</b> Deriving priors from meta-analyses</a></li>
<li class="chapter" data-level="6.4" data-path="ch-priors.html"><a href="ch-priors.html#using-previous-experiments-posteriors-as-priors-for-a-new-study"><i class="fa fa-check"></i><b>6.4</b> Using previous experiments’ posteriors as priors for a new study</a></li>
<li class="chapter" data-level="6.5" data-path="ch-priors.html"><a href="ch-priors.html#summary-5"><i class="fa fa-check"></i><b>6.5</b> Summary</a></li>
<li class="chapter" data-level="6.6" data-path="ch-priors.html"><a href="ch-priors.html#further-reading-3"><i class="fa fa-check"></i><b>6.6</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="ch-workflow.html"><a href="ch-workflow.html"><i class="fa fa-check"></i><b>7</b> Workflow</a><ul>
<li class="chapter" data-level="7.1" data-path="ch-workflow.html"><a href="ch-workflow.html#model-building"><i class="fa fa-check"></i><b>7.1</b> Model building</a></li>
<li class="chapter" data-level="7.2" data-path="ch-workflow.html"><a href="ch-workflow.html#principled-questions-on-a-model"><i class="fa fa-check"></i><b>7.2</b> Principled questions on a model</a><ul>
<li class="chapter" data-level="7.2.1" data-path="ch-workflow.html"><a href="ch-workflow.html#prior-predictive-checks-checking-consistency-with-domain-expertise"><i class="fa fa-check"></i><b>7.2.1</b> Prior predictive checks: Checking consistency with domain expertise</a></li>
<li class="chapter" data-level="7.2.2" data-path="ch-workflow.html"><a href="ch-workflow.html#computational-faithfulness-testing-for-correct-posterior-approximations"><i class="fa fa-check"></i><b>7.2.2</b> Computational faithfulness: Testing for correct posterior approximations</a></li>
<li class="chapter" data-level="7.2.3" data-path="ch-workflow.html"><a href="ch-workflow.html#model-sensitivity"><i class="fa fa-check"></i><b>7.2.3</b> Model sensitivity</a></li>
<li class="chapter" data-level="7.2.4" data-path="ch-workflow.html"><a href="ch-workflow.html#posterior-predictive-checks-does-the-model-adequately-capture-the-data"><i class="fa fa-check"></i><b>7.2.4</b> Posterior predictive checks: Does the model adequately capture the data?</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="ch-workflow.html"><a href="ch-workflow.html#exemplary-data-analysis"><i class="fa fa-check"></i><b>7.3</b> Exemplary data analysis</a><ul>
<li class="chapter" data-level="7.3.1" data-path="ch-workflow.html"><a href="ch-workflow.html#prior-predictive-checks"><i class="fa fa-check"></i><b>7.3.1</b> Prior predictive checks</a></li>
<li class="chapter" data-level="7.3.2" data-path="ch-workflow.html"><a href="ch-workflow.html#adjusting-priors"><i class="fa fa-check"></i><b>7.3.2</b> Adjusting priors</a></li>
<li class="chapter" data-level="7.3.3" data-path="ch-workflow.html"><a href="ch-workflow.html#computational-faithfulness-and-model-sensitivity"><i class="fa fa-check"></i><b>7.3.3</b> Computational faithfulness and model sensitivity</a></li>
<li class="chapter" data-level="7.3.4" data-path="ch-workflow.html"><a href="ch-workflow.html#posterior-predictive-checks-model-adequacy"><i class="fa fa-check"></i><b>7.3.4</b> Posterior predictive checks: Model adequacy</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="ch-workflow.html"><a href="ch-workflow.html#summary-6"><i class="fa fa-check"></i><b>7.4</b> Summary</a></li>
<li class="chapter" data-level="7.5" data-path="ch-workflow.html"><a href="ch-workflow.html#further-reading-4"><i class="fa fa-check"></i><b>7.5</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="ch-contr.html"><a href="ch-contr.html"><i class="fa fa-check"></i><b>8</b> Contrast coding</a><ul>
<li class="chapter" data-level="8.1" data-path="ch-contr.html"><a href="ch-contr.html#basic-concepts-illustrated-using-a-two-level-factor"><i class="fa fa-check"></i><b>8.1</b> Basic concepts illustrated using a two-level factor</a><ul>
<li class="chapter" data-level="8.1.1" data-path="ch-contr.html"><a href="ch-contr.html#treatmentcontrasts"><i class="fa fa-check"></i><b>8.1.1</b> Default contrast coding: Treatment contrasts</a></li>
<li class="chapter" data-level="8.1.2" data-path="ch-contr.html"><a href="ch-contr.html#inverseMatrix"><i class="fa fa-check"></i><b>8.1.2</b> Defining comparisons</a></li>
<li class="chapter" data-level="8.1.3" data-path="ch-contr.html"><a href="ch-contr.html#effectcoding"><i class="fa fa-check"></i><b>8.1.3</b> Sum contrasts</a></li>
<li class="chapter" data-level="8.1.4" data-path="ch-contr.html"><a href="ch-contr.html#sec-cellMeans"><i class="fa fa-check"></i><b>8.1.4</b> Cell means parameterization and posterior comparisons</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="ch-contr.html"><a href="ch-contr.html#the-hypothesis-matrix-illustrated-with-a-three-level-factor"><i class="fa fa-check"></i><b>8.2</b> The hypothesis matrix illustrated with a three-level factor</a><ul>
<li class="chapter" data-level="8.2.1" data-path="ch-contr.html"><a href="ch-contr.html#sumcontrasts"><i class="fa fa-check"></i><b>8.2.1</b> Sum contrasts</a></li>
<li class="chapter" data-level="8.2.2" data-path="ch-contr.html"><a href="ch-contr.html#the-hypothesis-matrix"><i class="fa fa-check"></i><b>8.2.2</b> The hypothesis matrix</a></li>
<li class="chapter" data-level="8.2.3" data-path="ch-contr.html"><a href="ch-contr.html#generating-contrasts-the-hypr-package"><i class="fa fa-check"></i><b>8.2.3</b> Generating contrasts: The <code>hypr</code> package</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="ch-contr.html"><a href="ch-contr.html#sec-4levelFactor"><i class="fa fa-check"></i><b>8.3</b> Other types of contrasts: illustration with a factor with four levels</a><ul>
<li class="chapter" data-level="8.3.1" data-path="ch-contr.html"><a href="ch-contr.html#repeatedcontrasts"><i class="fa fa-check"></i><b>8.3.1</b> Repeated contrasts</a></li>
<li class="chapter" data-level="8.3.2" data-path="ch-contr.html"><a href="ch-contr.html#helmertcontrasts"><i class="fa fa-check"></i><b>8.3.2</b> Helmert contrasts</a></li>
<li class="chapter" data-level="8.3.3" data-path="ch-contr.html"><a href="ch-contr.html#contrasts-in-linear-regression-analysis-the-design-or-model-matrix"><i class="fa fa-check"></i><b>8.3.3</b> Contrasts in linear regression analysis: The design or model matrix</a></li>
<li class="chapter" data-level="8.3.4" data-path="ch-contr.html"><a href="ch-contr.html#polynomialContrasts"><i class="fa fa-check"></i><b>8.3.4</b> Polynomial contrasts</a></li>
<li class="chapter" data-level="8.3.5" data-path="ch-contr.html"><a href="ch-contr.html#an-alternative-to-contrasts-monotonic-effects"><i class="fa fa-check"></i><b>8.3.5</b> An alternative to contrasts: monotonic effects</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="ch-contr.html"><a href="ch-contr.html#nonOrthogonal"><i class="fa fa-check"></i><b>8.4</b> What makes a good set of contrasts?</a><ul>
<li class="chapter" data-level="8.4.1" data-path="ch-contr.html"><a href="ch-contr.html#centered-contrasts"><i class="fa fa-check"></i><b>8.4.1</b> Centered contrasts</a></li>
<li class="chapter" data-level="8.4.2" data-path="ch-contr.html"><a href="ch-contr.html#orthogonal-contrasts"><i class="fa fa-check"></i><b>8.4.2</b> Orthogonal contrasts</a></li>
<li class="chapter" data-level="8.4.3" data-path="ch-contr.html"><a href="ch-contr.html#the-role-of-the-intercept-in-non-centered-contrasts"><i class="fa fa-check"></i><b>8.4.3</b> The role of the intercept in non-centered contrasts</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="ch-contr.html"><a href="ch-contr.html#computing-condition-means-from-estimated-contrasts"><i class="fa fa-check"></i><b>8.5</b> Computing condition means from estimated contrasts</a></li>
<li class="chapter" data-level="8.6" data-path="ch-contr.html"><a href="ch-contr.html#summary-7"><i class="fa fa-check"></i><b>8.6</b> Summary</a></li>
<li class="chapter" data-level="8.7" data-path="ch-contr.html"><a href="ch-contr.html#further-reading-5"><i class="fa fa-check"></i><b>8.7</b> Further reading</a></li>
<li class="chapter" data-level="8.8" data-path="ch-contr.html"><a href="ch-contr.html#sec-Contrastsexercises"><i class="fa fa-check"></i><b>8.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="ch-coding2x2.html"><a href="ch-coding2x2.html"><i class="fa fa-check"></i><b>9</b> Contrast coding for designs with two predictor variables</a><ul>
<li class="chapter" data-level="9.1" data-path="ch-coding2x2.html"><a href="ch-coding2x2.html#sec-MR-ANOVA"><i class="fa fa-check"></i><b>9.1</b> Contrast coding in a factorial <span class="math inline">\(2 \times 2\)</span> design</a><ul>
<li class="chapter" data-level="9.1.1" data-path="ch-coding2x2.html"><a href="ch-coding2x2.html#nestedEffects"><i class="fa fa-check"></i><b>9.1.1</b> Nested effects</a></li>
<li class="chapter" data-level="9.1.2" data-path="ch-coding2x2.html"><a href="ch-coding2x2.html#interactions-between-contrasts"><i class="fa fa-check"></i><b>9.1.2</b> Interactions between contrasts</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="ch-coding2x2.html"><a href="ch-coding2x2.html#sec-contrast-covariate"><i class="fa fa-check"></i><b>9.2</b> One factor and one covariate</a><ul>
<li class="chapter" data-level="9.2.1" data-path="ch-coding2x2.html"><a href="ch-coding2x2.html#estimating-a-group-difference-and-controlling-for-a-covariate"><i class="fa fa-check"></i><b>9.2.1</b> Estimating a group difference and controlling for a covariate</a></li>
<li class="chapter" data-level="9.2.2" data-path="ch-coding2x2.html"><a href="ch-coding2x2.html#estimating-differences-in-slopes"><i class="fa fa-check"></i><b>9.2.2</b> Estimating differences in slopes</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="ch-coding2x2.html"><a href="ch-coding2x2.html#sec-interactions-NLM"><i class="fa fa-check"></i><b>9.3</b> Interactions in generalized linear models (with non-linear link functions) and non-linear models</a></li>
<li class="chapter" data-level="9.4" data-path="ch-coding2x2.html"><a href="ch-coding2x2.html#summary-8"><i class="fa fa-check"></i><b>9.4</b> Summary</a></li>
<li class="chapter" data-level="9.5" data-path="ch-coding2x2.html"><a href="ch-coding2x2.html#further-reading-6"><i class="fa fa-check"></i><b>9.5</b> Further reading</a></li>
<li class="chapter" data-level="9.6" data-path="ch-coding2x2.html"><a href="ch-coding2x2.html#sec-Contrasts2x2exercises"><i class="fa fa-check"></i><b>9.6</b> Exercises</a></li>
</ul></li>
<li class="part"><span><b>III Advanced models with Stan</b></span></li>
<li class="chapter" data-level="10" data-path="ch-introstan.html"><a href="ch-introstan.html"><i class="fa fa-check"></i><b>10</b> Introduction to the probabilistic programming language Stan</a><ul>
<li class="chapter" data-level="10.1" data-path="ch-introstan.html"><a href="ch-introstan.html#stan-syntax"><i class="fa fa-check"></i><b>10.1</b> Stan syntax</a></li>
<li class="chapter" data-level="10.2" data-path="ch-introstan.html"><a href="ch-introstan.html#sec-firststan"><i class="fa fa-check"></i><b>10.2</b> A first simple example with Stan: Normal likelihood</a></li>
<li class="chapter" data-level="10.3" data-path="ch-introstan.html"><a href="ch-introstan.html#sec-clozestan"><i class="fa fa-check"></i><b>10.3</b> Another simple example: Cloze probability with Stan with the binomial likelihood</a></li>
<li class="chapter" data-level="10.4" data-path="ch-introstan.html"><a href="ch-introstan.html#regression-models-in-stan"><i class="fa fa-check"></i><b>10.4</b> Regression models in Stan</a><ul>
<li class="chapter" data-level="10.4.1" data-path="ch-introstan.html"><a href="ch-introstan.html#sec-pupilstan"><i class="fa fa-check"></i><b>10.4.1</b> A first linear regression in Stan: Does attentional load affect pupil size?</a></li>
<li class="chapter" data-level="10.4.2" data-path="ch-introstan.html"><a href="ch-introstan.html#sec-interstan"><i class="fa fa-check"></i><b>10.4.2</b> Interactions in Stan: Does attentional load interact with trial number affecting pupil size?</a></li>
<li class="chapter" data-level="10.4.3" data-path="ch-introstan.html"><a href="ch-introstan.html#sec-logisticstan"><i class="fa fa-check"></i><b>10.4.3</b> Logistic regression in Stan: Does set size and trial affect free recall?</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="ch-introstan.html"><a href="ch-introstan.html#summary-9"><i class="fa fa-check"></i><b>10.5</b> Summary</a></li>
<li class="chapter" data-level="10.6" data-path="ch-introstan.html"><a href="ch-introstan.html#further-reading-7"><i class="fa fa-check"></i><b>10.6</b> Further reading</a></li>
<li class="chapter" data-level="10.7" data-path="ch-introstan.html"><a href="ch-introstan.html#exercises"><i class="fa fa-check"></i><b>10.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="ch-complexstan.html"><a href="ch-complexstan.html"><i class="fa fa-check"></i><b>11</b> Complex models and reparameterization</a><ul>
<li class="chapter" data-level="11.1" data-path="ch-complexstan.html"><a href="ch-complexstan.html#sec-hierstan"><i class="fa fa-check"></i><b>11.1</b> Hierarchical models with Stan</a><ul>
<li class="chapter" data-level="11.1.1" data-path="ch-complexstan.html"><a href="ch-complexstan.html#varying-intercept-model-with-stan"><i class="fa fa-check"></i><b>11.1.1</b> Varying intercept model with Stan</a></li>
<li class="chapter" data-level="11.1.2" data-path="ch-complexstan.html"><a href="ch-complexstan.html#sec-uncorrstan"><i class="fa fa-check"></i><b>11.1.2</b> Uncorrelated varying intercept and slopes model with Stan</a></li>
<li class="chapter" data-level="11.1.3" data-path="ch-complexstan.html"><a href="ch-complexstan.html#sec-corrstan"><i class="fa fa-check"></i><b>11.1.3</b> Correlated varying intercept varying slopes model</a></li>
<li class="chapter" data-level="11.1.4" data-path="ch-complexstan.html"><a href="ch-complexstan.html#sec-crosscorrstan"><i class="fa fa-check"></i><b>11.1.4</b> By-subject and by-items correlated varying intercept varying slopes model</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="ch-complexstan.html"><a href="ch-complexstan.html#summary-10"><i class="fa fa-check"></i><b>11.2</b> Summary</a></li>
<li class="chapter" data-level="11.3" data-path="ch-complexstan.html"><a href="ch-complexstan.html#further-reading-8"><i class="fa fa-check"></i><b>11.3</b> Further reading</a></li>
<li class="chapter" data-level="11.4" data-path="ch-complexstan.html"><a href="ch-complexstan.html#exercises-1"><i class="fa fa-check"></i><b>11.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="ch-custom.html"><a href="ch-custom.html"><i class="fa fa-check"></i><b>12</b> Custom distributions in Stan</a><ul>
<li class="chapter" data-level="12.1" data-path="ch-custom.html"><a href="ch-custom.html#sec-change"><i class="fa fa-check"></i><b>12.1</b> A change of variables with the reciprocal normal distribution</a><ul>
<li class="chapter" data-level="12.1.1" data-path="ch-custom.html"><a href="ch-custom.html#scaling-a-probability-density-with-the-jacobian-adjustment"><i class="fa fa-check"></i><b>12.1.1</b> Scaling a probability density with the Jacobian adjustment</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="ch-custom.html"><a href="ch-custom.html#sec-validSBC"><i class="fa fa-check"></i><b>12.2</b> Validation of a computed posterior distribution</a><ul>
<li class="chapter" data-level="12.2.1" data-path="ch-custom.html"><a href="ch-custom.html#the-simulation-based-calibration-procedure"><i class="fa fa-check"></i><b>12.2.1</b> The simulation-based calibration procedure</a></li>
<li class="chapter" data-level="12.2.2" data-path="ch-custom.html"><a href="ch-custom.html#simulation-based-calibration-revealing-a-problem"><i class="fa fa-check"></i><b>12.2.2</b> Simulation-based calibration revealing a problem</a></li>
<li class="chapter" data-level="12.2.3" data-path="ch-custom.html"><a href="ch-custom.html#issues-and-limitation-of-simulation-based-calibration"><i class="fa fa-check"></i><b>12.2.3</b> Issues and limitation of simulation-based calibration</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="ch-custom.html"><a href="ch-custom.html#another-custom-distribution-re-implementing-the-exponential-distribution-manually"><i class="fa fa-check"></i><b>12.3</b> Another custom distribution: Re-implementing the exponential distribution manually</a></li>
<li class="chapter" data-level="12.4" data-path="ch-custom.html"><a href="ch-custom.html#summary-11"><i class="fa fa-check"></i><b>12.4</b> Summary</a></li>
<li class="chapter" data-level="12.5" data-path="ch-custom.html"><a href="ch-custom.html#further-reading-9"><i class="fa fa-check"></i><b>12.5</b> Further reading</a></li>
<li class="chapter" data-level="12.6" data-path="ch-custom.html"><a href="ch-custom.html#sec-customexercises"><i class="fa fa-check"></i><b>12.6</b> Exercises</a></li>
</ul></li>
<li class="part"><span><b>IV Evidence synthesis and measurements with error</b></span></li>
<li class="chapter" data-level="13" data-path="ch-remame.html"><a href="ch-remame.html"><i class="fa fa-check"></i><b>13</b> Meta-analysis and measurement error models</a><ul>
<li class="chapter" data-level="13.1" data-path="ch-remame.html"><a href="ch-remame.html#meta-analysis"><i class="fa fa-check"></i><b>13.1</b> Meta-analysis</a><ul>
<li class="chapter" data-level="13.1.1" data-path="ch-remame.html"><a href="ch-remame.html#a-meta-analysis-of-similarity-based-interference-in-sentence-comprehension"><i class="fa fa-check"></i><b>13.1.1</b> A meta-analysis of similarity-based interference in sentence comprehension</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="ch-remame.html"><a href="ch-remame.html#measurement-error-models"><i class="fa fa-check"></i><b>13.2</b> Measurement-error models</a><ul>
<li class="chapter" data-level="13.2.1" data-path="ch-remame.html"><a href="ch-remame.html#accounting-for-measurement-error-in-individual-differences-in-working-memory-capacity-and-reading-fluency"><i class="fa fa-check"></i><b>13.2.1</b> Accounting for measurement error in individual differences in working memory capacity and reading fluency</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="ch-remame.html"><a href="ch-remame.html#summary-12"><i class="fa fa-check"></i><b>13.3</b> Summary</a></li>
<li class="chapter" data-level="13.4" data-path="ch-remame.html"><a href="ch-remame.html#further-reading-10"><i class="fa fa-check"></i><b>13.4</b> Further reading</a></li>
<li class="chapter" data-level="13.5" data-path="ch-remame.html"><a href="ch-remame.html#sec-REMAMEexercises"><i class="fa fa-check"></i><b>13.5</b> Exercises</a></li>
</ul></li>
<li class="part"><span><b>V Model comparison and hypothesis testing</b></span></li>
<li class="chapter" data-level="14" data-path="ch-comparison.html"><a href="ch-comparison.html"><i class="fa fa-check"></i><b>14</b> Introduction to model comparison</a><ul>
<li class="chapter" data-level="14.1" data-path="ch-comparison.html"><a href="ch-comparison.html#further-reading-11"><i class="fa fa-check"></i><b>14.1</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="ch-bf.html"><a href="ch-bf.html"><i class="fa fa-check"></i><b>15</b> Bayes factors</a><ul>
<li class="chapter" data-level="15.1" data-path="ch-bf.html"><a href="ch-bf.html#hypothesis-testing-using-the-bayes-factor"><i class="fa fa-check"></i><b>15.1</b> Hypothesis testing using the Bayes factor</a><ul>
<li class="chapter" data-level="15.1.1" data-path="ch-bf.html"><a href="ch-bf.html#marginal-likelihood"><i class="fa fa-check"></i><b>15.1.1</b> Marginal likelihood</a></li>
<li class="chapter" data-level="15.1.2" data-path="ch-bf.html"><a href="ch-bf.html#bayes-factor"><i class="fa fa-check"></i><b>15.1.2</b> Bayes factor</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="ch-bf.html"><a href="ch-bf.html#sec-N400BF"><i class="fa fa-check"></i><b>15.2</b> Examining the N400 effect with Bayes factor</a><ul>
<li class="chapter" data-level="15.2.1" data-path="ch-bf.html"><a href="ch-bf.html#sensitivity-analysis-1"><i class="fa fa-check"></i><b>15.2.1</b> Sensitivity analysis</a></li>
<li class="chapter" data-level="15.2.2" data-path="ch-bf.html"><a href="ch-bf.html#sec-BFnonnested"><i class="fa fa-check"></i><b>15.2.2</b> Non-nested models</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="ch-bf.html"><a href="ch-bf.html#the-influence-of-the-priors-on-bayes-factors-beyond-the-effect-of-interest"><i class="fa fa-check"></i><b>15.3</b> The influence of the priors on Bayes factors: beyond the effect of interest</a></li>
<li class="chapter" data-level="15.4" data-path="ch-bf.html"><a href="ch-bf.html#sec-stanBF"><i class="fa fa-check"></i><b>15.4</b> Bayes factor in Stan</a></li>
<li class="chapter" data-level="15.5" data-path="ch-bf.html"><a href="ch-bf.html#bayes-factors-in-theory-and-in-practice"><i class="fa fa-check"></i><b>15.5</b> Bayes factors in theory and in practice</a><ul>
<li class="chapter" data-level="15.5.1" data-path="ch-bf.html"><a href="ch-bf.html#bayes-factors-in-theory-stability-and-accuracy"><i class="fa fa-check"></i><b>15.5.1</b> Bayes factors in theory: Stability and accuracy</a></li>
<li class="chapter" data-level="15.5.2" data-path="ch-bf.html"><a href="ch-bf.html#sec-BFvar"><i class="fa fa-check"></i><b>15.5.2</b> Bayes factors in practice: Variability with the data</a></li>
<li class="chapter" data-level="15.5.3" data-path="ch-bf.html"><a href="ch-bf.html#sec-caution"><i class="fa fa-check"></i><b>15.5.3</b> A cautionary note about Bayes factors</a></li>
</ul></li>
<li class="chapter" data-level="15.6" data-path="ch-bf.html"><a href="ch-bf.html#summary-13"><i class="fa fa-check"></i><b>15.6</b> Summary</a></li>
<li class="chapter" data-level="15.7" data-path="ch-bf.html"><a href="ch-bf.html#further-reading-12"><i class="fa fa-check"></i><b>15.7</b> Further reading</a></li>
<li class="chapter" data-level="15.8" data-path="ch-bf.html"><a href="ch-bf.html#exercises-2"><i class="fa fa-check"></i><b>15.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="ch-cv.html"><a href="ch-cv.html"><i class="fa fa-check"></i><b>16</b> Cross-validation</a><ul>
<li class="chapter" data-level="16.1" data-path="ch-cv.html"><a href="ch-cv.html#the-expected-log-predictive-density-of-a-model"><i class="fa fa-check"></i><b>16.1</b> The expected log predictive density of a model</a></li>
<li class="chapter" data-level="16.2" data-path="ch-cv.html"><a href="ch-cv.html#k-fold-and-leave-one-out-cross-validation"><i class="fa fa-check"></i><b>16.2</b> K-fold and leave-one-out cross-validation</a></li>
<li class="chapter" data-level="16.3" data-path="ch-cv.html"><a href="ch-cv.html#testing-the-n400-effect-using-cross-validation"><i class="fa fa-check"></i><b>16.3</b> Testing the N400 effect using cross-validation</a><ul>
<li class="chapter" data-level="16.3.1" data-path="ch-cv.html"><a href="ch-cv.html#cross-validation-with-psis-loo"><i class="fa fa-check"></i><b>16.3.1</b> Cross-validation with PSIS-LOO</a></li>
<li class="chapter" data-level="16.3.2" data-path="ch-cv.html"><a href="ch-cv.html#cross-validation-with-k-fold"><i class="fa fa-check"></i><b>16.3.2</b> Cross-validation with K-fold</a></li>
<li class="chapter" data-level="16.3.3" data-path="ch-cv.html"><a href="ch-cv.html#leave-one-group-out-cross-validation"><i class="fa fa-check"></i><b>16.3.3</b> Leave-one-group-out cross-validation</a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="ch-cv.html"><a href="ch-cv.html#sec-logcv"><i class="fa fa-check"></i><b>16.4</b> Comparing different likelihoods with cross-validation</a></li>
<li class="chapter" data-level="16.5" data-path="ch-cv.html"><a href="ch-cv.html#issues-with-cross-validation"><i class="fa fa-check"></i><b>16.5</b> Issues with cross-validation</a></li>
<li class="chapter" data-level="16.6" data-path="ch-cv.html"><a href="ch-cv.html#cross-validation-in-stan"><i class="fa fa-check"></i><b>16.6</b> Cross-validation in Stan</a><ul>
<li class="chapter" data-level="16.6.1" data-path="ch-cv.html"><a href="ch-cv.html#psis-loo-cv-in-stan"><i class="fa fa-check"></i><b>16.6.1</b> PSIS-LOO-CV in Stan</a></li>
</ul></li>
<li class="chapter" data-level="16.7" data-path="ch-cv.html"><a href="ch-cv.html#summary-14"><i class="fa fa-check"></i><b>16.7</b> Summary</a></li>
<li class="chapter" data-level="16.8" data-path="ch-cv.html"><a href="ch-cv.html#further-reading-13"><i class="fa fa-check"></i><b>16.8</b> Further reading</a></li>
<li class="chapter" data-level="16.9" data-path="ch-cv.html"><a href="ch-cv.html#exercises-3"><i class="fa fa-check"></i><b>16.9</b> Exercises</a></li>
</ul></li>
<li class="part"><span><b>VI Computational cognitive modeling with Stan</b></span></li>
<li class="chapter" data-level="17" data-path="ch-cogmod.html"><a href="ch-cogmod.html"><i class="fa fa-check"></i><b>17</b> Introduction to computational cognitive modeling</a><ul>
<li class="chapter" data-level="17.1" data-path="ch-cogmod.html"><a href="ch-cogmod.html#further-reading-14"><i class="fa fa-check"></i><b>17.1</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="ch-MPT.html"><a href="ch-MPT.html"><i class="fa fa-check"></i><b>18</b> Multinomial processing trees</a><ul>
<li class="chapter" data-level="18.1" data-path="ch-MPT.html"><a href="ch-MPT.html#modeling-multiple-categorical-responses"><i class="fa fa-check"></i><b>18.1</b> Modeling multiple categorical responses</a><ul>
<li class="chapter" data-level="18.1.1" data-path="ch-MPT.html"><a href="ch-MPT.html#sec-mult"><i class="fa fa-check"></i><b>18.1.1</b> A model for multiple responses using the multinomial likelihood</a></li>
<li class="chapter" data-level="18.1.2" data-path="ch-MPT.html"><a href="ch-MPT.html#sec-cat"><i class="fa fa-check"></i><b>18.1.2</b> A model for multiple responses using the categorical distribution</a></li>
</ul></li>
<li class="chapter" data-level="18.2" data-path="ch-MPT.html"><a href="ch-MPT.html#modeling-picture-naming-abilities-in-aphasia-with-mpt-models"><i class="fa fa-check"></i><b>18.2</b> Modeling picture naming abilities in aphasia with MPT models</a><ul>
<li class="chapter" data-level="18.2.1" data-path="ch-MPT.html"><a href="ch-MPT.html#calculation-of-the-probabilities-in-the-mpt-branches"><i class="fa fa-check"></i><b>18.2.1</b> Calculation of the probabilities in the MPT branches</a></li>
<li class="chapter" data-level="18.2.2" data-path="ch-MPT.html"><a href="ch-MPT.html#sec-mpt-data"><i class="fa fa-check"></i><b>18.2.2</b> A simple MPT model</a></li>
<li class="chapter" data-level="18.2.3" data-path="ch-MPT.html"><a href="ch-MPT.html#sec-MPT-reg"><i class="fa fa-check"></i><b>18.2.3</b> An MPT model assuming by-item variability</a></li>
<li class="chapter" data-level="18.2.4" data-path="ch-MPT.html"><a href="ch-MPT.html#sec-MPT-h"><i class="fa fa-check"></i><b>18.2.4</b> A hierarchical MPT</a></li>
</ul></li>
<li class="chapter" data-level="18.3" data-path="ch-MPT.html"><a href="ch-MPT.html#summary-15"><i class="fa fa-check"></i><b>18.3</b> Summary</a></li>
<li class="chapter" data-level="18.4" data-path="ch-MPT.html"><a href="ch-MPT.html#further-reading-15"><i class="fa fa-check"></i><b>18.4</b> Further reading</a></li>
<li class="chapter" data-level="18.5" data-path="ch-MPT.html"><a href="ch-MPT.html#exercises-4"><i class="fa fa-check"></i><b>18.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="ch-mixture.html"><a href="ch-mixture.html"><i class="fa fa-check"></i><b>19</b> Mixture models</a><ul>
<li class="chapter" data-level="19.1" data-path="ch-mixture.html"><a href="ch-mixture.html#a-mixture-model-of-the-speed-accuracy-trade-off-the-fast-guess-model-account"><i class="fa fa-check"></i><b>19.1</b> A mixture model of the speed-accuracy trade-off: The fast-guess model account</a><ul>
<li class="chapter" data-level="19.1.1" data-path="ch-mixture.html"><a href="ch-mixture.html#the-global-motion-detection-task"><i class="fa fa-check"></i><b>19.1.1</b> The global motion detection task</a></li>
<li class="chapter" data-level="19.1.2" data-path="ch-mixture.html"><a href="ch-mixture.html#sec-simplefastguess"><i class="fa fa-check"></i><b>19.1.2</b> A very simple implementation of the fast-guess model</a></li>
<li class="chapter" data-level="19.1.3" data-path="ch-mixture.html"><a href="ch-mixture.html#sec-multmix"><i class="fa fa-check"></i><b>19.1.3</b> A multivariate implementation of the fast-guess model</a></li>
<li class="chapter" data-level="19.1.4" data-path="ch-mixture.html"><a href="ch-mixture.html#an-implementation-of-the-fast-guess-model-that-takes-instructions-into-account"><i class="fa fa-check"></i><b>19.1.4</b> An implementation of the fast-guess model that takes instructions into account</a></li>
<li class="chapter" data-level="19.1.5" data-path="ch-mixture.html"><a href="ch-mixture.html#sec-fastguessh"><i class="fa fa-check"></i><b>19.1.5</b> A hierarchical implementation of the fast-guess model</a></li>
</ul></li>
<li class="chapter" data-level="19.2" data-path="ch-mixture.html"><a href="ch-mixture.html#summary-16"><i class="fa fa-check"></i><b>19.2</b> Summary</a></li>
<li class="chapter" data-level="19.3" data-path="ch-mixture.html"><a href="ch-mixture.html#further-reading-16"><i class="fa fa-check"></i><b>19.3</b> Further reading</a></li>
<li class="chapter" data-level="19.4" data-path="ch-mixture.html"><a href="ch-mixture.html#exercises-5"><i class="fa fa-check"></i><b>19.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="ch-lognormalrace.html"><a href="ch-lognormalrace.html"><i class="fa fa-check"></i><b>20</b> A simple accumulator model to account for choice response time</a><ul>
<li class="chapter" data-level="20.1" data-path="ch-lognormalrace.html"><a href="ch-lognormalrace.html#modeling-a-lexical-decision-task"><i class="fa fa-check"></i><b>20.1</b> Modeling a lexical decision task</a><ul>
<li class="chapter" data-level="20.1.1" data-path="ch-lognormalrace.html"><a href="ch-lognormalrace.html#sec-acccoding"><i class="fa fa-check"></i><b>20.1.1</b> Modeling the lexical decision task with the log-normal race model</a></li>
<li class="chapter" data-level="20.1.2" data-path="ch-lognormalrace.html"><a href="ch-lognormalrace.html#sec-genaccum"><i class="fa fa-check"></i><b>20.1.2</b> A generative model for a race between accumulators</a></li>
<li class="chapter" data-level="20.1.3" data-path="ch-lognormalrace.html"><a href="ch-lognormalrace.html#fitting-the-log-normal-race-model"><i class="fa fa-check"></i><b>20.1.3</b> Fitting the log-normal race model</a></li>
<li class="chapter" data-level="20.1.4" data-path="ch-lognormalrace.html"><a href="ch-lognormalrace.html#sec-lognormalh"><i class="fa fa-check"></i><b>20.1.4</b> A hierarchical implementation of the log-normal race model</a></li>
<li class="chapter" data-level="20.1.5" data-path="ch-lognormalrace.html"><a href="ch-lognormalrace.html#sec-contaminant"><i class="fa fa-check"></i><b>20.1.5</b> Dealing with contaminant responses</a></li>
</ul></li>
<li class="chapter" data-level="20.2" data-path="ch-lognormalrace.html"><a href="ch-lognormalrace.html#posterior-predictive-check-with-the-quantile-probability-plots"><i class="fa fa-check"></i><b>20.2</b> Posterior predictive check with the quantile probability plots</a></li>
<li class="chapter" data-level="20.3" data-path="ch-lognormalrace.html"><a href="ch-lognormalrace.html#summary-17"><i class="fa fa-check"></i><b>20.3</b> Summary</a></li>
<li class="chapter" data-level="20.4" data-path="ch-lognormalrace.html"><a href="ch-lognormalrace.html#further-reading-17"><i class="fa fa-check"></i><b>20.4</b> Further reading</a></li>
<li class="chapter" data-level="20.5" data-path="ch-lognormalrace.html"><a href="ch-lognormalrace.html#exercises-6"><i class="fa fa-check"></i><b>20.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="_blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">An Introduction to Bayesian Data Analysis for Cognitive Science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="ch-cv" class="section level1 hasAnchor">
<h1><span class="header-section-number">Chapter 16</span> Cross-validation<a href="ch-cv.html#ch-cv" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>A popular way to evaluate and compare models is to investigate their ability to make predictions for “out-of-sample data”, that is, to use what we learned from the observed data to predict future or unseen observations. Cross-validation is used to test which of the models under consideration is/are able to learn the most from our data in order to make better predictions. However, in cognitive science, our objective will rarely be to predict future observations, but rather to compare how well different models fare in accounting for the observed data.</p>
<p>The objective of cross-validation is to avoid over-optimistic predictions; such over-optimistic predictions would arise if we were to use the data to estimate the parameters of our model, and then use these estimates to predict the same data. That amounts to using the data twice. The basic idea behind cross-validation is that the models are with a large subset of the data, the <em>training set</em>, and then we predict a smaller part of the data, the <em>held-out set</em>. In order to treat the entire data set as a held-out set, and to evaluate the predictive accuracy using every observation, one changes what constitutes the training set and the held-out set. This ensures that the predictions of the model are tested over the entire data set.</p>
<div id="the-expected-log-predictive-density-of-a-model" class="section level2 hasAnchor">
<h2><span class="header-section-number">16.1</span> The expected log predictive density of a model<a href="ch-cv.html#the-expected-log-predictive-density-of-a-model" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In order to compare the quality of the posterior predictions of two models, a <em>utility</em> function or a <em>scoring rule</em> is used <span class="citation">(see Gneiting and Raftery <a href="#ref-GneitingRaftery2007">2007</a> for a review on scoring rules)</span>. The logarithmic score rule <span class="citation">(Good <a href="#ref-Good1952">1952</a>)</span>, shown in equation <a href="ch-cv.html#eq:lscore">(16.1)</a>, has been proposed as a reasonable way to assess the posterior predictive distribution of a candidate model <span class="math inline">\(\mathcal{M}_1\)</span> given the data <span class="math inline">\(y\)</span>. This approach is reasonable because it takes into account the uncertainty of the predictions (compare this the mean square error). If new observations are well-accounted by the posterior predictive distribution, then the density of the posterior predictive distribution is high and so is its logarithm.</p>
<p><span class="math display" id="eq:lscore">\[\begin{equation}
u( \mathcal{M}_1, y_{pred}) = \log p(y_{pred}| y, \mathcal{M}_1)
\tag{16.1}
\end{equation}\]</span></p>
<p>Unlike the Bayes factor, the prior is absent from equation <a href="ch-cv.html#eq:lscore">(16.1)</a>. However, the prior does have a role here: The posterior predictive distribution is based on the posterior distribution <span class="math inline">\(p(\Theta\mid y)\)</span> (where <span class="math inline">\(\Theta\)</span> is a vector of all the parameters of the model), which, according to Bayes’ rule, depends on both priors and likelihood together. Recall equation <a href="ch-compbda.html#eq:postpp">(3.8)</a> in section <a href="ch-compbda.html#sec-ppd">3.6</a>, repeated here for convenience:</p>
<p><span class="math display" id="eq:postpp3">\[\begin{equation}
p(y_{pred}\mid y )=\int_\Theta p(y_{pred}\mid \Theta) p(\Theta\mid y)\, d\Theta
\tag{16.2}
\end{equation}\]</span></p>
<p>In equation <a href="ch-cv.html#eq:postpp3">(16.2)</a>, we are implicitly conditioning on the model under consideration:</p>
<p><span class="math display" id="eq:postpp2">\[\begin{equation}
p(y_{pred}\mid y,  \mathcal{M}_1)=\int_\Theta p(y_{pred}\mid \Theta, \mathcal{M}_1) p(\Theta\mid y, \mathcal{M}_1)\, d\Theta
\tag{16.3}
\end{equation}\]</span></p>
<p>The predicted data, <span class="math inline">\(y_{pred}\)</span>, are unknown to the utility function, so the utility function as presented in equation <a href="ch-cv.html#eq:lscore">(16.1)</a> cannot be evaluated. For this reason, we marginalize over <em>all possible future data</em> (calculating <span class="math inline">\(E[\log p(y_{pred}| y, \mathcal{M}_1)]\)</span>); this expression is called the expected log predictive density of model <span class="math inline">\(\mathcal{M}_1\)</span>:</p>
<p><span class="math display" id="eq:elpd">\[\begin{equation}
elpd = u(\mathcal{M}_1) = \int_{y_{pred}} p_t(y_{pred}) \log p(y_{pred} \mid y, \mathcal{M}_1) \, dy_{pred}
\tag{16.4}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(p_t\)</span> is the true data generating distribution. If we consider a set of models, the model with the highest <span class="math inline">\(elpd\)</span> is the model with the predictions that are the closest to those of the true data generating process.<a href="#fn44" class="footnote-ref" id="fnref44"><sup>44</sup></a> The intuition behind Equation <a href="ch-cv.html#eq:elpd">(16.4)</a> is that we are evaluating the predictive distribution of <span class="math inline">\(\mathcal{M}_1\)</span> over all possible future data weighted by how likely the future data is according to its true distribution. This means that observations that are very likely according to the true model will have a higher weight than unlikely ones.</p>
<p>But we don’t know the true data-generating distribution, <span class="math inline">\(p_t\)</span>! If we knew it, we wouldn’t be looking for the best model, since <span class="math inline">\(p_t\)</span> <em>is</em> the best model.</p>
<p>We can use the observed data distribution as a proxy for the true data generation distribution. So instead of weighting the predictive distribution by the true density of all possible future data, we just use the <span class="math inline">\(N\)</span> observations that we have. We can do that because our observations are presumed to be samples from the true distribution of the data: Under this assumption, observations with higher likelihood according to the true distribution of the data will also be more commonly obtained. This means that instead of integrating, we sum the posterior predictive density of the observations and we give to each observation the same weight; this is valid because observations that are more common will be already appearing more often (see also Box <a href="ch-cv.html#thm:integral">16.1</a>). This quantity is called <em>log pointwise predictive density</em> or <span class="math inline">\(lpd\)</span> <span class="citation">(without the <span class="math inline">\(1/N\)</span> in Vehtari, Gelman, and Gabry <a href="#ref-vehtariPracticalBayesianModel2017">2017</a><a href="#ref-vehtariPracticalBayesianModel2017">b</a>)</span>:</p>
<p><span class="math display" id="eq:elpdapprox">\[\begin{equation}
lpd = \frac{1}{N} \sum_{n=1}^{N} \log p(y_n|y, \mathcal{M}_1) 
\tag{16.5}
\end{equation}\]</span></p>
<p>The <span class="math inline">\(lpd\)</span> is an overestimate of <em>elpd</em> for actual future data, because the parameters of the posterior predictive distribution are estimated with the same observations that we are considering out-of-sample. Incidentally, this also explains why posterior predictive checks are generally optimistic and good fits cannot be taken too seriously. But they do serve the purpose of identifying very strong model misspecifications.<a href="#fn45" class="footnote-ref" id="fnref45"><sup>45</sup></a></p>
<p>However, we can obtain a more conservative estimate of the predictive performance of a model using cross-validation <span class="citation">(Geisser and Eddy <a href="#ref-GeisserEddy1979">1979</a>)</span>. This is explained next. <span class="citation">(As an aside, we mention here that there are also other alternatives to cross-validation; these are presented in Vehtari and Ojanen <a href="#ref-VehtariOjanen2012">2012</a>)</span>.</p>

<div class="extra">
<div class="theorem">
<p><span id="thm:integral" class="theorem"><strong>Box 16.1  </strong></span><strong>How do we get rid of the integral in the approximation of elpd?</strong></p>
</div>
<p>As an example, imagine that there are <span class="math inline">\(N\)</span> observations in an experiment. Suppose also that the true generative process (which is always unknown to us) is a Beta distribution:</p>
<p><span class="math display">\[\begin{equation}
p_t(y) = \mathit{ Beta}(y | 1, 3)
\end{equation}\]</span></p>
<p>Set <span class="math inline">\(N\)</span> and observe some simulated data <span class="math inline">\(y\)</span>:</p>
<div class="sourceCode" id="cb921"><pre class="sourceCode r fold-show"><code class="sourceCode r"><a class="sourceLine" id="cb921-1" data-line-number="1">N &lt;-<span class="st"> </span><span class="dv">10000</span></a>
<a class="sourceLine" id="cb921-2" data-line-number="2">y_data &lt;-<span class="st"> </span><span class="kw">rbeta</span>(N, <span class="dv">1</span>, <span class="dv">3</span>)</a>
<a class="sourceLine" id="cb921-3" data-line-number="3"><span class="kw">head</span>(y_data)</a></code></pre></div>
<pre><code>## [1] 0.222 0.466 0.509 0.117 0.614 0.362</code></pre>
<p>Let’s say that we fit the Bayesian model <span class="math inline">\(\mathcal{M}_{1}\)</span>, and somehow, after getting the posterior distribution, we are able derive the analytical form of its posterior predictive distribution for the model:</p>
<p><span class="math display">\[\begin{equation}
p(y_{pred} | y, \mathcal{M}_1) = \mathit{Beta}(y_{pred} | 2, 2)
\end{equation}\]</span></p>
<p>This distribution will tell us how likely different future observations will be, and it also entails that our future observations will be bounded by <span class="math inline">\(0\)</span> and <span class="math inline">\(1\)</span>. (Any observation outside this range will have a probability density of zero).</p>
<p>Imagine that we could know the true distribution of the data, <span class="math inline">\(p_t\)</span>, which is conveniently close to our posterior predictive distribution. This means that equation <a href="ch-cv.html#eq:elpd">(16.4)</a>, repeated below, is simple enough, and we know all its terms:</p>
<p><span class="math display">\[\begin{equation}
elpd = u(\mathcal{M}_1) = \int_{y_{pred}} p_t(y_{pred}) \log p(y_{pred} \mid y, \mathcal{M}_1)\, dy_{pred}
\end{equation}\]</span></p>
<p>We can compute this quantity in R. Notice that we don’t introduce the data at any point. However, the data had to be used when <code>p</code>, the posterior predictive distribution, was derived; we skipped that step here.</p>
<div class="sourceCode" id="cb923"><pre class="sourceCode r fold-show"><code class="sourceCode r"><a class="sourceLine" id="cb923-1" data-line-number="1"><span class="co"># True distribution:</span></a>
<a class="sourceLine" id="cb923-2" data-line-number="2">p_t &lt;-<span class="st"> </span><span class="cf">function</span>(y) <span class="kw">dbeta</span>(y, <span class="dv">1</span>, <span class="dv">3</span>)</a>
<a class="sourceLine" id="cb923-3" data-line-number="3"><span class="co"># Predictive distribution:</span></a>
<a class="sourceLine" id="cb923-4" data-line-number="4">p &lt;-<span class="st"> </span><span class="cf">function</span>(y) <span class="kw">dbeta</span>(y, <span class="dv">2</span>, <span class="dv">2</span>)</a>
<a class="sourceLine" id="cb923-5" data-line-number="5"><span class="co"># Integration:</span></a>
<a class="sourceLine" id="cb923-6" data-line-number="6">integrand &lt;-<span class="st"> </span><span class="cf">function</span>(y) <span class="kw">p_t</span>(y) <span class="op">*</span><span class="st"> </span><span class="kw">log</span>(<span class="kw">p</span>(y))</a>
<a class="sourceLine" id="cb923-7" data-line-number="7"><span class="kw">integrate</span>(<span class="dt">f =</span> integrand, <span class="dt">lower =</span> <span class="dv">0</span>, <span class="dt">upper =</span> <span class="dv">1</span>)</a></code></pre></div>
<pre><code>## -0.375 with absolute error &lt; 0.00000068</code></pre>
<p>Because we will never know <code>p_t</code>, this integral can be approximated using the data, <code>y_data</code>. It is possible to approximate the integration without any reference to <code>p_t</code> (see equation <a href="ch-cv.html#eq:elpdapprox">(16.5)</a>):</p>
<div class="sourceCode" id="cb925"><pre class="sourceCode r fold-show"><code class="sourceCode r"><a class="sourceLine" id="cb925-1" data-line-number="1"><span class="dv">1</span><span class="op">/</span>N <span class="op">*</span><span class="st"> </span><span class="kw">sum</span>(<span class="kw">log</span>(<span class="kw">p</span>(y_data)))</a></code></pre></div>
<pre><code>## [1] -0.356</code></pre>
<p>The main problem with this approach is that we are using <code>y_data</code> twice, once to derive <code>p</code>, the predictive posterior distribution, and once for the approximation of <span class="math inline">\(elpd\)</span>. We’ll see that cross-validation approaches rely on deriving the posterior predictive distribution with part of the data, and estimating the approximation to <span class="math inline">\(elpd\)</span> with unseen data. (Don’t worry that we don’t know the analytical form of the posterior predictive distribution: we saw that we could generate samples from that distribution based on the likelihood and posterior samples.)</p>
</div>

</div>
<div id="k-fold-and-leave-one-out-cross-validation" class="section level2 hasAnchor">
<h2><span class="header-section-number">16.2</span> K-fold and leave-one-out cross-validation<a href="ch-cv.html#k-fold-and-leave-one-out-cross-validation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The basic idea of K-fold cross-validation (K-fold-CV) is to split the N observations of our data into K subsets, such that each subset is used as a validation (or held-out) set, <span class="math inline">\(D_k\)</span>, while the remaining set (the training set), <span class="math inline">\(D_{-k}\)</span> is used for estimating the parameters and approximating <span class="math inline">\(p_t\)</span>, the true data distribution. The leave-one-out cross-validation (LOO-CV) method represent a special case of K-fold-CV where the training set only excludes one observation (<span class="math inline">\(K = N\)</span>). We estimate <span class="math inline">\(elpd\)</span> as follows.</p>
<p><span class="math display" id="eq:approxelpd">\[\begin{equation}
\widehat{elpd} =  \frac{1}{N} \sum_{n=1}^{N} \log  p(y_n| D_{\backslash n}, \mathcal{M}_1)
\tag{16.6}
\end{equation}\]</span></p>
<p>In equation <a href="ch-cv.html#eq:approxelpd">(16.6)</a>, each observation, <span class="math inline">\(y_n\)</span>, belongs to a certain “validation” fold, <span class="math inline">\(D_k\)</span>, and the predictive accuracy of <span class="math inline">\(y_n\)</span> is evaluated based on a posterior predictive model trained on the set, <span class="math inline">\(D_{\backslash n}\)</span>, which is the complete data set excluding the validation fold that contains the <span class="math inline">\(n\)</span>-th observation. This means that the posterior predictive distribution is used to evaluate <span class="math inline">\(y_{n}\)</span>, even though the posterior predictive distribution was derived without having information from that <span class="math inline">\(y_n\)</span>-th observation (in other words, the model was trained without that observation in the subset of the data, <span class="math inline">\(D_{-k}\)</span>).
In K-fold-CV, several observations are held out in same (validation) fold. This means that the the held-out observations are split among K folds, and <span class="math inline">\(D_{\backslash n}\)</span>, the data used to derive the posterior predictive distribution, contain only a proportion of the observations; this proportion is <span class="math inline">\((1 - 1/K)\)</span>. By contrast, in leave-one-out cross-validation, the held-out data set includes only one observation. That is, <span class="math inline">\(D_{\backslash n}\)</span> contains the entire data set except for one data point, <span class="math inline">\(y_n\)</span>, with <span class="math inline">\(n=1,\dots,N\)</span>. Box <a href="ch-cv.html#thm:CV-alg">16.2</a> explains the algorithm in detail.</p>
<p><span class="citation">Vehtari, Gelman, and Gabry (<a href="#ref-vehtariPracticalBayesianModel2017">2017</a><a href="#ref-vehtariPracticalBayesianModel2017">b</a>)</span> define the expected log <em>pointwise</em> predictive density of the observation <span class="math inline">\(y_n\)</span> as follows:</p>
<p><span class="math display">\[\begin{equation}
\widehat{elpd}_{n} =  \log  p(y_n| D_{\backslash n} , \mathcal{M}_1)
\end{equation}\]</span></p>
<p>This quantity indicates the predictive accuracy of the model <span class="math inline">\(\mathcal{M}_1\)</span> for a single observation, and it is reported in the package <code>loo</code> and also in <code>brms</code>. In addition, the <code>loo</code> package uses the sum of the expected log pointwise predictive density, <span class="math inline">\(\sum elpd_n\)</span> (equation <a href="ch-cv.html#eq:approxelpd">(16.6)</a> without <span class="math inline">\(\frac{1}{N}\)</span>) as a measure of predictive accuracy (this is referred as <code>elpd_loo</code> or <code>elpd_kfold</code> by <code>loo</code> and <code>brms</code> packages). For model comparison, the difference between the <span class="math inline">\(\sum elpd_n\)</span> of competing models can be computed, including the standard deviation of the sampling distribution of the difference. It’s important to notice that we are calculating an approximation to the expectation that we actually want to compute, <span class="math inline">\(elpd\)</span>, and thus we always need to consider its inherent randomness <span class="citation">(Vehtari, Simpson, et al. <a href="#ref-vehtariLimitationsLimitationsBayesian2019">2019</a>)</span>.</p>
<p>Unlike what is common with information criterion methods (such as the Akaike Information Criterion, AIC, and the Deviance Information Criterion, DIC), a higher <span class="math inline">\(\widehat{elpd}\)</span> means higher predictive accuracy. An alternative to using <span class="math inline">\(\widehat{elpd}\)</span> is to examine <span class="math inline">\(-2\times \widehat{elpd}\)</span>, which is equivalent to deviance, and is called the LOO Information Criterion (LOOIC) <span class="citation">(see section 22 of Vehtari <a href="#ref-FAQCV">2022</a>)</span>.</p>
<p>The approximation to the true data generating distribution is worse when fewer observations are used, and thus ideally we would set <span class="math inline">\(K =N\)</span>, and thus compute LOO-CV rather than K-fold-CV. The main advantage of LOO-CV is its robustness, since the training set is as similar as possible to the observed data, and the same observations are never used simultaneously for training and evaluating the predictions. A major disadvantage is the computational burden <span class="citation">(Vehtari and Ojanen <a href="#ref-VehtariOjanen2012">2012</a>)</span>, since we need to fit a model as many times as the number of observations. The package <code>loo</code> provides an approximation to LOO-CV, Pareto smoothed importance sampling leave-one-out <span class="citation">(PSIS-LOO; Vehtari and Gelman <a href="#ref-VehtariGelman2015Pareto">2015</a>; Vehtari, Gelman, and Gabry <a href="#ref-vehtariPracticalBayesianModel2017">2017</a><a href="#ref-vehtariPracticalBayesianModel2017">b</a>)</span> which, as we show next, is relatively straightforward to use in <code>brms</code> and in Stan models (see <a href="https://mc-stan.org/loo/articles/loo2-with-rstan.html" class="uri">https://mc-stan.org/loo/articles/loo2-with-rstan.html</a>). However, in some cases, its estimates can be unreliable; this is indicated by the estimated shape parameter <span class="math inline">\(\hat{k}\)</span> of the generalized Pareto distribution. In those cases, where one or several pointwise predictive density have associated large (larger than 0.5 or 0.7, see <a href="https://mc-stan.org/loo/reference/pareto-k-diagnostic.html" class="uri">https://mc-stan.org/loo/reference/pareto-k-diagnostic.html</a>) <span class="math inline">\(\hat{k}\)</span>, either (i) the problematic predictions can be refitted with exact LOO-CV, (ii) one can try some additional computations using the existing posterior sample based on the moment matching approximation <span class="citation">(see <a href="https://mc-stan.org/loo/articles/loo2-moment-matching.html" class="uri">https://mc-stan.org/loo/articles/loo2-moment-matching.html</a> and Paananen et al. <a href="#ref-Paananen_2021">2021</a>)</span>, or (iii) one can abandon PSIS-LOO-CV and use K-fold-CV, with K typically set to 10.</p>
<p>One of the main disadvantages of cross-validation (in comparison with Bayes factor at least) is that the numerical difference in predictive accuracy is hard to interpret. As a rule of thumb, it has been suggested that if the <code>elpd</code> difference (<code>elpd_diff</code> in the <code>loo</code> package) is less than 4, the difference is small, and if it is larger than 4, one should compare that difference to its standard error (<code>se_diff</code>) <span class="citation">(see section 16 of Vehtari <a href="#ref-FAQCV">2022</a>)</span>.</p>

<div class="extra">
<div class="theorem">
<p><span id="thm:CV-alg" class="theorem"><strong>Box 16.2  </strong></span><strong>The cross-validation algorithm</strong></p>
</div>
<p>Here we spell out the Bayesian cross-validation algorithm in detail:</p>
<ol style="list-style-type: decimal">
<li><p>Split the data pseudo-randomly into <span class="math inline">\(K\)</span> held-out or validation sets <span class="math inline">\(D_k\)</span>, (where <span class="math inline">\(k=1,\dots,K\)</span>) that are a fraction of the original data, and <span class="math inline">\(K\)</span> training sets, <span class="math inline">\(D_{-k}\)</span>. The length of the held-out data vector <span class="math inline">\(D_k\)</span> is approximately <span class="math inline">\(1/K\)</span>-th the size of the full data set. It is common to use <span class="math inline">\(K=10\)</span> for K-fold-CV. For LOO-CV, K should be set to the number of observations.</p></li>
<li><p>Fit <span class="math inline">\(K\)</span> models using each of the <span class="math inline">\(K\)</span> training sets, and obtain posterior distributions <span class="math inline">\(p_{-k} (\Theta) = p(\Theta\mid D_{-k})\)</span>, where <span class="math inline">\(\Theta\)</span> is the vector of model parameters.</p></li>
<li><p>Each posterior distribution <span class="math inline">\(p(\Theta\mid D_{-k})\)</span> is used to compute the predictive accuracy for each held-out data-point <span class="math inline">\(y_n\)</span> in the vector <span class="math inline">\(D_{k}\)</span>:</p></li>
</ol>
<p><span class="math display">\[\begin{equation}
 \widehat{elpd}_n = \log p(y_n \mid D_{-k}) %= \log \int p(y_n \mid \Theta) p(\Theta\mid D_{-k})\, d\Theta
  \end{equation}\]</span></p>
<p>Given that the posterior distribution <span class="math inline">\(p(\Theta\mid D_{-k})\)</span> is summarized by <span class="math inline">\(S\)</span> samples, the log predictive density for each data point <span class="math inline">\(y_n\)</span> in a data vector <span class="math inline">\(D_k\)</span> can be approximated as follows:</p>
<p><span class="math display" id="eq:pwkfold">\[\begin{equation}
    \widehat{elpd}_n = \log \left(\frac{1}{S} \sum_{s=1}^S p(y_n\mid \Theta^{k,s})\right)
    \tag{16.7}
  \end{equation}\]</span></p>
<p>where <span class="math inline">\(\Theta^{k,s}\)</span> corresponds to the sample <span class="math inline">\(s\)</span> of the posterior of the model fit to the validation set <span class="math inline">\(-k\)</span>.</p>
<ol start="5" style="list-style-type: decimal">
<li>We obtain the <span class="math inline">\(elpd_{kfold}\)</span> (or <span class="math inline">\(elpd_{loo}\)</span>) for all the held-out data points by summing up the <span class="math inline">\(\widehat{elpd}_n\)</span>:</li>
</ol>
<p><span class="math display" id="eq:totalkfold">\[\begin{equation} 
    elpd_{kfold} = \sum_{n=1}^n \widehat{elpd}_n
    \tag{16.8}
  \end{equation}\]</span></p>
<p>We can also compute the standard deviation of the sampling distribution (the standard error) by multiplying the standard deviation (or square root of variance) of the <span class="math inline">\(N\)</span> components by <span class="math inline">\(\sqrt{N}\)</span>. Letting <span class="math inline">\(\widehat{ELPD}\)</span> be the vector <span class="math inline">\(\widehat{elpd}_1,\dots,\widehat{elpd}_N\)</span>, we can write:</p>
<p><span class="math display" id="eq:sekfold">\[\begin{equation}
se(\widehat{elpd}) = \sqrt{N \mathit{Var}(\widehat{ELPD})}
\tag{16.9}
\end{equation}\]</span></p>
<p>The difference between the <span class="math inline">\(elpd_{kfold}\)</span> of two competing models, <span class="math inline">\(\mathcal{M}_1\)</span> and <span class="math inline">\(\mathcal{M}_2\)</span> , is a measure of relative predictive performance. We can also compute the standard error of their difference using the formula discussed in <span class="citation">Vehtari, Gelman, and Gabry (<a href="#ref-vehtariPracticalBayesianModel2017">2017</a><a href="#ref-vehtariPracticalBayesianModel2017">b</a>)</span>.</p>
<p><span class="math display" id="eq:sekfolddiff">\[\begin{equation}
se(\widehat{elpd}_{\mathcal{M}1} - \widehat{elpd}_{\mathcal{M}2}) = \sqrt{N \mathit{Var}(\widehat{ELPD_{\mathcal{M}1}} - \widehat{ELPD_{\mathcal{M}2}})}
\tag{16.10}
\end{equation}\]</span></p>
</div>

</div>
<div id="testing-the-n400-effect-using-cross-validation" class="section level2 hasAnchor">
<h2><span class="header-section-number">16.3</span> Testing the N400 effect using cross-validation<a href="ch-cv.html#testing-the-n400-effect-using-cross-validation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>As we did in section <a href="ch-bf.html#sec-N400BF">15.2</a> with the Bayes factor, we revisit section <a href="ch-hierarchical.html#sec-N400hierarchical">5.2</a>, where we estimated the effect of cloze probability on the N400 average signal. We consider two models here, a model that includes the effect of cloze probability, such as <code>fit_N400_sih</code> from section <a href="ch-hierarchical.html#sec-sih">5.2.5</a>, and a null model.</p>
<p>We can verify that the likelihood that we fit was appropriate for a hierarchical model that includes an effect of cloze probability as follows:</p>
<div class="sourceCode" id="cb927"><pre class="sourceCode r fold-show"><code class="sourceCode r"><a class="sourceLine" id="cb927-1" data-line-number="1"><span class="kw">formula</span>(fit_N400_sih) </a></code></pre></div>
<pre><code>## n400 ~ c_cloze + (c_cloze | subj) + (c_cloze | item)</code></pre>
<p>In contrast to the situation with Bayes factor, priors are less critical for cross-validation. Priors are only important in cross-validation to the extent that they affect parameter estimation: As we saw previously, very narrow priors can bias the posterior; and unrealistically wide priors can lead to convergence problems. The number of samples is also less critical than with Bayes factor, most of the uncertainty in the estimates of the <span class="math inline">\(\widehat{elpd}\)</span> is due to the number of observations. However, a very small number of samples can affect the <span class="math inline">\(\widehat{elpd}\)</span> because the posterior estimation will be affected by the small sample size.
We update our previous formula to define a null model as follows:</p>
<div class="sourceCode" id="cb929"><pre class="sourceCode r fold-show"><code class="sourceCode r"><a class="sourceLine" id="cb929-1" data-line-number="1">fit_N400_sih_null &lt;-<span class="st"> </span><span class="kw">update</span>(fit_N400_sih, <span class="op">~</span><span class="st"> </span>. <span class="op">-</span><span class="st"> </span>c_cloze) </a></code></pre></div>
<div id="cross-validation-with-psis-loo" class="section level3 hasAnchor">
<h3><span class="header-section-number">16.3.1</span> Cross-validation with PSIS-LOO<a href="ch-cv.html#cross-validation-with-psis-loo" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Estimating <span class="math inline">\(elpd\)</span> using PSIS-LOO is very straightforward with <code>brms</code>, which uses the package <code>loo</code> as a back-end. There is no need to refit the model, and <code>loo</code> takes care of the applying the PSIS approximation to derive estimates and standard errors.</p>
<div class="sourceCode" id="cb930"><pre class="sourceCode r fold-show"><code class="sourceCode r"><a class="sourceLine" id="cb930-1" data-line-number="1">(loo_sih &lt;-<span class="st"> </span><span class="kw">loo</span>(fit_N400_sih))</a></code></pre></div>
<pre><code>## 
## Computed from 4000 by 2863 log-likelihood matrix
## 
##          Estimate   SE
## elpd_loo -11092.9 46.7
## p_loo        81.5  2.8
## looic     22185.7 93.4
## ------
## Monte Carlo SE of elpd_loo is 0.1.
## 
## All Pareto k estimates are good (k &lt; 0.5).
## See help(&#39;pareto-k-diagnostic&#39;) for details.</code></pre>
<div class="sourceCode" id="cb932"><pre class="sourceCode r fold-show"><code class="sourceCode r"><a class="sourceLine" id="cb932-1" data-line-number="1">(loo_sih_null &lt;-<span class="st"> </span><span class="kw">loo</span>(fit_N400_sih_null))</a></code></pre></div>
<pre><code>## 
## Computed from 4000 by 2863 log-likelihood matrix
## 
##          Estimate   SE
## elpd_loo -11095.5 46.5
## p_loo        89.5  3.0
## looic     22191.0 93.1
## ------
## Monte Carlo SE of elpd_loo is 0.2.
## 
## All Pareto k estimates are good (k &lt; 0.5).
## See help(&#39;pareto-k-diagnostic&#39;) for details.</code></pre>
<p>The function <code>loo</code> reports three quantities with their standard error:</p>
<ol style="list-style-type: decimal">
<li><code>elpd_loo</code> is the sum of pointwise predictive accuracy (a larger, less negative number indicates better predictions).</li>
<li><code>p_loo</code> is an estimate of effective complexity of the model; asymptotically and under certain regularity conditions, <code>p_loo</code> can be interpreted as the effective number of parameters. If <code>p_loo</code> is larger than the number of data points or parameters, this may indicate a severe model misspecification.</li>
<li><code>looic</code> is simply <code>-2*elpd_loo</code>, the <span class="math inline">\(elpd\)</span> on the deviance scale. This is called the information criterion, and is mainly provided for historical reasons: other information criteria like the AIC (Akaike Information Criterion) and the DIC (Deviance Information Criterion) are commonly used in model selection <span class="citation">(Venables and Ripley <a href="#ref-venablesripley">2002</a>; Lunn et al. <a href="#ref-lunn2012bugs">2012</a>)</span>.</li>
</ol>
<p>It’s important to bear in mind that the PSIS-LOO approximation to LOO can only be trusted if Pareto k estimates (<span class="math inline">\(\hat{k}\)</span>) are smaller than 0.7. To compare the models, we need to take a look at the difference between <code>elpd_loo</code> and the standard error of that difference:</p>
<div class="sourceCode" id="cb934"><pre class="sourceCode r fold-show"><code class="sourceCode r"><a class="sourceLine" id="cb934-1" data-line-number="1"><span class="kw">loo_compare</span>(loo_sih, loo_sih_null)</a></code></pre></div>
<pre><code>##                   elpd_diff se_diff
## fit_N400_sih       0.0       0.0   
## fit_N400_sih_null -2.6       2.5</code></pre>
<p>Although the model that includes cloze probability as a predictor has higher predictive accuracy, the difference is smaller than 4 and it’s smaller than two SE. This means that from the perspective LOO-CV, both models are almost indistinguishable! In fact, the same will happen if we compare the model with logarithmic predictability to the linear or null model; see exercise <a href="ch-cv.html#exr:logcv">16.1</a>.</p>
<p>We could also check whether the alternative model is making good predictions for some range of values by examining the difference in pointwise predictive accuracy as a function of, for example, cloze probability. In the following plot, we subtract the predictive accuracy of the alternative model from the accuracy of the null model; we can now interpret larger differences as an advantage for the alternative model. However, we see that as far as posterior predictive accuracy goes, both models are quite similar. Figure <a href="ch-cv.html#fig:diffpredacc">16.1</a> shows that the difference in predictive accuracy is symmetrical with respect to the zero; as we go further from the mean cloze (which is around <span class="math inline">\(0.5\)</span>), the differences in predictions are larger but they span over positive and negative values.</p>
<p>The following code stores the difference in predictive accuracy of the models in a variable and plots it in Figure <a href="ch-cv.html#fig:diffpredacc">16.1</a>.</p>
<div class="sourceCode" id="cb936"><pre class="sourceCode r fold-show"><code class="sourceCode r"><a class="sourceLine" id="cb936-1" data-line-number="1">df_eeg &lt;-<span class="st"> </span><span class="kw">mutate</span>(df_eeg,</a>
<a class="sourceLine" id="cb936-2" data-line-number="2">  <span class="dt">diff_elpd =</span> loo_sih<span class="op">$</span>pointwise[, <span class="st">&quot;elpd_loo&quot;</span>] <span class="op">-</span></a>
<a class="sourceLine" id="cb936-3" data-line-number="3"><span class="st">    </span>loo_sih_null<span class="op">$</span>pointwise[, <span class="st">&quot;elpd_loo&quot;</span>]</a>
<a class="sourceLine" id="cb936-4" data-line-number="4">)</a>
<a class="sourceLine" id="cb936-5" data-line-number="5"><span class="kw">ggplot</span>(df_eeg, <span class="kw">aes</span>(<span class="dt">x =</span> cloze, <span class="dt">y =</span> diff_elpd)) <span class="op">+</span></a>
<a class="sourceLine" id="cb936-6" data-line-number="6"><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">alpha =</span> <span class="fl">.4</span>, <span class="dt">position =</span> <span class="kw">position_jitter</span>(<span class="dt">w =</span> <span class="fl">.001</span>, <span class="dt">h =</span> <span class="dv">0</span>))</a></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:diffpredacc"></span>
<img src="bookdown_files/figure-html/diffpredacc-1.svg" alt="The difference in predictive accuracy between a model including the effect of cloze and a null model. A larger (more positive) difference indicates an advantage for the model that includes the effect of cloze." width="672" />
<p class="caption">
FIGURE 16.1: The difference in predictive accuracy between a model including the effect of cloze and a null model. A larger (more positive) difference indicates an advantage for the model that includes the effect of cloze.
</p>
</div>
<p>This is unsettling because the effect of cloze probability on the N400 has been replicated in numerous studies. We would expect to see that, similar to the Bayes factor, cross-validation techniques will also show that a model that includes cloze probability as a predictor is superior to a model without it. Before we discuss why we don’t see a large difference, let us check what K-fold-CV yields.</p>
</div>
<div id="cross-validation-with-k-fold" class="section level3 hasAnchor">
<h3><span class="header-section-number">16.3.2</span> Cross-validation with K-fold<a href="ch-cv.html#cross-validation-with-k-fold" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Estimating <span class="math inline">\(elpd\)</span> using k-fold-CV has the advantage of omitting one layer of approximations: the <span class="math inline">\(elpd\)</span> based on PSIS-LOO-CV is an approximation of the <span class="math inline">\(elpd\)</span> based on <em>exact</em> LOO-CV (and we saw how any cross-validation approach gave as an approximation to the true <span class="math inline">\(elpd\)</span>). This means that we don’t need to worry about <span class="math inline">\(\hat{k}\)</span>. However, K-fold also uses a reduced training set in comparison with LOO, worsening the approximation to the true generating process <span class="math inline">\(p_{t}\)</span>.</p>
<p>Because we divide our data into folds, we need to think about the way we split the data: We could do it randomly, but we take the risk that in some of the training sets, observations from a subject, for example, would be completely absent. This will lead to large differences in predictive accuracy between folds. We can avoid that by using stratification: we split the observations into groups ensuring that relative category frequencies are approximately preserved. We do this with the <code>kfold()</code> function, available in the package <code>brms</code>, by setting <code>folds = &quot;stratified&quot;</code> and <code>group = &quot;subj&quot;</code>, by default <code>K</code> is set to 10, but that can be changed.</p>
<div class="sourceCode" id="cb937"><pre class="sourceCode r fold-show"><code class="sourceCode r"><a class="sourceLine" id="cb937-1" data-line-number="1">kfold_sih &lt;-<span class="st"> </span><span class="kw">kfold</span>(fit_N400_sih,</a>
<a class="sourceLine" id="cb937-2" data-line-number="2">                    <span class="dt">folds =</span> <span class="st">&quot;stratified&quot;</span>,</a>
<a class="sourceLine" id="cb937-3" data-line-number="3">                    <span class="dt">group =</span> <span class="st">&quot;subj&quot;</span>)</a></code></pre></div>
<div class="sourceCode" id="cb938"><pre class="sourceCode r fold-show"><code class="sourceCode r"><a class="sourceLine" id="cb938-1" data-line-number="1">kfold_sih_null &lt;-<span class="st"> </span><span class="kw">kfold</span>(fit_N400_sih_null,</a>
<a class="sourceLine" id="cb938-2" data-line-number="2">                         <span class="dt">folds =</span> <span class="st">&quot;stratified&quot;</span>,</a>
<a class="sourceLine" id="cb938-3" data-line-number="3">                         <span class="dt">group =</span> <span class="st">&quot;subj&quot;</span>)</a></code></pre></div>
<p>Running K-fold CV takes some time since each model is refit K times. We can now inspect the <span class="math inline">\(elpd\)</span> values:</p>
<div class="sourceCode" id="cb939"><pre class="sourceCode r fold-show"><code class="sourceCode r"><a class="sourceLine" id="cb939-1" data-line-number="1">kfold_sih</a></code></pre></div>
<pre><code>## 
## Based on 10-fold cross-validation
## 
##            Estimate   SE
## elpd_kfold -11097.4 46.6
## p_kfold        85.7  3.5
## kfoldic     22194.8 93.1</code></pre>
<div class="sourceCode" id="cb941"><pre class="sourceCode r fold-show"><code class="sourceCode r"><a class="sourceLine" id="cb941-1" data-line-number="1">kfold_sih_null</a></code></pre></div>
<pre><code>## 
## Based on 10-fold cross-validation
## 
##            Estimate   SE
## elpd_kfold -11098.7 46.5
## p_kfold        93.3  3.7
## kfoldic     22197.5 93.0</code></pre>
<p>Compare the two models using <code>loo_compare</code> (this function is usedf for both PSIS-LOO-CV and K-fold-CV):</p>
<div class="sourceCode" id="cb943"><pre class="sourceCode r fold-show"><code class="sourceCode r"><a class="sourceLine" id="cb943-1" data-line-number="1"><span class="kw">loo_compare</span>(kfold_sih, kfold_sih_null)</a></code></pre></div>
<pre><code>##                   elpd_diff se_diff
## fit_N400_sih       0.0       0.0   
## fit_N400_sih_null -1.3       4.1</code></pre>
<p>We see that, in this case, the results with K-fold-CV and PSIS-LOO-CV are quite similar: We can’t really distinguish between the two models.</p>
</div>
<div id="leave-one-group-out-cross-validation" class="section level3 hasAnchor">
<h3><span class="header-section-number">16.3.3</span> Leave-one-group-out cross-validation<a href="ch-cv.html#leave-one-group-out-cross-validation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>An alternative to splitting the observations randomly using stratification is to treat naturally occurring clusters as folds, this is leave-one-group-out cross-validation (LOGO-CV). By doing this we can interpret the output of cross-validation as the capacity of the models for generalizing to unseen clusters. We implement LOGO-CV with subjects.</p>
<div class="sourceCode" id="cb945"><pre class="sourceCode r fold-show"><code class="sourceCode r"><a class="sourceLine" id="cb945-1" data-line-number="1">logo_sih &lt;-<span class="st"> </span><span class="kw">kfold</span>(fit_N400_sih,</a>
<a class="sourceLine" id="cb945-2" data-line-number="2">                    <span class="dt">group =</span> <span class="st">&quot;subj&quot;</span>)</a></code></pre></div>
<div class="sourceCode" id="cb946"><pre class="sourceCode r fold-show"><code class="sourceCode r"><a class="sourceLine" id="cb946-1" data-line-number="1">logo_sih_null &lt;-<span class="st"> </span><span class="kw">kfold</span>(fit_N400_sih_null,</a>
<a class="sourceLine" id="cb946-2" data-line-number="2">                         <span class="dt">group =</span> <span class="st">&quot;subj&quot;</span>)</a></code></pre></div>
<p>Running LOGO CV with subjects takes some time since each model is refit as many times as we have subjects, in this case 37 times. We can now inspect the <span class="math inline">\(elpd\)</span> estimates and evaluate which model generalizes better to unseen subjects.</p>
<p>We compare the models using <code>loo_compare</code>.</p>
<div class="sourceCode" id="cb947"><pre class="sourceCode r fold-show"><code class="sourceCode r"><a class="sourceLine" id="cb947-1" data-line-number="1"><span class="kw">loo_compare</span>(logo_sih, logo_sih_null)</a></code></pre></div>
<pre><code>##                   elpd_diff se_diff
## fit_N400_sih       0.0       0.0   
## fit_N400_sih_null -1.5       2.3</code></pre>
<p>As before, and as with PSIS-LOO-CV, K-fold-CV, we can’t distinguish between the two models.</p>
</div>
</div>
<div id="sec-logcv" class="section level2 hasAnchor">
<h2><span class="header-section-number">16.4</span> Comparing different likelihoods with cross-validation<a href="ch-cv.html#sec-logcv" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We now compare two models with different likelihoods. In section <a href="ch-compbda.html#sec-lognormal">3.7.2</a> from chapter <a href="ch-compbda.html#ch-compbda">3</a>, we saw how a log-normal distribution was a more appropriate likelihood than a normal distribution for response times data. This was because response times are bounded by zero and right skewed, unlike the symmetrical normal distribution. Now we’ll use PSIS-LOO-CV to compare the predictive accuracy of the Stroop model from section <a href="ch-hierarchical.html#sec-stroop">5.3</a> in chapter <a href="ch-hierarchical.html#ch-hierarchical">5</a>, which assumed a log-normal likelihood to fit response times of correct responses with a similar model which assumes a normal likelihood.</p>
<p>Load the data from <code>bcogsci</code>, create a sum coded predictor (see chapter <a href="ch-contr.html#ch-contr">8</a> for more details), and fit the model as in section <a href="ch-hierarchical.html#sec-stroop">5.3</a>.</p>
<div class="sourceCode" id="cb949"><pre class="sourceCode r fold-show"><code class="sourceCode r"><a class="sourceLine" id="cb949-1" data-line-number="1"><span class="kw">data</span>(<span class="st">&quot;df_stroop&quot;</span>)</a>
<a class="sourceLine" id="cb949-2" data-line-number="2">df_stroop &lt;-<span class="st"> </span>df_stroop <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb949-3" data-line-number="3"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">c_cond =</span> <span class="kw">if_else</span>(condition <span class="op">==</span><span class="st"> &quot;Incongruent&quot;</span>, <span class="dv">1</span>, <span class="dv">-1</span>))</a></code></pre></div>
<div class="sourceCode" id="cb950"><pre class="sourceCode r fold-show"><code class="sourceCode r"><a class="sourceLine" id="cb950-1" data-line-number="1">fit_stroop_log &lt;-<span class="st"> </span><span class="kw">brm</span>(RT <span class="op">~</span><span class="st"> </span>c_cond <span class="op">+</span><span class="st"> </span>(c_cond <span class="op">|</span><span class="st"> </span>subj),</a>
<a class="sourceLine" id="cb950-2" data-line-number="2">  <span class="dt">family =</span> <span class="kw">lognormal</span>(),</a>
<a class="sourceLine" id="cb950-3" data-line-number="3">  <span class="dt">prior =</span></a>
<a class="sourceLine" id="cb950-4" data-line-number="4">    <span class="kw">c</span>(</a>
<a class="sourceLine" id="cb950-5" data-line-number="5">      <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">6</span>, <span class="fl">1.5</span>), <span class="dt">class =</span> Intercept),</a>
<a class="sourceLine" id="cb950-6" data-line-number="6">      <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="dt">class =</span> b),</a>
<a class="sourceLine" id="cb950-7" data-line-number="7">      <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="dt">class =</span> sigma),</a>
<a class="sourceLine" id="cb950-8" data-line-number="8">      <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="dt">class =</span> sd),</a>
<a class="sourceLine" id="cb950-9" data-line-number="9">      <span class="kw">prior</span>(<span class="kw">lkj</span>(<span class="dv">2</span>), <span class="dt">class =</span> cor)</a>
<a class="sourceLine" id="cb950-10" data-line-number="10">    ),</a>
<a class="sourceLine" id="cb950-11" data-line-number="11">  <span class="dt">data =</span> df_stroop</a>
<a class="sourceLine" id="cb950-12" data-line-number="12">)</a></code></pre></div>
<p>Calculate the <span class="math inline">\(elpd_{loo}\)</span> for the original model with the log-normal likelihood:</p>
<div class="sourceCode" id="cb951"><pre class="sourceCode r fold-show"><code class="sourceCode r"><a class="sourceLine" id="cb951-1" data-line-number="1">loo_stroop_log &lt;-<span class="st"> </span><span class="kw">loo</span>(fit_stroop_log)</a></code></pre></div>
<div class="sourceCode" id="cb952"><pre class="sourceCode r fold-show"><code class="sourceCode r"><a class="sourceLine" id="cb952-1" data-line-number="1">loo_stroop_log </a></code></pre></div>
<pre><code>## 
## Computed from 4000 by 3058 log-likelihood matrix
## 
##          Estimate    SE
## elpd_loo -19858.7  93.6
## p_loo        60.5   4.1
## looic     39717.4 187.1
## ------
## Monte Carlo SE of elpd_loo is 0.1.
## 
## Pareto k diagnostic values:
##                          Count Pct.    Min. n_eff
## (-Inf, 0.5]   (good)     3057  100.0%  1069      
##  (0.5, 0.7]   (ok)          1    0.0%  203       
##    (0.7, 1]   (bad)         0    0.0%  &lt;NA&gt;      
##    (1, Inf)   (very bad)    0    0.0%  &lt;NA&gt;      
## 
## All Pareto k estimates are ok (k &lt; 0.7).
## See help(&#39;pareto-k-diagnostic&#39;) for details.</code></pre>
<p>The summary shows that <span class="math inline">\(k\)</span> estimates are ok.</p>
<p>Now fit a similar model where we assume that the likelihood is a normal distribution. It’s important now to change the priors since they are on a different scale (namely, in milliseconds). We choose reasonable but wide priors. We can do a sensitivity analysis, if we are unsure about the priors. However, unlike what happened with the Bayes factor in chapter <a href="ch-bf.html#ch-bf">15</a>, priors are going to affect cross-validation based model comparison only as far as they have a noticeable effect on the posterior distribution.</p>
<div class="sourceCode" id="cb954"><pre class="sourceCode r fold-show"><code class="sourceCode r"><a class="sourceLine" id="cb954-1" data-line-number="1">fit_stroop_normal &lt;-<span class="st"> </span><span class="kw">brm</span>(RT <span class="op">~</span><span class="st"> </span>c_cond <span class="op">+</span><span class="st"> </span>(c_cond <span class="op">|</span><span class="st"> </span>subj),</a>
<a class="sourceLine" id="cb954-2" data-line-number="2">  <span class="dt">family =</span> <span class="kw">gaussian</span>(),</a>
<a class="sourceLine" id="cb954-3" data-line-number="3">  <span class="dt">prior =</span></a>
<a class="sourceLine" id="cb954-4" data-line-number="4">    <span class="kw">c</span>(</a>
<a class="sourceLine" id="cb954-5" data-line-number="5">      <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">400</span>, <span class="dv">600</span>), <span class="dt">class =</span> Intercept),</a>
<a class="sourceLine" id="cb954-6" data-line-number="6">      <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">100</span>), <span class="dt">class =</span> b),</a>
<a class="sourceLine" id="cb954-7" data-line-number="7">      <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">300</span>), <span class="dt">class =</span> sigma),</a>
<a class="sourceLine" id="cb954-8" data-line-number="8">      <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">300</span>), <span class="dt">class =</span> sd),</a>
<a class="sourceLine" id="cb954-9" data-line-number="9">      <span class="kw">prior</span>(<span class="kw">lkj</span>(<span class="dv">2</span>), <span class="dt">class =</span> cor)</a>
<a class="sourceLine" id="cb954-10" data-line-number="10">    ),</a>
<a class="sourceLine" id="cb954-11" data-line-number="11">  <span class="dt">data =</span> df_stroop</a>
<a class="sourceLine" id="cb954-12" data-line-number="12">)</a></code></pre></div>
<p>If we try to obtain <span class="math inline">\(elpd\)</span> based on PSIS-LOO-CV, we’ll find several large <span class="math inline">\(\hat{k}\)</span> values.</p>
<div class="sourceCode" id="cb955"><pre class="sourceCode r fold-show"><code class="sourceCode r"><a class="sourceLine" id="cb955-1" data-line-number="1">loo_stroop_normal &lt;-<span class="st"> </span><span class="kw">loo</span>(fit_stroop_normal)</a></code></pre></div>
<div class="sourceCode" id="cb956"><pre class="sourceCode r fold-show"><code class="sourceCode r"><a class="sourceLine" id="cb956-1" data-line-number="1">loo_stroop_normal</a></code></pre></div>
<pre><code>## 
## Computed from 4000 by 3058 log-likelihood matrix
## 
##          Estimate    SE
## elpd_loo -21588.9 480.5
## p_loo       117.5  67.2
## looic     43177.8 961.1
## ------
## Monte Carlo SE of elpd_loo is NA.
## 
## Pareto k diagnostic values:
##                          Count Pct.    Min. n_eff
## (-Inf, 0.5]   (good)     3054  99.9%   1305      
##  (0.5, 0.7]   (ok)          1   0.0%   84        
##    (0.7, 1]   (bad)         2   0.1%   43        
##    (1, Inf)   (very bad)    1   0.0%   3         
## See help(&#39;pareto-k-diagnostic&#39;) for details.</code></pre>
<p>We can try the model matching approximation for problematic observations, by setting <code>moment_match = TRUE</code> in the <code>loo()</code> call (and we also need to fit the model with <code>save_pars = save_pars(all = TRUE)</code>). In this particular case, this approximation won’t solve our problem. We skip that step here. We can use exact LOO (rather than its approximation) for the problematic observations. By setting <code>reloo = TRUE</code>, we re-fit the 3 problematic observations with <span class="math inline">\(\hat{k}\)</span> values over <span class="math inline">\(0.7\)</span> using exact LOO-CV.</p>
<div class="sourceCode" id="cb958"><pre class="sourceCode r fold-show"><code class="sourceCode r"><a class="sourceLine" id="cb958-1" data-line-number="1">loo_stroop_normal &lt;-<span class="st"> </span><span class="kw">loo</span>(fit_stroop_normal, <span class="dt">reloo =</span> <span class="ot">TRUE</span>)</a></code></pre></div>
<div class="sourceCode" id="cb959"><pre class="sourceCode r fold-show"><code class="sourceCode r"><a class="sourceLine" id="cb959-1" data-line-number="1">loo_stroop_normal</a></code></pre></div>
<pre><code>## 
## Computed from 4000 by 3058 log-likelihood matrix
## 
##          Estimate     SE
## elpd_loo -21702.3  589.5
## p_loo       230.7  180.2
## looic     43404.7 1178.9
## ------
## Monte Carlo SE of elpd_loo is 0.3.
## 
## Pareto k diagnostic values:
##                          Count Pct.    Min. n_eff
## (-Inf, 0.5]   (good)     3057  100.0%  1         
##  (0.5, 0.7]   (ok)          1    0.0%  77        
##    (0.7, 1]   (bad)         0    0.0%  &lt;NA&gt;      
##    (1, Inf)   (very bad)    0    0.0%  &lt;NA&gt;      
## 
## All Pareto k estimates are ok (k &lt; 0.7).
## See help(&#39;pareto-k-diagnostic&#39;) for details.</code></pre>
<p>We are ready to compare the models.</p>
<div class="sourceCode" id="cb961"><pre class="sourceCode r fold-show"><code class="sourceCode r"><a class="sourceLine" id="cb961-1" data-line-number="1"><span class="kw">loo_compare</span>(loo_stroop_log, loo_stroop_normal)</a></code></pre></div>
<pre><code>##                   elpd_diff se_diff
## fit_stroop            0.0       0.0
## fit_stroop_normal -1843.6     533.8</code></pre>
<p>Here cross-validation shows a clear advantage for the model with the log-normal likelihood. We visualize the pointwise predictive accuracy in Figure <a href="ch-cv.html#fig:diffpredacclog">16.2</a>.</p>
<div class="sourceCode" id="cb963"><pre class="sourceCode r fold-show"><code class="sourceCode r"><a class="sourceLine" id="cb963-1" data-line-number="1">df_stroop &lt;-<span class="st"> </span><span class="kw">mutate</span>(df_stroop,</a>
<a class="sourceLine" id="cb963-2" data-line-number="2">  <span class="dt">diff_elpd =</span> loo_stroop_log<span class="op">$</span>pointwise[, <span class="st">&quot;elpd_loo&quot;</span>] <span class="op">-</span></a>
<a class="sourceLine" id="cb963-3" data-line-number="3"><span class="st">    </span>loo_stroop_normal<span class="op">$</span>pointwise[, <span class="st">&quot;elpd_loo&quot;</span>]</a>
<a class="sourceLine" id="cb963-4" data-line-number="4">)</a>
<a class="sourceLine" id="cb963-5" data-line-number="5"><span class="kw">ggplot</span>(df_stroop, <span class="kw">aes</span>(<span class="dt">x =</span> RT, <span class="dt">y =</span> diff_elpd)) <span class="op">+</span></a>
<a class="sourceLine" id="cb963-6" data-line-number="6"><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">alpha =</span> <span class="fl">.4</span>) <span class="op">+</span><span class="st"> </span><span class="kw">xlab</span>(<span class="st">&quot;RC (ms)&quot;</span>)</a></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:diffpredacclog"></span>
<img src="bookdown_files/figure-html/diffpredacclog-1.svg" alt="The difference in predictive accuracy between a Stroop model with a log-normal likelihood and a model with a normal likelihood. A larger (more positive) difference indicates an advantage for the model with the log-normal likelihood." width="672" />
<p class="caption">
FIGURE 16.2: The difference in predictive accuracy between a Stroop model with a log-normal likelihood and a model with a normal likelihood. A larger (more positive) difference indicates an advantage for the model with the log-normal likelihood.
</p>
</div>
<p>Figure <a href="ch-cv.html#fig:diffpredacclog">16.2</a> shows that at first glance, the advantage of the log-normal likelihood lseems to lie in being able to capture extremely slow observations.</p>
<p>Figure <a href="ch-cv.html#fig:diffpredacclog2">16.3</a> zooms in to visualize the pointwise predictive accuracy for observations with response times smaller than 2 seconds.</p>
<div class="sourceCode" id="cb964"><pre class="sourceCode r fold-show"><code class="sourceCode r"><a class="sourceLine" id="cb964-1" data-line-number="1"><span class="kw">ggplot</span>(df_stroop, <span class="kw">aes</span>(<span class="dt">x =</span> RT, <span class="dt">y =</span> diff_elpd)) <span class="op">+</span></a>
<a class="sourceLine" id="cb964-2" data-line-number="2"><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">alpha =</span> <span class="fl">.3</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb964-3" data-line-number="3"><span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;RC (ms)&quot;</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb964-4" data-line-number="4"><span class="st">  </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> <span class="dv">0</span>, <span class="dt">linetype =</span> <span class="st">&quot;dashed&quot;</span>)<span class="op">+</span></a>
<a class="sourceLine" id="cb964-5" data-line-number="5"><span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">xlim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">2000</span>), <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">10</span>, <span class="dv">10</span>)) </a></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:diffpredacclog2"></span>
<img src="bookdown_files/figure-html/diffpredacclog2-1.svg" alt="The difference in predictive accuracy between a Stroop model with a log-normal likelihood and a model with a normal likelihood for observations smaller than 2 seconds. A larger (more positive) difference indicates an advantage for the model with the log-normal likelihood." width="672" />
<p class="caption">
FIGURE 16.3: The difference in predictive accuracy between a Stroop model with a log-normal likelihood and a model with a normal likelihood for observations smaller than 2 seconds. A larger (more positive) difference indicates an advantage for the model with the log-normal likelihood.
</p>
</div>
<p>Figure <a href="ch-cv.html#fig:diffpredacclog2">16.3</a> suggests that the advantage of the log-normal likelihood seems to lie in being able to account for most of the observations in the data set, which occur around the <span class="math inline">\(500\)</span> ms.</p>
</div>
<div id="issues-with-cross-validation" class="section level2 hasAnchor">
<h2><span class="header-section-number">16.5</span> Issues with cross-validation<a href="ch-cv.html#issues-with-cross-validation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><span class="citation">Sivula, Magnusson, and Vehtari (<a href="#ref-sivula2020uncertainty">2020</a>)</span> analyzed the behavior of the uncertainty estimate of the <span class="math inline">\(elpd\)</span> in typical situations. Although they focus on LOO-CV, the consequences are the same for K-fold-CV (and cross-validation in a non-Bayesian context). <span class="citation">Sivula, Magnusson, and Vehtari (<a href="#ref-sivula2020uncertainty">2020</a>)</span> identified three cases where the uncertainty estimates can perform badly:</p>
<ol style="list-style-type: decimal">
<li>The models make very similar predictions.</li>
<li>The number of observations is small.</li>
<li>The models are misspecified with outliers (influential extreme values) in the data.</li>
</ol>
<p>When the models make similar predictions (as it is the case with nested models that we saw in earlier model comparisons) and when there is not much difference in the predictive performance of the models, the uncertainty estimates will behave badly. In these situations, cross-validation is not very useful for separating very small effect sizes from zero effect sizes.
In addition, small differences in the predictive performance cannot reliably be detected by cross-validation if the number of observations is small (say, around 100 observations). However, if the predictions are very similar, <span class="citation">Sivula, Magnusson, and Vehtari (<a href="#ref-sivula2020uncertainty">2020</a>)</span> show that the same problems persist even with a larger data set.</p>
<p>One of the issues that cross-validation methods face when they are used to compare nested models lies in the way that the exact <span class="math inline">\(elpd\)</span> is approximated: In cross-validation approximations, out-of-sample observations are used, which are not part of the model that that was fit. Every time we evaluate the predictive accuracy of an observation, we ignore modeling assumptions. One of the weaknesses of cross-validation is the high variance in the approximation of the integral over the unknown true data distribution, <span class="math inline">\(p_t\)</span> <span class="citation">(Vehtari and Ojanen <a href="#ref-VehtariOjanen2012">2012</a>, sec. 4)</span>.</p>
<p>Cross-validation methods are sometimes criticized because when a lot of data are available, they will give undue preference to the complex model in comparison to a true simpler model <span class="citation">(Gronau and Wagenmakers <a href="#ref-gronauLimitationsBayesianLeaveOneOut2018">2018</a>)</span>. This might be true for toy examples where we can have unlimited observations and we compare a “wrong” model with the true model.<a href="#fn46" class="footnote-ref" id="fnref46"><sup>46</sup></a> However, the problems that we face in practice are often very different: This is because the true model is unknown and very likely not under consideration in our comparison <span class="citation">(see Navarro <a href="#ref-navarroDevilDeepBlue2018">2019</a>)</span>. In our experience, we are very far from the asymptotic behavior of cross-validation whereby it gives undue preference to a more complex model in comparison to a true simpler model. The main weakness of cross-validation lies in its lack of assumptions, which prevents it from selecting a more complex model rather than a simple one when there is only a modest gain in predictions <span class="citation">(Vehtari, Simpson, et al. <a href="#ref-vehtariLimitationsLimitationsBayesian2019">2019</a>)</span>.</p>
<p>An alternative to the cross-validation approach discussed here for nested models is the projection predictive method <span class="citation">(Piironen, Paasiniemi, and Vehtari <a href="#ref-Piironenetal2020">2020</a>)</span>. However, this approach (which is less general since it is valid only for generalized linear models) has a somewhat different objective. In the projection predictive method, we first build the most complete predictive model, the <em>reference model</em>, and then we look for a simpler model that gives as similar predictions as the reference model. The idea is that for a given complexity (number of predictors), the model with the smallest predictive discrepancy to the reference model should be selected. See <a href="https://github.com/stan-dev/projpred" class="uri">https://github.com/stan-dev/projpred</a> for an implementation of this approach. Thus this approach focuses on model simplification rather than on model comparison.</p>
<p>For models that are badly misspecified, the bias in the uncertainty makes their comparison unreliable as well. In this case, posterior predictive checks and possible model refinements are worth considering before carrying out model comparison.</p>
<p>If there are a large number of observations and the models under consideration are different enough from each other, the differences in predictive accuracy will dwarf the variance in the estimate of <span class="math inline">\(elpd\)</span>, and cross-validation can be very useful <span class="citation">(see also Piironen and Vehtari <a href="#ref-piironenComparisonBayesianPredictive2017">2017</a>)</span>. An example of this situation appeared in section <a href="ch-cv.html#sec-logcv">16.4</a>. When models are very different, one advantage of cross-validation methods in comparison with the Bayes factor is that the selection of priors is less critical in cross-validation. It is sometimes hard to decide on priors that encode our knowledge for one model, and this difficulty is exacerbated when we want to assign comparable prior information to models with a different number of parameters that might be on a different scale. Given that cross-validation methods are less sensitive to prior specification, different models can be compared on the same footing. See <span class="citation">Nicenboim and Vasishth (<a href="#ref-nicenboimModelsRetrievalSentence2018">2018</a>)</span> for an example from psycholinguistics where K-fold-CV does help in distinguishing between models.</p>
</div>
<div id="cross-validation-in-stan" class="section level2 hasAnchor">
<h2><span class="header-section-number">16.6</span> Cross-validation in Stan<a href="ch-cv.html#cross-validation-in-stan" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We can also use PSIS-LOO-CV and K-fold-CV with our Stan models, but we should be careful to store the appropriate log-likelihood in the <code>generated quantities</code> block.</p>
<div id="psis-loo-cv-in-stan" class="section level3 hasAnchor">
<h3><span class="header-section-number">16.6.1</span> PSIS-LOO-CV in Stan<a href="ch-cv.html#psis-loo-cv-in-stan" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>As explained earlier, PSIS-LOO (as implemented in the package <code>loo</code>) approximates the likelihood of the held-out data based on the observed data: it’s faster (because only one model is fit), and it only requires a minimal modification of the Stan code we need to fit a model. By default, Stan only saves the sum of the log likelihood of each observation (in the parameter <code>lp__</code>). If we want to store the log-likelihood of each observation, we have to do this in the generated quantities block.</p>
<p>We revisit the model implemented in section <a href="ch-introstan.html#sec-interstan">10.4.2</a>, which was evaluated using the Bayes factor in chapter <a href="ch-bf.html#ch-bf">15</a>. Now, we want to compare the predictive performance of a model that assumes an effect of attentional load on pupil size against a similar model that assumes no effect. To do this, we assume the following likelihood:</p>
<p><span class="math display">\[\begin{equation}
p\_size_n \sim \mathit{Normal}(\alpha + c\_load_n \cdot \beta_1 + c\_trial \cdot \beta_2 + c\_load \cdot c\_trial \cdot \beta_3, \sigma)
\end{equation}\]</span></p>
<p>Define priors for all the <span class="math inline">\(\beta\)</span>’s as before:</p>
<p><span class="math display">\[\begin{equation}
\begin{aligned}
\alpha &amp;\sim \mathit{Normal}(1000, 500) \\
\beta_{\{1,2,3\}} &amp;\sim \mathit{Normal}(0, 100) \\
\sigma &amp;\sim \mathit{Normal}_+(0, 1000)
\end{aligned}
\end{equation}\]</span></p>
<p>Prepare the data as in section <a href="ch-introstan.html#sec-interstan">10.4.2</a>:</p>
<div class="sourceCode" id="cb965"><pre class="sourceCode r fold-show"><code class="sourceCode r"><a class="sourceLine" id="cb965-1" data-line-number="1">df_pupil &lt;-<span class="st"> </span>df_pupil <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb965-2" data-line-number="2"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">c_load =</span> load <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(load),</a>
<a class="sourceLine" id="cb965-3" data-line-number="3">         <span class="dt">c_trial =</span> load <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(trial))</a>
<a class="sourceLine" id="cb965-4" data-line-number="4">ls_pupil &lt;-<span class="st"> </span><span class="kw">list</span>(</a>
<a class="sourceLine" id="cb965-5" data-line-number="5">  <span class="dt">c_load =</span> df_pupil<span class="op">$</span>c_load,</a>
<a class="sourceLine" id="cb965-6" data-line-number="6">  <span class="dt">c_trial=</span> df_pupil<span class="op">$</span>c_trial,</a>
<a class="sourceLine" id="cb965-7" data-line-number="7">  <span class="dt">p_size =</span> df_pupil<span class="op">$</span>p_size,</a>
<a class="sourceLine" id="cb965-8" data-line-number="8">  <span class="dt">N =</span> <span class="kw">nrow</span>(df_pupil)</a>
<a class="sourceLine" id="cb965-9" data-line-number="9">)</a></code></pre></div>
<p>Add a <code>generated quantities</code> block to the model shown below. (It is also possible to run this block in a stand-alone file with the <code>rstan</code> function <code>gqs()</code>). If we use the variable name <code>log_lik</code> in the Stan code, the <code>loo</code> package will know where to find the log likelihood of the observations.</p>
<p>Code the effects as <code>beta1</code>, <code>beta2</code>, <code>beta3</code> to more easily compare the model with the one used in the BF chapter, but in this case we could have used a vector or an array instead. This is the model <code>pupil_null.stan</code> shown below:</p>
<pre class="stan fold-show"><code>data {
  int&lt;lower = 1&gt; N;
  vector[N] c_load;
  vector[N] c_trial;
  vector[N] p_size;
}
parameters {
  real alpha;
  real&lt;lower = 0&gt; beta1;
  real beta2;
  real beta3;
  real&lt;lower = 0&gt; sigma;
}
model {
  // priors including all constants
  target += normal_lpdf(alpha | 1000, 500);
  target += normal_lpdf(beta1 | 0, 100);
  target += normal_lpdf(beta2 | 0, 100);
  target += normal_lpdf(beta3 | 0, 100);
  target += normal_lpdf(sigma | 0, 1000)
    - normal_lccdf(0 | 0, 1000);
  target += normal_lpdf(p_size | alpha + c_load * beta1 +
                                 c_trial * beta2 +
                                 c_load .* c_trial * beta3, sigma);

}
generated quantities{
  array[N] real log_lik;
  for (n in 1:N){
    log_lik[n] = normal_lpdf(p_size[n] | alpha + c_load[n] * beta1 +
                                         c_trial[n] * beta2 +
                                         c_load[n] * c_trial[n] * beta3,
                                         sigma);

  }
}</code></pre>
<p>For the null model, just omit the term with <code>beta1</code> in both the model block and the generated quantities block. This is the model <code>pupil_model_cv.stan</code> shown below:</p>
<pre class="stan fold-show"><code>data {
  int&lt;lower = 1&gt; N;
  vector[N] c_load;
  vector[N] c_trial;
  vector[N] p_size;
}
parameters {
  real alpha;
  real beta2;
  real beta3;
  real&lt;lower = 0&gt; sigma;
}
model {
  target += normal_lpdf(alpha | 1000, 500);
  target += normal_lpdf(beta2 | 0, 100);
  target += normal_lpdf(beta3 | 0, 100);
  target += normal_lpdf(sigma | 0, 1000)
    - normal_lccdf(0 | 0, 1000);
  target += normal_lpdf(p_size | alpha + c_trial * beta2 +
                                 c_load .* c_trial * beta3, sigma);
}
generated quantities{
  array[N] real log_lik;
  for (n in 1:N){
    log_lik[n] = normal_lpdf(p_size[n] | alpha + c_trial[n] * beta2 +
                                         c_load[n] * c_trial[n] * beta3,
                                         sigma);

  }
}</code></pre>
<p>The models can be found in the <code>bcogsci</code> package:</p>
<div class="sourceCode" id="cb968"><pre class="sourceCode r fold-show"><code class="sourceCode r"><a class="sourceLine" id="cb968-1" data-line-number="1">pupil_model_cv &lt;-<span class="st"> </span><span class="kw">system.file</span>(<span class="st">&quot;stan_models&quot;</span>,</a>
<a class="sourceLine" id="cb968-2" data-line-number="2">                              <span class="st">&quot;pupil_model_cv.stan&quot;</span>,</a>
<a class="sourceLine" id="cb968-3" data-line-number="3">                              <span class="dt">package =</span> <span class="st">&quot;bcogsci&quot;</span>)</a>
<a class="sourceLine" id="cb968-4" data-line-number="4">pupil_null &lt;-<span class="st"> </span><span class="kw">system.file</span>(<span class="st">&quot;stan_models&quot;</span>,</a>
<a class="sourceLine" id="cb968-5" data-line-number="5">                          <span class="st">&quot;pupil_null.stan&quot;</span>,</a>
<a class="sourceLine" id="cb968-6" data-line-number="6">                          <span class="dt">package =</span> <span class="st">&quot;bcogsci&quot;</span>)</a></code></pre></div>
<p>Fit the models:</p>
<div class="sourceCode" id="cb969"><pre class="sourceCode r fold-show"><code class="sourceCode r"><a class="sourceLine" id="cb969-1" data-line-number="1">fit_pupil_int_pos_ll &lt;-<span class="st"> </span><span class="kw">stan</span>(</a>
<a class="sourceLine" id="cb969-2" data-line-number="2">  <span class="dt">file =</span> pupil_model_cv,</a>
<a class="sourceLine" id="cb969-3" data-line-number="3">  <span class="dt">iter =</span> <span class="dv">3000</span>,</a>
<a class="sourceLine" id="cb969-4" data-line-number="4">  <span class="dt">data =</span> ls_pupil</a>
<a class="sourceLine" id="cb969-5" data-line-number="5">)</a>
<a class="sourceLine" id="cb969-6" data-line-number="6">fit_pupil_int_null_ll &lt;-<span class="st"> </span><span class="kw">stan</span>(</a>
<a class="sourceLine" id="cb969-7" data-line-number="7">  <span class="dt">file =</span> pupil_null,</a>
<a class="sourceLine" id="cb969-8" data-line-number="8">  <span class="dt">iter =</span> <span class="dv">3000</span>,</a>
<a class="sourceLine" id="cb969-9" data-line-number="9">  <span class="dt">data =</span> ls_pupil</a>
<a class="sourceLine" id="cb969-10" data-line-number="10">)</a></code></pre></div>
<p>Show summary of predictive accuracy of the models using the function <code>loo</code>.
Unlike <code>brms</code>, the package <code>loo</code> is configured to warn the user if <span class="math inline">\(\hat{k} &gt; 0.5\)</span> (rather than <span class="math inline">\(\hat{k} &gt; 0.5\)</span>). In practice, however, PSIS-LOO-CV has good performance for values of <span class="math inline">\(\hat{k}\)</span> up to <span class="math inline">\(0.7\)</span> and the pointwise <span class="math inline">\(\widehat{elpd}\)</span> values with these associated <span class="math inline">\(\hat{k}\)</span> can still be used <span class="citation">(Vehtari, Gelman, and Gabry <a href="#ref-vehtariPracticalBayesianModel2017">2017</a><a href="#ref-vehtariPracticalBayesianModel2017">b</a>)</span>.</p>
<div class="sourceCode" id="cb970"><pre class="sourceCode r fold-show"><code class="sourceCode r"><a class="sourceLine" id="cb970-1" data-line-number="1">(loo_pos &lt;-<span class="st"> </span><span class="kw">loo</span>(fit_pupil_int_pos_ll))</a></code></pre></div>
<pre><code>## 
## Computed from 6000 by 41 log-likelihood matrix
## 
##          Estimate   SE
## elpd_loo   -258.7  5.6
## p_loo         3.4  1.0
## looic       517.4 11.2
## ------
## Monte Carlo SE of elpd_loo is 0.0.
## 
## All Pareto k estimates are good (k &lt; 0.5).
## See help(&#39;pareto-k-diagnostic&#39;) for details.</code></pre>
<div class="sourceCode" id="cb972"><pre class="sourceCode r fold-show"><code class="sourceCode r"><a class="sourceLine" id="cb972-1" data-line-number="1">(loo_null &lt;-<span class="st"> </span><span class="kw">loo</span>(fit_pupil_int_null_ll))</a></code></pre></div>
<pre><code>## 
## Computed from 6000 by 41 log-likelihood matrix
## 
##          Estimate   SE
## elpd_loo   -258.2  5.6
## p_loo         3.2  1.0
## looic       516.3 11.2
## ------
## Monte Carlo SE of elpd_loo is 0.0.
## 
## All Pareto k estimates are good (k &lt; 0.5).
## See help(&#39;pareto-k-diagnostic&#39;) for details.</code></pre>
<div class="sourceCode" id="cb974"><pre class="sourceCode r fold-show"><code class="sourceCode r"><a class="sourceLine" id="cb974-1" data-line-number="1"><span class="kw">loo_compare</span>(loo_pos, loo_null)</a></code></pre></div>
<pre><code>##        elpd_diff se_diff
## model2  0.0       0.0   
## model1 -0.5       0.4</code></pre>
<p>As it happened with the cloze probability effect in the previous section, we cannot decide which model has better predictive accuracy according to PSIS-LOO.</p>
<div id="k-fold-cv-in-stan" class="section level4 hasAnchor">
<h4><span class="header-section-number">16.6.1.1</span> K-fold-CV in Stan<a href="ch-cv.html#k-fold-cv-in-stan" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>If we want to use K-fold-CV (or LOGO-CV) in Stan (as opposed to PSIS-LOO), we need to be careful to store the log-likelihood of the <em>held-out data</em>, since we evaluate our model with only this subset of the data. The following example closely follows the vignette <a href="https://cran.r-project.org/web/packages/loo/vignettes/loo2-elpd.html" class="uri">https://cran.r-project.org/web/packages/loo/vignettes/loo2-elpd.html</a>.</p>
<p>The steps taken are as follows:</p>
<ol style="list-style-type: decimal">
<li>Split the data in 10 folds.</li>
</ol>
<p>Since there is only one subject, we don’t need to stratify (using <code>kfold_split_stratified</code>), and we use <code>kfold_split_random</code> from the <code>loo</code> package.</p>
<div class="sourceCode" id="cb976"><pre class="sourceCode r fold-show"><code class="sourceCode r"><a class="sourceLine" id="cb976-1" data-line-number="1">df_pupil<span class="op">$</span>fold &lt;-<span class="st"> </span><span class="kw">kfold_split_random</span>(<span class="dt">K =</span> <span class="dv">10</span>, <span class="dt">N =</span> <span class="kw">nrow</span>(df_pupil))</a>
<a class="sourceLine" id="cb976-2" data-line-number="2"><span class="co"># Show number of obs for each fold:</span></a>
<a class="sourceLine" id="cb976-3" data-line-number="3">df_pupil <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb976-4" data-line-number="4"><span class="st">  </span><span class="kw">group_by</span>(fold) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb976-5" data-line-number="5"><span class="st">  </span><span class="kw">count</span>() <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb976-6" data-line-number="6"><span class="st">  </span><span class="kw">print</span>(<span class="dt">n=</span><span class="dv">10</span>)</a></code></pre></div>
<pre><code>## # A tibble: 10 × 2
## # Groups:   fold [10]
##     fold     n
##    &lt;int&gt; &lt;int&gt;
##  1     1     4
##  2     2     4
##  3     3     4
##  4     4     4
##  5     5     4
##  6     6     4
##  7     7     4
##  8     8     4
##  9     9     4
## 10    10     5</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>Fit and extract the log pointwise predictive densities for each fold.</li>
</ol>
<p>Compile the alternative and the null models first with <code>stan_model</code>, and prepare two matrices to store the predictive densities from the held out data. Each matrix has as many rows as post-warmup iterations we’ll produce (<span class="math inline">\(3000 \times 2\)</span>), and as many columns as observations in the data set.</p>
<div class="sourceCode" id="cb978"><pre class="sourceCode r fold-show"><code class="sourceCode r"><a class="sourceLine" id="cb978-1" data-line-number="1">pupil_stanmodel &lt;-<span class="st"> </span><span class="kw">stan_model</span>(pupil_model_cv)</a>
<a class="sourceLine" id="cb978-2" data-line-number="2">pupil_null_stanmodel &lt;-<span class="st"> </span><span class="kw">stan_model</span>(pupil_null)</a>
<a class="sourceLine" id="cb978-3" data-line-number="3">log_pd_kfold &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dt">nrow =</span> <span class="dv">6000</span>, <span class="dt">ncol =</span> <span class="kw">nrow</span>(df_pupil))</a>
<a class="sourceLine" id="cb978-4" data-line-number="4">log_pd_null_kfold &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dt">nrow =</span> <span class="dv">6000</span>, <span class="dt">ncol =</span> <span class="kw">nrow</span>(df_pupil))</a></code></pre></div>
<p>Next, loop over the 10 folds. Each loop carries out the following steps. First, fit each model (i.e., the alternative and null model) to all the observations except the ones belonging to the held-out fold using <code>sampling()</code>; this uses the already-compiled models. Second, compute the log pointwise predictive densities for the held-out fold with <code>gqs()</code>. This function produces <code>generated quantities</code> based on samples from a posterior (in the <code>draw</code> argument) and ignores all the blocks except <code>generated quantities</code>.<a href="#fn47" class="footnote-ref" id="fnref47"><sup>47</sup></a> Finally, store the predictive density for the observations of the held-out fold in a matrix by extracting the log likelihood of the held-out data. The output of this loop is a matrix of the log pointwise predictive densities of all the observations.</p>
<div class="sourceCode" id="cb979"><pre class="sourceCode r fold-show"><code class="sourceCode r"><a class="sourceLine" id="cb979-1" data-line-number="1"><span class="co"># Loop over the folds</span></a>
<a class="sourceLine" id="cb979-2" data-line-number="2"><span class="cf">for</span>(k <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">10</span>){</a>
<a class="sourceLine" id="cb979-3" data-line-number="3">  <span class="co"># Training set for k</span></a>
<a class="sourceLine" id="cb979-4" data-line-number="4">  df_pupil_train &lt;-<span class="st"> </span>df_pupil <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb979-5" data-line-number="5"><span class="st">    </span><span class="kw">filter</span>(fold <span class="op">!=</span><span class="st"> </span>k)</a>
<a class="sourceLine" id="cb979-6" data-line-number="6">  ls_pupil_train &lt;-<span class="st"> </span><span class="kw">list</span>(</a>
<a class="sourceLine" id="cb979-7" data-line-number="7">    <span class="dt">c_load =</span> df_pupil_train<span class="op">$</span>c_load,</a>
<a class="sourceLine" id="cb979-8" data-line-number="8">    <span class="dt">c_trial=</span> df_pupil_train<span class="op">$</span>c_trial,</a>
<a class="sourceLine" id="cb979-9" data-line-number="9">    <span class="dt">p_size =</span> df_pupil_train<span class="op">$</span>p_size,</a>
<a class="sourceLine" id="cb979-10" data-line-number="10">    <span class="dt">N =</span> <span class="kw">nrow</span>(df_pupil_train)</a>
<a class="sourceLine" id="cb979-11" data-line-number="11">  )</a>
<a class="sourceLine" id="cb979-12" data-line-number="12">  <span class="co"># Held out set for k</span></a>
<a class="sourceLine" id="cb979-13" data-line-number="13">   df_pupil_ho &lt;-<span class="st"> </span>df_pupil <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb979-14" data-line-number="14"><span class="st">    </span><span class="kw">filter</span>(fold <span class="op">==</span><span class="st"> </span>k)</a>
<a class="sourceLine" id="cb979-15" data-line-number="15">  ls_pupil_ho &lt;-<span class="st"> </span><span class="kw">list</span>(</a>
<a class="sourceLine" id="cb979-16" data-line-number="16">    <span class="dt">c_load =</span> df_pupil_ho<span class="op">$</span>c_load,</a>
<a class="sourceLine" id="cb979-17" data-line-number="17">    <span class="dt">c_trial=</span> df_pupil_ho<span class="op">$</span>c_trial,</a>
<a class="sourceLine" id="cb979-18" data-line-number="18">    <span class="dt">p_size =</span> df_pupil_ho<span class="op">$</span>p_size,</a>
<a class="sourceLine" id="cb979-19" data-line-number="19">    <span class="dt">N =</span> <span class="kw">nrow</span>(df_pupil_ho)</a>
<a class="sourceLine" id="cb979-20" data-line-number="20">  )</a>
<a class="sourceLine" id="cb979-21" data-line-number="21">  <span class="co"># Train the models</span></a>
<a class="sourceLine" id="cb979-22" data-line-number="22">  fit_train &lt;-<span class="st"> </span><span class="kw">sampling</span>(pupil_stanmodel,</a>
<a class="sourceLine" id="cb979-23" data-line-number="23">                                     <span class="dt">iter =</span> <span class="dv">3000</span>,</a>
<a class="sourceLine" id="cb979-24" data-line-number="24">                                     <span class="dt">data =</span> ls_pupil_train)</a>
<a class="sourceLine" id="cb979-25" data-line-number="25">  fit_null_train &lt;-<span class="st"> </span><span class="kw">sampling</span>(pupil_null_stanmodel,</a>
<a class="sourceLine" id="cb979-26" data-line-number="26">                                     <span class="dt">iter =</span> <span class="dv">3000</span>,</a>
<a class="sourceLine" id="cb979-27" data-line-number="27">                                     <span class="dt">data =</span> ls_pupil_train)</a>
<a class="sourceLine" id="cb979-28" data-line-number="28">  <span class="co"># Generated quantities based on the posterior from the training set</span></a>
<a class="sourceLine" id="cb979-29" data-line-number="29">  <span class="co"># and the data from the held out set </span></a>
<a class="sourceLine" id="cb979-30" data-line-number="30">  gq_ho &lt;-<span class="st"> </span><span class="kw">gqs</span>(pupil_stanmodel,</a>
<a class="sourceLine" id="cb979-31" data-line-number="31">                     <span class="dt">draws =</span> <span class="kw">as.matrix</span>(fit_train),</a>
<a class="sourceLine" id="cb979-32" data-line-number="32">                     <span class="dt">data =</span> ls_pupil_ho)</a>
<a class="sourceLine" id="cb979-33" data-line-number="33">  gq_null_ho &lt;-<span class="st"> </span><span class="kw">gqs</span>(pupil_null_stanmodel,</a>
<a class="sourceLine" id="cb979-34" data-line-number="34">                        <span class="dt">draws =</span> <span class="kw">as.matrix</span>(fit_null_train),</a>
<a class="sourceLine" id="cb979-35" data-line-number="35">                        <span class="dt">data =</span> ls_pupil_ho)</a>
<a class="sourceLine" id="cb979-36" data-line-number="36">  <span class="co"># Extract log likelihood which represents</span></a>
<a class="sourceLine" id="cb979-37" data-line-number="37">  <span class="co"># the pointwise predictive density</span></a>
<a class="sourceLine" id="cb979-38" data-line-number="38">  log_pd_kfold[, df_pupil<span class="op">$</span>fold <span class="op">==</span><span class="st"> </span>k] &lt;-</a>
<a class="sourceLine" id="cb979-39" data-line-number="39"><span class="st">    </span><span class="kw">extract_log_lik</span>(gq_ho)</a>
<a class="sourceLine" id="cb979-40" data-line-number="40">  log_pd_null_kfold[, df_pupil<span class="op">$</span>fold <span class="op">==</span><span class="st"> </span>k] &lt;-</a>
<a class="sourceLine" id="cb979-41" data-line-number="41"><span class="st">    </span><span class="kw">extract_log_lik</span>(gq_null_ho)</a>
<a class="sourceLine" id="cb979-42" data-line-number="42">}</a></code></pre></div>
<ol start="3" style="list-style-type: decimal">
<li>Compute K-fold <span class="math inline">\(\widehat{elpd}\)</span>.</li>
</ol>
<p>Now we evaluate the predictive performance of the model on the 10 folds using <code>elpd()</code>.</p>
<div class="sourceCode" id="cb980"><pre class="sourceCode r fold-show"><code class="sourceCode r"><a class="sourceLine" id="cb980-1" data-line-number="1">(elpd_pupil_kfold &lt;-<span class="st"> </span><span class="kw">elpd</span>(log_pd_kfold))</a></code></pre></div>
<pre><code>## 
## Computed from 6000 by 41 log-likelihood matrix using the generic elpd function
## 
##      Estimate   SE
## elpd   -259.7  6.0
## ic      519.5 12.0</code></pre>
<div class="sourceCode" id="cb982"><pre class="sourceCode r fold-show"><code class="sourceCode r"><a class="sourceLine" id="cb982-1" data-line-number="1">(elpd_pupil_null_kfold &lt;-<span class="st"> </span><span class="kw">elpd</span>(log_pd_null_kfold))</a></code></pre></div>
<pre><code>## 
## Computed from 6000 by 41 log-likelihood matrix using the generic elpd function
## 
##      Estimate   SE
## elpd   -259.6  6.0
## ic      519.1 12.1</code></pre>
<ol start="4" style="list-style-type: decimal">
<li>Compare the <span class="math inline">\(\widehat{elpd}\)</span> estimates.</li>
</ol>
<div class="sourceCode" id="cb984"><pre class="sourceCode r fold-show"><code class="sourceCode r"><a class="sourceLine" id="cb984-1" data-line-number="1"><span class="kw">loo_compare</span>(elpd_pupil_kfold, elpd_pupil_null_kfold)</a></code></pre></div>
<pre><code>##        elpd_diff se_diff
## model2  0.0       0.0   
## model1 -0.2       0.5</code></pre>
<p>As with PSIS-LOO, we cannot decide which model has better predictive accuracy according to K-fold-CV.</p>
</div>
</div>
</div>
<div id="summary-14" class="section level2 hasAnchor">
<h2><span class="header-section-number">16.7</span> Summary<a href="ch-cv.html#summary-14" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In this chapter, we learned how to use K-fold cross-validation and leave-one-out cross-validation, using both built-in functionality in <code>brms</code> as well as Stan, in conjunction with the <code>loo</code> package. We saw an example of model comparison where cross-validation helped distinguish between the two models (log-normal vs. normal likelihood), and another example where no important differences were found between the models being compared (the N400 data with cloze probability as predictor). In general, cross-validation will be helpful when comparing rather different models <span class="citation">(for an example from psycholinguistics, see Nicenboim and Vasishth <a href="#ref-nicenboimModelsRetrievalSentence2018">2018</a>)</span>; when the models are highly similar, it will be difficult to distinguish between them. In particular, for typical psychology and linguistics data sets, it will be difficult to get conclusive results from model comparisons using cross-validation that aim to find evidence for the presence of a population-level (or fixed) effect, if the effect is very small and/or the data are relatively sparse (this is often the case, especially in psycholinguistic data). In such cases, if the aim is to find evidence for a theoretical claim, other model comparison methods like Bayes factors might be more meaningful.</p>
</div>
<div id="further-reading-13" class="section level2 hasAnchor">
<h2><span class="header-section-number">16.8</span> Further reading<a href="ch-cv.html#further-reading-13" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>A technical discussion about cross-validation methods can be found in Chapter 7 of <span class="citation">Gelman et al. (<a href="#ref-Gelman14">2014</a>)</span>.
For a discussion about the advantages and disadvantages of (leave-one-out) cross-validation, see <span class="citation">Gronau and Wagenmakers (<a href="#ref-gronauLimitationsBayesianLeaveOneOut2018">2018</a>)</span>, <span class="citation">Vehtari, Simpson, et al. (<a href="#ref-vehtariLimitationsLimitationsBayesian2019">2019</a>)</span> and <span class="citation">Gronau and Wagenmakers (<a href="#ref-gronauRejoinderMoreLimitations">2019</a>)</span>. A LOO glossary from <code>loo</code> package can be found in (<a href="https://mc-stan.org/loo/reference/loo-glossary.html" class="uri">https://mc-stan.org/loo/reference/loo-glossary.html</a>). Cross-validation is still an active area of research, there are multiple websites and blog posts on this topic: Aki Vehtari, the creator of the <code>loo</code> package has a comprehensive FAQ about cross-validation in <a href="https://avehtari.github.io/modelselection/CV-FAQ.html" class="uri">https://avehtari.github.io/modelselection/CV-FAQ.html</a>; on Andrew Gelman’s blog, he also discusses the situations where cross-validation can be applied: <a href="https://statmodeling.stat.columbia.edu/2018/08/03/loo-cross-validation-approaches-valid/" class="uri">https://statmodeling.stat.columbia.edu/2018/08/03/loo-cross-validation-approaches-valid/</a>.</p>
</div>
<div id="exercises-3" class="section level2 hasAnchor">
<h2><span class="header-section-number">16.9</span> Exercises<a href="ch-cv.html#exercises-3" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="exercise">
<p><span id="exr:logcv" class="exercise"><strong>Exercise 16.1  </strong></span>Predictive accuracy of the linear and the logarithm effect of cloze probability.</p>
</div>
<p>Is there a difference in predictive accuracy between the model that incorporates a linear effect of cloze probability and one that incorporates log-transformed cloze probabilities?</p>
<div class="exercise">
<p><span id="exr:stroopcv" class="exercise"><strong>Exercise 16.2  </strong></span>Lognormal model</p>
</div>
<p>Use PSIS-LOO to compare a model of Stroop as the one in <a href="ch-complexstan.html#exr:stroop">11.1</a> with a model that assumes no population-level effect</p>
<ol style="list-style-type: lower-alpha">
<li>in <code>brms</code>.</li>
<li>in Stan.</li>
</ol>
<div class="exercise">
<p><span id="exr:logrec" class="exercise"><strong>Exercise 16.3  </strong></span>Lognormal vs rec-normal model in Stan</p>
</div>
<p>In section <a href="ch-custom.html#sec-change">12.1</a>, we proposed a reciprocal truncated normal distribution (rec-normal) to response times data, as an alternative to the log-normal distribution. The log-likelihood (of <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>) of an individual observation, <span class="math inline">\(\mathit{RT}_{n}\)</span>, for the rec-normal distribution would be the following one.</p>
<p><span class="math display">\[\begin{equation}
\log \mathcal{L} = \log(\mathit{Normal}(1/\mathit{RT}_n | \mu, \sigma)) - 2 \cdot \log(\mathit{RT}_n) 
\end{equation}\]</span></p>
<p>As explained in <a href="ch-custom.html#sec-change">12.1</a>, we obtain the log-likelihood based on all the <span class="math inline">\(N\)</span> observations by summing the log-likelihood of individual observations.</p>
<p><span class="math display">\[\begin{equation}
\log \mathcal{L} = \sum_n^N \log(\mathit{Normal}(1/\mathit{RT}_n | \mu, \sigma))  - \sum_n^N 2 \cdot \log(\mathit{RT}_n) 
\end{equation}\]</span></p>
<p>Since these two models assume right-skewed data with only positive values, the question that we are interested in here is if we can really distinguish between them. Investigate this in the following way:</p>
<ol style="list-style-type: lower-alpha">
<li>Generate data (N = 100 and N = 1000) with a rec-normal distribution (e.g., <code>rt = 1 / rtnorm(N, mu, sigma, a = 0)</code>).</li>
<li>Generate data (N = 100 and N = 1000) with a log-normal distribution</li>
</ol>
<p>Fit a rec-normal and a log-normal model using Stan to each of the four datasets, and use PSIS-LOO to compare the models.</p>
<p>What do you conclude?</p>

</div>
</div>



<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references">
<div id="ref-bernardosmith">
<p>Bernardo, José M, and Adrian FM Smith. 2009. <em>Bayesian Theory</em>. Vol. 405. John Wiley &amp; Sons.</p>
</div>
<div id="ref-GeisserEddy1979">
<p>Geisser, Seymour, and William F Eddy. 1979. “A Predictive Approach to Model Selection.” <em>Journal of the American Statistical Association</em> 74 (365). Taylor &amp; Francis Group: 153–60.</p>
</div>
<div id="ref-Gelman14">
<p>Gelman, Andrew, John B. Carlin, Hal S. Stern, David B. Dunson, Aki Vehtari, and Donald B. Rubin. 2014. <em>Bayesian Data Analysis</em>. Third Edition. Boca Raton, FL: Chapman; Hall/CRC Press.</p>
</div>
<div id="ref-GneitingRaftery2007">
<p>Gneiting, Tilmann, and Adrian E Raftery. 2007. “Strictly Proper Scoring Rules, Prediction, and Estimation.” <em>Journal of the American Statistical Association</em> 102 (477). Taylor &amp; Francis: 359–78. <a href="https://doi.org/10.1198/016214506000001437" class="uri">https://doi.org/10.1198/016214506000001437</a>.</p>
</div>
<div id="ref-Good1952">
<p>Good, I. J. 1952. “Rational Decisions.” <em>Journal of the Royal Statistical Society. Series B (Methodological)</em> 14 (1). [Royal Statistical Society, Wiley]: 107–14. <a href="http://www.jstor.org/stable/2984087" class="uri">http://www.jstor.org/stable/2984087</a>.</p>
</div>
<div id="ref-gronauLimitationsBayesianLeaveOneOut2018">
<p>Gronau, Quentin F., and Eric-Jan Wagenmakers. 2018. “Limitations of Bayesian Leave-One-Out Cross-Validation for Model Selection.” <em>Computational Brain &amp; Behavior</em>. <a href="https://doi.org/10.1007/s42113-018-0011-7" class="uri">https://doi.org/10.1007/s42113-018-0011-7</a>.</p>
</div>
<div id="ref-gronauRejoinderMoreLimitations">
<p>Gronau, Quentin F., and Eric-Jan Wagenmakers. 2018. “Limitations of Bayesian Leave-One-Out Cross-Validation for Model Selection.” <em>Computational Brain &amp; Behavior</em>. <a href="https://doi.org/10.1007/s42113-018-0011-7" class="uri">https://doi.org/10.1007/s42113-018-0011-7</a>.</p> 2019. “Rejoinder: More Limitations of Bayesian Leave-One-Out Cross-Validation.” <em>Computational Brain &amp; Behavior</em> 2 (1). Springer: 35–47.</p>
</div>
<div id="ref-lunn2012bugs">
<p>Lunn, David, Chris Jackson, David J Spiegelhalter, Nicky Best, and Andrew Thomas. 2012. <em>The BUGS Book: A Practical Introduction to Bayesian Analysis</em>. Vol. 98. CRC Press.</p>
</div>
<div id="ref-navarroDevilDeepBlue2018">
<p>Navarro, Danielle J. 2019. “Between the Devil and the Deep Blue Sea: Tensions Between Scientific Judgement and Statistical Model Selection.” <em>Computational Brain &amp; Behavior</em> 2 (1): 28–34. <a href="https://doi.org/10.1007/s42113-018-0019-z" class="uri">https://doi.org/10.1007/s42113-018-0019-z</a>.</p>
</div>
<div id="ref-nicenboimModelsRetrievalSentence2018">
<p>Nicenboim, Bruno, and Shravan Vasishth. 2018. “Models of Retrieval in Sentence Comprehension: A Computational Evaluation Using Bayesian Hierarchical Modeling.” <em>Journal of Memory and Language</em> 99: 1–34. <a href="https://doi.org/10.1016/j.jml.2017.08.004" class="uri">https://doi.org/10.1016/j.jml.2017.08.004</a>.</p>
</div>
<div id="ref-Paananen_2021">
<p>Paananen, Topi, Juho Piironen, Paul-Christian Bürkner, and Aki Vehtari. 2021. “Implicitly Adaptive Importance Sampling.” <em>Statistics and Computing</em> 31 (2). Springer Science; Business Media LLC. <a href="https://doi.org/10.1007/s11222-020-09982-2" class="uri">https://doi.org/10.1007/s11222-020-09982-2</a>.</p>
</div>
<div id="ref-Piironenetal2020">
<p>Piironen, Juho, Markus Paasiniemi, and Aki Vehtari. 2020. “Projective inference in high-dimensional problems: Prediction and feature selection.” <em>Electronic Journal of Statistics</em> 14 (1). Institute of Mathematical Statistics; Bernoulli Society: 2155–97. <a href="https://doi.org/10.1214/20-EJS1711" class="uri">https://doi.org/10.1214/20-EJS1711</a>.</p>
</div>
<div id="ref-piironenComparisonBayesianPredictive2017">
<p>Piironen, Juho, and Aki Vehtari. 2017. “Comparison of Bayesian Predictive Methods for Model Selection.” <em>Statistics and Computing</em> 27 (3): 711–35. <a href="https://doi.org/10.1007/s11222-016-9649-y" class="uri">https://doi.org/10.1007/s11222-016-9649-y</a>.</p>
</div>
<div id="ref-sivula2020uncertainty">
<p>Sivula, Tuomas, Måns Magnusson, and Aki Vehtari. 2020. “Uncertainty in Bayesian Leave-One-Out Cross-Validation Based Model Comparison.”</p>
</div>
<div id="ref-FAQCV">
<p>Vehtari, Aki. 2022. “Cross-validation FAQ.” <a href="https://web.archive.org/web/20221219223947/https://avehtari.github.io/modelselection/CV-FAQ.html" class="uri">https://web.archive.org/web/20221219223947/https://avehtari.github.io/modelselection/CV-FAQ.html</a>.</p>
</div>
<div id="ref-VehtariGelman2015Pareto">
<p>Vehtari, Aki, and Andrew Gelman. 2015. “Pareto Smoothed Importance Sampling.” <em>arXiv Preprint arXiv:1507.02646</em>.</p>
</div>
<div id="ref-vehtariPracticalBayesianModel2017">
<p>Vehtari, Aki, Andrew Gelman, and Jonah Gabry. 2017b. “Practical Bayesian Model Evaluation Using Leave-One-Out Cross-Validation and WAIC.” <em>Statistics and Computing</em> 27 (5): 1413–32. <a href="https://doi.org/10.1007/s11222-016-9696-4" class="uri">https://doi.org/10.1007/s11222-016-9696-4</a>.</p>
</div>
<div id="ref-VehtariOjanen2012">
<p>Vehtari, Aki, and Janne Ojanen. 2012. “A Survey of Bayesian Predictive Methods for Model Assessment, Selection and Comparison.” <em>Statistical Surveys</em> 6 (0). Institute of Mathematical Statistics: 142–228. <a href="https://doi.org/10.1214/12-ss102" class="uri">https://doi.org/10.1214/12-ss102</a>.</p>
</div>
<div id="ref-vehtariLimitationsLimitationsBayesian2019">
<p>Vehtari, Aki, Daniel P. Simpson, Yuling Yao, and Andrew Gelman. 2019. “Limitations of ‘Limitations of Bayesian Leave-One-Out Cross-Validation for Model Selection’.” <em>Computational Brain &amp; Behavior</em> 2 (1): 22–27. <a href="https://doi.org/10.1007/s42113-018-0020-6" class="uri">https://doi.org/10.1007/s42113-018-0020-6</a>.</p>
</div>
<div id="ref-venablesripley">
<p>Venables, William N., and Brian D. Ripley. 2002. <em>Modern Applied Statistics with S-PLUS</em>. New York: Springer.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="44">
<li id="fn44"><p>Maximizing the <span class="math inline">\(elpd\)</span> in <a href="ch-cv.html#eq:elpd">(16.4)</a> is also equivalent to minimizing the Kullback–Leibler (KL) divergence from the true data generating distribution <span class="math inline">\(p_t(y_{pred})\)</span> to the <em>posterior predictive distribution</em> of the candidate model <span class="math inline">\(\mathcal{M}_1\)</span>.<a href="ch-cv.html#fnref44" class="footnote-back">↩</a></p></li>
<li id="fn45"><p>The double use of the data is also a problem when one relies on information criteria like the Akaike Information Criterion (AIC) or the Bayesian Information Criterion (BIC).<a href="ch-cv.html#fnref45" class="footnote-back">↩</a></p></li>
<li id="fn46"><p>If the true model is under consideration among the models being compared, we are under an <span class="math inline">\(M_{closed}\)</span> scenario. However, this is rarely realistic. The most common case is an <span class="math inline">\(M_{open}\)</span> scenario <span class="citation">(Bernardo and Smith <a href="#ref-bernardosmith">2009</a>)</span>, where the true model is not included in the set of models being compared.<a href="ch-cv.html#fnref46" class="footnote-back">↩</a></p></li>
<li id="fn47"><p>The reader using <code>cmdstanr</code> rather than <code>rstan</code> might find a cryptic error here. This is because <code>cmdstanr</code> expects the parameters not to change. A workaround can be found in <a href="https://discourse.mc-stan.org/t/generated-quantities-returns-error-mismatch-between-model-and-fitted-parameters-csv-file/17869/15" class="uri">https://discourse.mc-stan.org/t/generated-quantities-returns-error-mismatch-between-model-and-fitted-parameters-csv-file/17869/15</a><a href="ch-cv.html#fnref47" class="footnote-back">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="ch-bf.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="ch-cogmod.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/clipboard.min.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script src="libs/gitbook/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "none"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
