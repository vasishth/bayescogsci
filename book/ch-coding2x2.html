<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 9 Contrast coding for designs with two predictor variables | An Introduction to Bayesian Data Analysis for Cognitive Science</title>
  <meta name="description" content="An introduction to Bayesian data analysis for Cognitive Science." />
  <meta name="generator" content="bookdown 0.39 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 9 Contrast coding for designs with two predictor variables | An Introduction to Bayesian Data Analysis for Cognitive Science" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="https://vasishth.github.io/Bayes_CogSci//images/temporarycover.jpg" />
  <meta property="og:description" content="An introduction to Bayesian data analysis for Cognitive Science." />
  <meta name="github-repo" content="https://github.com/vasishth/Bayes_CogSci" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 9 Contrast coding for designs with two predictor variables | An Introduction to Bayesian Data Analysis for Cognitive Science" />
  
  <meta name="twitter:description" content="An introduction to Bayesian data analysis for Cognitive Science." />
  <meta name="twitter:image" content="https://vasishth.github.io/Bayes_CogSci//images/temporarycover.jpg" />

<meta name="author" content="Bruno Nicenboim, Daniel Schad, and Shravan Vasishth" />


<meta name="date" content="2024-08-26" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="ch-contr.html"/>
<link rel="next" href="ch-introstan.html"/>
<script src="libs/jquery/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-clipboard.css" rel="stylesheet" />








<script src="libs/accessible-code-block/empty-anchor.js"></script>
<link href="libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections/anchor-sections.js"></script>
<script>
// FOLD code from 
// https://github.com/bblodfon/rtemps/blob/master/docs/bookdown-lite/hide_code.html
/* ========================================================================
 * Bootstrap: transition.js v3.3.7
 * http://getbootstrap.com/javascript/#transitions
 * ========================================================================
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 * ======================================================================== */


+function ($) {
  'use strict';

  // CSS TRANSITION SUPPORT (Shoutout: http://www.modernizr.com/)
  // ============================================================

  function transitionEnd() {
    var el = document.createElement('bootstrap')

    var transEndEventNames = {
      WebkitTransition : 'webkitTransitionEnd',
      MozTransition    : 'transitionend',
      OTransition      : 'oTransitionEnd otransitionend',
      transition       : 'transitionend'
    }

    for (var name in transEndEventNames) {
      if (el.style[name] !== undefined) {
        return { end: transEndEventNames[name] }
      }
    }

    return false // explicit for ie8 (  ._.)
  }

  // http://blog.alexmaccaw.com/css-transitions
  $.fn.emulateTransitionEnd = function (duration) {
    var called = false
    var $el = this
    $(this).one('bsTransitionEnd', function () { called = true })
    var callback = function () { if (!called) $($el).trigger($.support.transition.end) }
    setTimeout(callback, duration)
    return this
  }

  $(function () {
    $.support.transition = transitionEnd()

    if (!$.support.transition) return

    $.event.special.bsTransitionEnd = {
      bindType: $.support.transition.end,
      delegateType: $.support.transition.end,
      handle: function (e) {
        if ($(e.target).is(this)) return e.handleObj.handler.apply(this, arguments)
      }
    }
  })

}(jQuery);
</script>
<script>
/* ========================================================================
 * Bootstrap: collapse.js v3.3.7
 * http://getbootstrap.com/javascript/#collapse
 * ========================================================================
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 * ======================================================================== */

/* jshint latedef: false */

+function ($) {
  'use strict';

  // COLLAPSE PUBLIC CLASS DEFINITION
  // ================================

  var Collapse = function (element, options) {
    this.$element      = $(element)
    this.options       = $.extend({}, Collapse.DEFAULTS, options)
    this.$trigger      = $('[data-toggle="collapse"][href="#' + element.id + '"],' +
                           '[data-toggle="collapse"][data-target="#' + element.id + '"]')
    this.transitioning = null

    if (this.options.parent) {
      this.$parent = this.getParent()
    } else {
      this.addAriaAndCollapsedClass(this.$element, this.$trigger)
    }

    if (this.options.toggle) this.toggle()
  }

  Collapse.VERSION  = '3.3.7'

  Collapse.TRANSITION_DURATION = 350

  Collapse.DEFAULTS = {
    toggle: true
  }

  Collapse.prototype.dimension = function () {
    var hasWidth = this.$element.hasClass('width')
    return hasWidth ? 'width' : 'height'
  }

  Collapse.prototype.show = function () {
    if (this.transitioning || this.$element.hasClass('in')) return

    var activesData
    var actives = this.$parent && this.$parent.children('.panel').children('.in, .collapsing')

    if (actives && actives.length) {
      activesData = actives.data('bs.collapse')
      if (activesData && activesData.transitioning) return
    }

    var startEvent = $.Event('show.bs.collapse')
    this.$element.trigger(startEvent)
    if (startEvent.isDefaultPrevented()) return

    if (actives && actives.length) {
      Plugin.call(actives, 'hide')
      activesData || actives.data('bs.collapse', null)
    }

    var dimension = this.dimension()

    this.$element
      .removeClass('collapse')
      .addClass('collapsing')[dimension](0)
      .attr('aria-expanded', true)

    this.$trigger
      .removeClass('collapsed')
      .attr('aria-expanded', true)

    this.transitioning = 1

    var complete = function () {
      this.$element
        .removeClass('collapsing')
        .addClass('collapse in')[dimension]('')
      this.transitioning = 0
      this.$element
        .trigger('shown.bs.collapse')
    }

    if (!$.support.transition) return complete.call(this)

    var scrollSize = $.camelCase(['scroll', dimension].join('-'))

    this.$element
      .one('bsTransitionEnd', $.proxy(complete, this))
      .emulateTransitionEnd(Collapse.TRANSITION_DURATION)[dimension](this.$element[0][scrollSize])
  }

  Collapse.prototype.hide = function () {
    if (this.transitioning || !this.$element.hasClass('in')) return

    var startEvent = $.Event('hide.bs.collapse')
    this.$element.trigger(startEvent)
    if (startEvent.isDefaultPrevented()) return

    var dimension = this.dimension()

    this.$element[dimension](this.$element[dimension]())[0].offsetHeight

    this.$element
      .addClass('collapsing')
      .removeClass('collapse in')
      .attr('aria-expanded', false)

    this.$trigger
      .addClass('collapsed')
      .attr('aria-expanded', false)

    this.transitioning = 1

    var complete = function () {
      this.transitioning = 0
      this.$element
        .removeClass('collapsing')
        .addClass('collapse')
        .trigger('hidden.bs.collapse')
    }

    if (!$.support.transition) return complete.call(this)

    this.$element
      [dimension](0)
      .one('bsTransitionEnd', $.proxy(complete, this))
      .emulateTransitionEnd(Collapse.TRANSITION_DURATION)
  }

  Collapse.prototype.toggle = function () {
    this[this.$element.hasClass('in') ? 'hide' : 'show']()
  }

  Collapse.prototype.getParent = function () {
    return $(this.options.parent)
      .find('[data-toggle="collapse"][data-parent="' + this.options.parent + '"]')
      .each($.proxy(function (i, element) {
        var $element = $(element)
        this.addAriaAndCollapsedClass(getTargetFromTrigger($element), $element)
      }, this))
      .end()
  }

  Collapse.prototype.addAriaAndCollapsedClass = function ($element, $trigger) {
    var isOpen = $element.hasClass('in')

    $element.attr('aria-expanded', isOpen)
    $trigger
      .toggleClass('collapsed', !isOpen)
      .attr('aria-expanded', isOpen)
  }

  function getTargetFromTrigger($trigger) {
    var href
    var target = $trigger.attr('data-target')
      || (href = $trigger.attr('href')) && href.replace(/.*(?=#[^\s]+$)/, '') // strip for ie7

    return $(target)
  }


  // COLLAPSE PLUGIN DEFINITION
  // ==========================

  function Plugin(option) {
    return this.each(function () {
      var $this   = $(this)
      var data    = $this.data('bs.collapse')
      var options = $.extend({}, Collapse.DEFAULTS, $this.data(), typeof option == 'object' && option)

      if (!data && options.toggle && /show|hide/.test(option)) options.toggle = false
      if (!data) $this.data('bs.collapse', (data = new Collapse(this, options)))
      if (typeof option == 'string') data[option]()
    })
  }

  var old = $.fn.collapse

  $.fn.collapse             = Plugin
  $.fn.collapse.Constructor = Collapse


  // COLLAPSE NO CONFLICT
  // ====================

  $.fn.collapse.noConflict = function () {
    $.fn.collapse = old
    return this
  }


  // COLLAPSE DATA-API
  // =================

  $(document).on('click.bs.collapse.data-api', '[data-toggle="collapse"]', function (e) {
    var $this   = $(this)

    if (!$this.attr('data-target')) e.preventDefault()

    var $target = getTargetFromTrigger($this)
    var data    = $target.data('bs.collapse')
    var option  = data ? 'toggle' : $this.data()

    Plugin.call($target, option)
  })

}(jQuery);
</script>
<script>
window.initializeCodeFolding = function(show) {

  // handlers for show-all and hide all
  $("#rmd-show-all-code").click(function() {
    // close the dropdown menu when an option is clicked
    $("#allCodeButton").dropdown("toggle");
    $('div.r-code-collapse').each(function() {
      $(this).collapse('show');
    });
  });
  $("#rmd-hide-all-code").click(function() {
    // close the dropdown menu when an option is clicked
    $("#allCodeButton").dropdown("toggle");
    $('div.r-code-collapse').each(function() {
      $(this).collapse('hide');
    });
  });

  // index for unique code element ids
  var currentIndex = 1;

  // select all R code blocks
  var rCodeBlocks = $('pre.sourceCode, pre.r, pre.python, pre.bash, pre.sql, pre.cpp, pre.stan');
  rCodeBlocks.each(function() {

    // if code block has been labeled with class `fold-show`, show the code on init!
    var classList = $(this).attr('class').split(/\s+/);
    for (var i = 0; i < classList.length; i++) {
    if (classList[i] === 'fold-show') {
        show = true;
      }
    }

    // create a collapsable div to wrap the code in
    var div = $('<div class="collapse r-code-collapse"></div>');
    if (show)
      div.addClass('in');
    var id = 'rcode-643E0F36' + currentIndex++;
    div.attr('id', id);
    $(this).before(div);
    $(this).detach().appendTo(div);

    // add a show code button right above
    var showCodeText = $('<span>' + (show ? 'Hide' : 'Code') + '</span>');
    var showCodeButton = $('<button type="button" class="btn btn-default btn-xs code-folding-btn pull-right"></button>');
    showCodeButton.append(showCodeText);
    showCodeButton
        .attr('data-toggle', 'collapse')
        .attr('data-target', '#' + id)
        .attr('aria-expanded', show)
        .attr('aria-controls', id);

    var buttonRow = $('<div class="row"></div>');
    var buttonCol = $('<div class="col-md-12"></div>');

    buttonCol.append(showCodeButton);
    buttonRow.append(buttonCol);

    div.before(buttonRow);

    // hack: return show to false, otherwise all next codeBlocks will be shown!
    show = false;

    // update state of button on show/hide
    div.on('hidden.bs.collapse', function () {
      showCodeText.text('Code');
    });
    div.on('show.bs.collapse', function () {
      showCodeText.text('Hide');
    });
  });

}
</script>
<script>
/* ========================================================================
 * Bootstrap: dropdown.js v3.3.7
 * http://getbootstrap.com/javascript/#dropdowns
 * ========================================================================
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 * ======================================================================== */


+function ($) {
  'use strict';

  // DROPDOWN CLASS DEFINITION
  // =========================

  var backdrop = '.dropdown-backdrop'
  var toggle   = '[data-toggle="dropdown"]'
  var Dropdown = function (element) {
    $(element).on('click.bs.dropdown', this.toggle)
  }

  Dropdown.VERSION = '3.3.7'

  function getParent($this) {
    var selector = $this.attr('data-target')

    if (!selector) {
      selector = $this.attr('href')
      selector = selector && /#[A-Za-z]/.test(selector) && selector.replace(/.*(?=#[^\s]*$)/, '') // strip for ie7
    }

    var $parent = selector && $(selector)

    return $parent && $parent.length ? $parent : $this.parent()
  }

  function clearMenus(e) {
    if (e && e.which === 3) return
    $(backdrop).remove()
    $(toggle).each(function () {
      var $this         = $(this)
      var $parent       = getParent($this)
      var relatedTarget = { relatedTarget: this }

      if (!$parent.hasClass('open')) return

      if (e && e.type == 'click' && /input|textarea/i.test(e.target.tagName) && $.contains($parent[0], e.target)) return

      $parent.trigger(e = $.Event('hide.bs.dropdown', relatedTarget))

      if (e.isDefaultPrevented()) return

      $this.attr('aria-expanded', 'false')
      $parent.removeClass('open').trigger($.Event('hidden.bs.dropdown', relatedTarget))
    })
  }

  Dropdown.prototype.toggle = function (e) {
    var $this = $(this)

    if ($this.is('.disabled, :disabled')) return

    var $parent  = getParent($this)
    var isActive = $parent.hasClass('open')

    clearMenus()

    if (!isActive) {
      if ('ontouchstart' in document.documentElement && !$parent.closest('.navbar-nav').length) {
        // if mobile we use a backdrop because click events don't delegate
        $(document.createElement('div'))
          .addClass('dropdown-backdrop')
          .insertAfter($(this))
          .on('click', clearMenus)
      }

      var relatedTarget = { relatedTarget: this }
      $parent.trigger(e = $.Event('show.bs.dropdown', relatedTarget))

      if (e.isDefaultPrevented()) return

      $this
        .trigger('focus')
        .attr('aria-expanded', 'true')

      $parent
        .toggleClass('open')
        .trigger($.Event('shown.bs.dropdown', relatedTarget))
    }

    return false
  }

  Dropdown.prototype.keydown = function (e) {
    if (!/(38|40|27|32)/.test(e.which) || /input|textarea/i.test(e.target.tagName)) return

    var $this = $(this)

    e.preventDefault()
    e.stopPropagation()

    if ($this.is('.disabled, :disabled')) return

    var $parent  = getParent($this)
    var isActive = $parent.hasClass('open')

    if (!isActive && e.which != 27 || isActive && e.which == 27) {
      if (e.which == 27) $parent.find(toggle).trigger('focus')
      return $this.trigger('click')
    }

    var desc = ' li:not(.disabled):visible a'
    var $items = $parent.find('.dropdown-menu' + desc)

    if (!$items.length) return

    var index = $items.index(e.target)

    if (e.which == 38 && index > 0)                 index--         // up
    if (e.which == 40 && index < $items.length - 1) index++         // down
    if (!~index)                                    index = 0

    $items.eq(index).trigger('focus')
  }


  // DROPDOWN PLUGIN DEFINITION
  // ==========================

  function Plugin(option) {
    return this.each(function () {
      var $this = $(this)
      var data  = $this.data('bs.dropdown')

      if (!data) $this.data('bs.dropdown', (data = new Dropdown(this)))
      if (typeof option == 'string') data[option].call($this)
    })
  }

  var old = $.fn.dropdown

  $.fn.dropdown             = Plugin
  $.fn.dropdown.Constructor = Dropdown


  // DROPDOWN NO CONFLICT
  // ====================

  $.fn.dropdown.noConflict = function () {
    $.fn.dropdown = old
    return this
  }


  // APPLY TO STANDARD DROPDOWN ELEMENTS
  // ===================================

  $(document)
    .on('click.bs.dropdown.data-api', clearMenus)
    .on('click.bs.dropdown.data-api', '.dropdown form', function (e) { e.stopPropagation() })
    .on('click.bs.dropdown.data-api', toggle, Dropdown.prototype.toggle)
    .on('keydown.bs.dropdown.data-api', toggle, Dropdown.prototype.keydown)
    .on('keydown.bs.dropdown.data-api', '.dropdown-menu', Dropdown.prototype.keydown)

}(jQuery);
</script>
<style type="text/css">
.code-folding-btn {
  margin-bottom: 4px;
}

.row { display: flex; }
.collapse { display: none; }
.in { display:block }
.pull-right > .dropdown-menu {
    right: 0;
    left: auto;
}

.dropdown-menu {
    position: absolute;
    top: 100%;
    left: 0;
    z-index: 1000;
    display: none;
    float: left;
    min-width: 160px;
    padding: 5px 0;
    margin: 2px 0 0;
    font-size: 14px;
    text-align: left;
    list-style: none;
    background-color: #fff;
    -webkit-background-clip: padding-box;
    background-clip: padding-box;
    border: 1px solid #ccc;
    border: 1px solid rgba(0,0,0,.15);
    border-radius: 4px;
    -webkit-box-shadow: 0 6px 12px rgba(0,0,0,.175);
    box-shadow: 0 6px 12px rgba(0,0,0,.175);
}

.open > .dropdown-menu {
    display: block;
    color: #ffffff;
    background-color: #ffffff;
    background-image: none;
    border-color: #92897e;
}

.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: 400;
  line-height: 1.42857143;
  color: #000000;
  white-space: nowrap;
}

.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  color: #ffffff;
  text-decoration: none;
  background-color: #e95420;
}

.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #ffffff;
  text-decoration: none;
  background-color: #e95420;
  outline: 0;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #aea79f;
}

.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  cursor: not-allowed;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
}

.btn {
  display: inline-block;
  margin-bottom: 1;
  font-weight: normal;
  text-align: center;
  white-space: nowrap;
  vertical-align: middle;
  -ms-touch-action: manipulation;
      touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  padding: 4px 8px;
  font-size: 14px;
  line-height: 1.42857143;
  border-radius: 4px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #ffffff;
  text-decoration: none;
}
.btn:active,
.btn.active {
  background-image: none;
  outline: 0;
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  filter: alpha(opacity=65);
  opacity: 0.65;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #ffffff;
  background-color: #aea79f; #important
  border-color: #aea79f;
}

.btn-default:focus,
.btn-default.focus {
  color: #ffffff;
  background-color: #978e83;
  border-color: #6f675e;
}

.btn-default:hover {
  color: #ffffff;
  background-color: #978e83;
  border-color: #92897e;
}
.btn-default:active,
.btn-default.active,
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-top-right-radius: 0;
  border-bottom-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-top-left-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-top-right-radius: 0;
  border-bottom-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-left-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-right: 8px;
  padding-left: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-right: 12px;
  padding-left: 12px;
}
.btn-group.open .dropdown-toggle {
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  box-shadow: none;
}

</style>
<script>
var str = '<div class="btn-group pull-right" style="position: fixed; right: 50px; top: 10px; z-index: 200"><button type="button" class="btn btn-default btn-xs dropdown-toggle" id="allCodeButton" data-toggle="dropdown" aria-haspopup="true" aria-expanded="true" data-_extension-text-contrast=""><span>Code</span> <span class="caret"></span></button><ul class="dropdown-menu" style="min-width: 50px;"><li><a id="rmd-show-all-code" href="#">Show All Code</a></li><li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li></ul></div>';
document.write(str);
</script>
<script>
$(document).ready(function () {
  window.initializeCodeFolding("show" === "hide");
});
</script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
<link rel="stylesheet" href="css/toc.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Bayesian Data Analysis for Cognitive Science (DRAFT)</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#why-read-this-book-and-what-is-its-target-audience"><i class="fa fa-check"></i>Why read this book, and what is its target audience?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#developing-the-right-mindset-for-this-book"><i class="fa fa-check"></i>Developing the right mindset for this book</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#how-to-read-this-book"><i class="fa fa-check"></i>How to read this book</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#some-conventions-used-in-this-book"><i class="fa fa-check"></i>Some conventions used in this book</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#online-materials"><i class="fa fa-check"></i>Online materials</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#software-needed"><i class="fa fa-check"></i>Software needed</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgments"><i class="fa fa-check"></i>Acknowledgments</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="about-the-authors.html"><a href="about-the-authors.html"><i class="fa fa-check"></i>About the Authors</a></li>
<li class="part"><span><b>I Foundational ideas</b></span></li>
<li class="chapter" data-level="1" data-path="ch-intro.html"><a href="ch-intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="ch-intro.html"><a href="ch-intro.html#introprob"><i class="fa fa-check"></i><b>1.1</b> Probability</a></li>
<li class="chapter" data-level="1.2" data-path="ch-intro.html"><a href="ch-intro.html#condprob"><i class="fa fa-check"></i><b>1.2</b>  Conditional probability</a></li>
<li class="chapter" data-level="1.3" data-path="ch-intro.html"><a href="ch-intro.html#the-law-of-total-probability"><i class="fa fa-check"></i><b>1.3</b> The  law of total probability</a></li>
<li class="chapter" data-level="1.4" data-path="ch-intro.html"><a href="ch-intro.html#sec-binomialcloze"><i class="fa fa-check"></i><b>1.4</b>  Discrete random variables: An example using the  binomial distribution</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="ch-intro.html"><a href="ch-intro.html#the-mean-and-variance-of-the-binomial-distribution"><i class="fa fa-check"></i><b>1.4.1</b> The mean and variance of the binomial distribution</a></li>
<li class="chapter" data-level="1.4.2" data-path="ch-intro.html"><a href="ch-intro.html#what-information-does-a-probability-distribution-provide"><i class="fa fa-check"></i><b>1.4.2</b> What information does a probability distribution provide?</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="ch-intro.html"><a href="ch-intro.html#continuous-random-variables-an-example-using-the-normal-distribution"><i class="fa fa-check"></i><b>1.5</b>  Continuous random variables: An example using the  normal distribution</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="ch-intro.html"><a href="ch-intro.html#an-important-distinction-probability-vs.-density-in-a-continuous-random-variable"><i class="fa fa-check"></i><b>1.5.1</b> An important distinction: probability vs. density in a continuous random variable</a></li>
<li class="chapter" data-level="1.5.2" data-path="ch-intro.html"><a href="ch-intro.html#truncating-a-normal-distribution"><i class="fa fa-check"></i><b>1.5.2</b> Truncating a normal distribution</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="ch-intro.html"><a href="ch-intro.html#bivariate-and-multivariate-distributions"><i class="fa fa-check"></i><b>1.6</b> Bivariate and multivariate distributions</a>
<ul>
<li class="chapter" data-level="1.6.1" data-path="ch-intro.html"><a href="ch-intro.html#example-1-discrete-bivariate-distributions"><i class="fa fa-check"></i><b>1.6.1</b> Example 1:  Discrete bivariate distributions</a></li>
<li class="chapter" data-level="1.6.2" data-path="ch-intro.html"><a href="ch-intro.html#sec-contbivar"><i class="fa fa-check"></i><b>1.6.2</b> Example 2:  Continuous bivariate distributions</a></li>
<li class="chapter" data-level="1.6.3" data-path="ch-intro.html"><a href="ch-intro.html#sec-generatebivariatedata"><i class="fa fa-check"></i><b>1.6.3</b> Generate  simulated bivariate  (multivariate) data</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="ch-intro.html"><a href="ch-intro.html#sec-marginal"><i class="fa fa-check"></i><b>1.7</b> An important concept: The  marginal likelihood  (integrating out a parameter)</a></li>
<li class="chapter" data-level="1.8" data-path="ch-intro.html"><a href="ch-intro.html#summary-of-useful-r-functions-relating-to-distributions"><i class="fa fa-check"></i><b>1.8</b> Summary of useful R functions relating to distributions</a></li>
<li class="chapter" data-level="1.9" data-path="ch-intro.html"><a href="ch-intro.html#summary"><i class="fa fa-check"></i><b>1.9</b> Summary</a></li>
<li class="chapter" data-level="1.10" data-path="ch-intro.html"><a href="ch-intro.html#further-reading"><i class="fa fa-check"></i><b>1.10</b> Further reading</a></li>
<li class="chapter" data-level="1.11" data-path="ch-intro.html"><a href="ch-intro.html#sec-Foundationsexercises"><i class="fa fa-check"></i><b>1.11</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="ch-introBDA.html"><a href="ch-introBDA.html"><i class="fa fa-check"></i><b>2</b> Introduction to Bayesian data analysis</a>
<ul>
<li class="chapter" data-level="2.1" data-path="ch-introBDA.html"><a href="ch-introBDA.html#bayes-rule"><i class="fa fa-check"></i><b>2.1</b>  Bayes’ rule</a></li>
<li class="chapter" data-level="2.2" data-path="ch-introBDA.html"><a href="ch-introBDA.html#sec-analytical"><i class="fa fa-check"></i><b>2.2</b> Deriving the  posterior using Bayes’ rule: An analytical example</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="ch-introBDA.html"><a href="ch-introBDA.html#choosing-a-likelihood"><i class="fa fa-check"></i><b>2.2.1</b> Choosing a  likelihood</a></li>
<li class="chapter" data-level="2.2.2" data-path="ch-introBDA.html"><a href="ch-introBDA.html#sec-choosepriortheta"><i class="fa fa-check"></i><b>2.2.2</b> Choosing a  prior for <span class="math inline">\(\theta\)</span></a></li>
<li class="chapter" data-level="2.2.3" data-path="ch-introBDA.html"><a href="ch-introBDA.html#using-bayes-rule-to-compute-the-posterior-pthetank"><i class="fa fa-check"></i><b>2.2.3</b> Using  Bayes’ rule to compute the  posterior <span class="math inline">\(p(\theta|n,k)\)</span></a></li>
<li class="chapter" data-level="2.2.4" data-path="ch-introBDA.html"><a href="ch-introBDA.html#summary-of-the-procedure"><i class="fa fa-check"></i><b>2.2.4</b> Summary of the procedure</a></li>
<li class="chapter" data-level="2.2.5" data-path="ch-introBDA.html"><a href="ch-introBDA.html#visualizing-the-prior-likelihood-and-posterior"><i class="fa fa-check"></i><b>2.2.5</b> Visualizing the prior, likelihood, and posterior</a></li>
<li class="chapter" data-level="2.2.6" data-path="ch-introBDA.html"><a href="ch-introBDA.html#the-posterior-distribution-is-a-compromise-between-the-prior-and-the-likelihood"><i class="fa fa-check"></i><b>2.2.6</b> The  posterior distribution is a compromise between the prior and the likelihood</a></li>
<li class="chapter" data-level="2.2.7" data-path="ch-introBDA.html"><a href="ch-introBDA.html#incremental-knowledge-gain-using-prior-knowledge"><i class="fa fa-check"></i><b>2.2.7</b> Incremental knowledge gain using prior knowledge</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="ch-introBDA.html"><a href="ch-introBDA.html#summary-1"><i class="fa fa-check"></i><b>2.3</b> Summary</a></li>
<li class="chapter" data-level="2.4" data-path="ch-introBDA.html"><a href="ch-introBDA.html#further-reading-1"><i class="fa fa-check"></i><b>2.4</b> Further reading</a></li>
<li class="chapter" data-level="2.5" data-path="ch-introBDA.html"><a href="ch-introBDA.html#sec-BDAexercises"><i class="fa fa-check"></i><b>2.5</b> Exercises</a></li>
</ul></li>
<li class="part"><span><b>II Regression models with brms</b></span></li>
<li class="chapter" data-level="3" data-path="ch-compbda.html"><a href="ch-compbda.html"><i class="fa fa-check"></i><b>3</b> Computational Bayesian data analysis</a>
<ul>
<li class="chapter" data-level="3.1" data-path="ch-compbda.html"><a href="ch-compbda.html#sec-sampling"><i class="fa fa-check"></i><b>3.1</b> Deriving the  posterior through  sampling</a></li>
<li class="chapter" data-level="3.2" data-path="ch-compbda.html"><a href="ch-compbda.html#bayesian-regression-models-using-stan-brms"><i class="fa fa-check"></i><b>3.2</b>  Bayesian Regression Models using Stan:  brms</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="ch-compbda.html"><a href="ch-compbda.html#sec-simplenormal"><i class="fa fa-check"></i><b>3.2.1</b> A simple linear model: A single subject pressing a button repeatedly (a finger tapping task)</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="ch-compbda.html"><a href="ch-compbda.html#sec-priorpred"><i class="fa fa-check"></i><b>3.3</b>  Prior predictive distribution</a></li>
<li class="chapter" data-level="3.4" data-path="ch-compbda.html"><a href="ch-compbda.html#sec-sensitivity"><i class="fa fa-check"></i><b>3.4</b> The influence of priors:  sensitivity analysis</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="ch-compbda.html"><a href="ch-compbda.html#flat-uninformative-priors"><i class="fa fa-check"></i><b>3.4.1</b>  Flat, uninformative priors</a></li>
<li class="chapter" data-level="3.4.2" data-path="ch-compbda.html"><a href="ch-compbda.html#regularizing-priors"><i class="fa fa-check"></i><b>3.4.2</b>  Regularizing priors</a></li>
<li class="chapter" data-level="3.4.3" data-path="ch-compbda.html"><a href="ch-compbda.html#principled-priors"><i class="fa fa-check"></i><b>3.4.3</b>  Principled priors</a></li>
<li class="chapter" data-level="3.4.4" data-path="ch-compbda.html"><a href="ch-compbda.html#informative-priors"><i class="fa fa-check"></i><b>3.4.4</b>  Informative priors</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="ch-compbda.html"><a href="ch-compbda.html#sec-revisit"><i class="fa fa-check"></i><b>3.5</b> Revisiting the button-pressing example with different priors</a></li>
<li class="chapter" data-level="3.6" data-path="ch-compbda.html"><a href="ch-compbda.html#sec-ppd"><i class="fa fa-check"></i><b>3.6</b>  Posterior predictive distribution</a></li>
<li class="chapter" data-level="3.7" data-path="ch-compbda.html"><a href="ch-compbda.html#the-influence-of-the-likelihood"><i class="fa fa-check"></i><b>3.7</b> The influence of the likelihood</a>
<ul>
<li class="chapter" data-level="3.7.1" data-path="ch-compbda.html"><a href="ch-compbda.html#sec-lnfirst"><i class="fa fa-check"></i><b>3.7.1</b> The  log-normal likelihood</a></li>
<li class="chapter" data-level="3.7.2" data-path="ch-compbda.html"><a href="ch-compbda.html#sec-lognormal"><i class="fa fa-check"></i><b>3.7.2</b> Using a log-normal likelihood to fit data from a single subject pressing a button repeatedly</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="ch-compbda.html"><a href="ch-compbda.html#list-of-the-most-important-commands"><i class="fa fa-check"></i><b>3.8</b> List of the most important commands</a></li>
<li class="chapter" data-level="3.9" data-path="ch-compbda.html"><a href="ch-compbda.html#summary-2"><i class="fa fa-check"></i><b>3.9</b> Summary</a></li>
<li class="chapter" data-level="3.10" data-path="ch-compbda.html"><a href="ch-compbda.html#sec-ch3furtherreading"><i class="fa fa-check"></i><b>3.10</b> Further reading</a></li>
<li class="chapter" data-level="3.11" data-path="ch-compbda.html"><a href="ch-compbda.html#ex:compbda"><i class="fa fa-check"></i><b>3.11</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="ch-reg.html"><a href="ch-reg.html"><i class="fa fa-check"></i><b>4</b> Bayesian regression models</a>
<ul>
<li class="chapter" data-level="4.1" data-path="ch-reg.html"><a href="ch-reg.html#sec-pupil"><i class="fa fa-check"></i><b>4.1</b> A first  linear regression: Does attentional load affect pupil size?</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="ch-reg.html"><a href="ch-reg.html#likelihood-and-priors"><i class="fa fa-check"></i><b>4.1.1</b>  Likelihood and  priors</a></li>
<li class="chapter" data-level="4.1.2" data-path="ch-reg.html"><a href="ch-reg.html#the-brms-model"><i class="fa fa-check"></i><b>4.1.2</b> The  <code>brms</code> model</a></li>
<li class="chapter" data-level="4.1.3" data-path="ch-reg.html"><a href="ch-reg.html#how-to-communicate-the-results"><i class="fa fa-check"></i><b>4.1.3</b> How to communicate the results?</a></li>
<li class="chapter" data-level="4.1.4" data-path="ch-reg.html"><a href="ch-reg.html#sec-pupiladq"><i class="fa fa-check"></i><b>4.1.4</b> Descriptive adequacy</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="ch-reg.html"><a href="ch-reg.html#sec-trial"><i class="fa fa-check"></i><b>4.2</b>  Log-normal model: Does trial affect response times?</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="ch-reg.html"><a href="ch-reg.html#likelihood-and-priors-for-the-log-normal-model"><i class="fa fa-check"></i><b>4.2.1</b> Likelihood and priors for the log-normal model</a></li>
<li class="chapter" data-level="4.2.2" data-path="ch-reg.html"><a href="ch-reg.html#the-brms-model-1"><i class="fa fa-check"></i><b>4.2.2</b> The  <code>brms</code> model</a></li>
<li class="chapter" data-level="4.2.3" data-path="ch-reg.html"><a href="ch-reg.html#how-to-communicate-the-results-1"><i class="fa fa-check"></i><b>4.2.3</b> How to communicate the results?</a></li>
<li class="chapter" data-level="4.2.4" data-path="ch-reg.html"><a href="ch-reg.html#descriptive-adequacy"><i class="fa fa-check"></i><b>4.2.4</b> Descriptive adequacy</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="ch-reg.html"><a href="ch-reg.html#sec-logistic"><i class="fa fa-check"></i><b>4.3</b>  Logistic regression: Does  set size affect  free recall?</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="ch-reg.html"><a href="ch-reg.html#the-likelihood-for-the-logistic-regression-model"><i class="fa fa-check"></i><b>4.3.1</b> The likelihood for the logistic regression model</a></li>
<li class="chapter" data-level="4.3.2" data-path="ch-reg.html"><a href="ch-reg.html#sec-priorslogisticregression"><i class="fa fa-check"></i><b>4.3.2</b> Priors for the logistic regression</a></li>
<li class="chapter" data-level="4.3.3" data-path="ch-reg.html"><a href="ch-reg.html#the-brms-model-2"><i class="fa fa-check"></i><b>4.3.3</b> The <code>brms</code> model</a></li>
<li class="chapter" data-level="4.3.4" data-path="ch-reg.html"><a href="ch-reg.html#sec-comlogis"><i class="fa fa-check"></i><b>4.3.4</b> How to communicate the results?</a></li>
<li class="chapter" data-level="4.3.5" data-path="ch-reg.html"><a href="ch-reg.html#descriptive-adequacy-1"><i class="fa fa-check"></i><b>4.3.5</b>  Descriptive adequacy</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="ch-reg.html"><a href="ch-reg.html#summary-3"><i class="fa fa-check"></i><b>4.4</b> Summary</a></li>
<li class="chapter" data-level="4.5" data-path="ch-reg.html"><a href="ch-reg.html#sec-ch4furtherreading"><i class="fa fa-check"></i><b>4.5</b> Further reading</a></li>
<li class="chapter" data-level="4.6" data-path="ch-reg.html"><a href="ch-reg.html#sec-LMexercises"><i class="fa fa-check"></i><b>4.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html"><i class="fa fa-check"></i><b>5</b> Bayesian hierarchical models</a>
<ul>
<li class="chapter" data-level="5.1" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#exchangeability-and-hierarchical-models"><i class="fa fa-check"></i><b>5.1</b> Exchangeability and hierarchical models</a></li>
<li class="chapter" data-level="5.2" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#sec-N400hierarchical"><i class="fa fa-check"></i><b>5.2</b> A hierarchical model with a normal likelihood: The N400 effect</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#sec-Mcp"><i class="fa fa-check"></i><b>5.2.1</b>  Complete pooling model (<span class="math inline">\(M_{cp}\)</span>)</a></li>
<li class="chapter" data-level="5.2.2" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#no-pooling-model-m_np"><i class="fa fa-check"></i><b>5.2.2</b>  No pooling model (<span class="math inline">\(M_{np}\)</span>)</a></li>
<li class="chapter" data-level="5.2.3" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#sec-uncorrelated"><i class="fa fa-check"></i><b>5.2.3</b>  Varying intercepts and  varying slopes model (<span class="math inline">\(M_{v}\)</span>)</a></li>
<li class="chapter" data-level="5.2.4" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#sec-mcvivs"><i class="fa fa-check"></i><b>5.2.4</b> Correlated varying intercept varying slopes model (<span class="math inline">\(M_{h}\)</span>)</a></li>
<li class="chapter" data-level="5.2.5" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#sec-sih"><i class="fa fa-check"></i><b>5.2.5</b> By-subjects and by-items correlated varying intercept varying slopes model (<span class="math inline">\(M_{sih}\)</span>)</a></li>
<li class="chapter" data-level="5.2.6" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#sec-distrmodel"><i class="fa fa-check"></i><b>5.2.6</b> Beyond the maximal model–Distributional regression models</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#sec-stroop"><i class="fa fa-check"></i><b>5.3</b> A  hierarchical log-normal model: The  Stroop effect</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#a-correlated-varying-intercept-varying-slopes-log-normal-model"><i class="fa fa-check"></i><b>5.3.1</b> A correlated varying intercept varying slopes  log-normal model</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#why-fitting-a-bayesian-hierarchical-model-is-worth-the-effort"><i class="fa fa-check"></i><b>5.4</b> Why fitting a Bayesian hierarchical model is worth the effort</a></li>
<li class="chapter" data-level="5.5" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#summary-4"><i class="fa fa-check"></i><b>5.5</b> Summary</a></li>
<li class="chapter" data-level="5.6" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#further-reading-2"><i class="fa fa-check"></i><b>5.6</b> Further reading</a></li>
<li class="chapter" data-level="5.7" data-path="ch-hierarchical.html"><a href="ch-hierarchical.html#sec-HLMexercises"><i class="fa fa-check"></i><b>5.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="ch-priors.html"><a href="ch-priors.html"><i class="fa fa-check"></i><b>6</b> The Art and Science of  Prior Elicitation</a>
<ul>
<li class="chapter" data-level="6.1" data-path="ch-priors.html"><a href="ch-priors.html#sec-simpleexamplepriors"><i class="fa fa-check"></i><b>6.1</b> Eliciting priors from oneself for a self-paced reading study: A simple example</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="ch-priors.html"><a href="ch-priors.html#an-example-english-relative-clauses"><i class="fa fa-check"></i><b>6.1.1</b> An example: English  relative clauses</a></li>
<li class="chapter" data-level="6.1.2" data-path="ch-priors.html"><a href="ch-priors.html#eliciting-a-prior-for-the-intercept"><i class="fa fa-check"></i><b>6.1.2</b> Eliciting a prior for the intercept</a></li>
<li class="chapter" data-level="6.1.3" data-path="ch-priors.html"><a href="ch-priors.html#eliciting-a-prior-for-the-slope"><i class="fa fa-check"></i><b>6.1.3</b> Eliciting a prior for the slope</a></li>
<li class="chapter" data-level="6.1.4" data-path="ch-priors.html"><a href="ch-priors.html#sec-varcomppriors"><i class="fa fa-check"></i><b>6.1.4</b> Eliciting priors for the  variance components</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="ch-priors.html"><a href="ch-priors.html#eliciting-priors-from-experts"><i class="fa fa-check"></i><b>6.2</b>  Eliciting priors from experts</a></li>
<li class="chapter" data-level="6.3" data-path="ch-priors.html"><a href="ch-priors.html#deriving-priors-from-meta-analyses"><i class="fa fa-check"></i><b>6.3</b> Deriving priors from  meta-analyses</a></li>
<li class="chapter" data-level="6.4" data-path="ch-priors.html"><a href="ch-priors.html#using-previous-experiments-posteriors-as-priors-for-a-new-study"><i class="fa fa-check"></i><b>6.4</b> Using previous experiments’  posteriors as priors for a new study</a></li>
<li class="chapter" data-level="6.5" data-path="ch-priors.html"><a href="ch-priors.html#summary-5"><i class="fa fa-check"></i><b>6.5</b> Summary</a></li>
<li class="chapter" data-level="6.6" data-path="ch-priors.html"><a href="ch-priors.html#further-reading-3"><i class="fa fa-check"></i><b>6.6</b> Further reading</a></li>
<li class="chapter" data-level="6.7" data-path="ch-priors.html"><a href="ch-priors.html#sec-priorsexercises"><i class="fa fa-check"></i><b>6.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="ch-workflow.html"><a href="ch-workflow.html"><i class="fa fa-check"></i><b>7</b> Workflow</a>
<ul>
<li class="chapter" data-level="7.1" data-path="ch-workflow.html"><a href="ch-workflow.html#building-a-model"><i class="fa fa-check"></i><b>7.1</b>  Building a model</a></li>
<li class="chapter" data-level="7.2" data-path="ch-workflow.html"><a href="ch-workflow.html#principled-questions-to-ask-on-a-model"><i class="fa fa-check"></i><b>7.2</b> Principled questions to ask on a model</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="ch-workflow.html"><a href="ch-workflow.html#checking-whether-assumptions-are-consistent-with-domain-expertise-prior-predictive-checks"><i class="fa fa-check"></i><b>7.2.1</b>  Checking whether assumptions are consistent with  domain expertise: Prior predictive checks</a></li>
<li class="chapter" data-level="7.2.2" data-path="ch-workflow.html"><a href="ch-workflow.html#testing-for-correct-posterior-approximations-checks-of-computational-faithfulness"><i class="fa fa-check"></i><b>7.2.2</b>  Testing for correct posterior approximations: Checks of computational faithfulness</a></li>
<li class="chapter" data-level="7.2.3" data-path="ch-workflow.html"><a href="ch-workflow.html#sensitivity-of-the-model"><i class="fa fa-check"></i><b>7.2.3</b>  Sensitivity of the model</a></li>
<li class="chapter" data-level="7.2.4" data-path="ch-workflow.html"><a href="ch-workflow.html#does-the-model-adequately-capture-the-dataposterior-predictive-checks"><i class="fa fa-check"></i><b>7.2.4</b>  Does the model adequately capture the data?–Posterior predictive checks</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="ch-workflow.html"><a href="ch-workflow.html#further-reading-4"><i class="fa fa-check"></i><b>7.3</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="ch-contr.html"><a href="ch-contr.html"><i class="fa fa-check"></i><b>8</b>  Contrast coding</a>
<ul>
<li class="chapter" data-level="8.1" data-path="ch-contr.html"><a href="ch-contr.html#basic-concepts-illustrated-using-a-two-level-factor"><i class="fa fa-check"></i><b>8.1</b> Basic concepts illustrated using a two-level factor</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="ch-contr.html"><a href="ch-contr.html#treatmentcontrasts"><i class="fa fa-check"></i><b>8.1.1</b> Default contrast coding:  Treatment contrasts</a></li>
<li class="chapter" data-level="8.1.2" data-path="ch-contr.html"><a href="ch-contr.html#inverseMatrix"><i class="fa fa-check"></i><b>8.1.2</b> Defining comparisons</a></li>
<li class="chapter" data-level="8.1.3" data-path="ch-contr.html"><a href="ch-contr.html#effectcoding"><i class="fa fa-check"></i><b>8.1.3</b>  Sum contrasts</a></li>
<li class="chapter" data-level="8.1.4" data-path="ch-contr.html"><a href="ch-contr.html#sec-cellMeans"><i class="fa fa-check"></i><b>8.1.4</b>  Cell means parameterization and  posterior comparisons</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="ch-contr.html"><a href="ch-contr.html#the-hypothesis-matrix-illustrated-with-a-three-level-factor"><i class="fa fa-check"></i><b>8.2</b> The hypothesis matrix illustrated with a three-level factor</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="ch-contr.html"><a href="ch-contr.html#sumcontrasts"><i class="fa fa-check"></i><b>8.2.1</b>  Sum contrasts</a></li>
<li class="chapter" data-level="8.2.2" data-path="ch-contr.html"><a href="ch-contr.html#the-hypothesis-matrix"><i class="fa fa-check"></i><b>8.2.2</b> The  hypothesis matrix</a></li>
<li class="chapter" data-level="8.2.3" data-path="ch-contr.html"><a href="ch-contr.html#generating-contrasts-the-hypr-package"><i class="fa fa-check"></i><b>8.2.3</b> Generating contrasts: The  <code>hypr</code> package</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="ch-contr.html"><a href="ch-contr.html#sec-4levelFactor"><i class="fa fa-check"></i><b>8.3</b> Other types of contrasts: illustration with a factor of four levels</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="ch-contr.html"><a href="ch-contr.html#repeatedcontrasts"><i class="fa fa-check"></i><b>8.3.1</b>  Repeated contrasts</a></li>
<li class="chapter" data-level="8.3.2" data-path="ch-contr.html"><a href="ch-contr.html#helmertcontrasts"><i class="fa fa-check"></i><b>8.3.2</b>  Helmert contrasts</a></li>
<li class="chapter" data-level="8.3.3" data-path="ch-contr.html"><a href="ch-contr.html#contrasts-in-linear-regression-analysis-the-design-or-model-matrix"><i class="fa fa-check"></i><b>8.3.3</b> Contrasts in linear regression analysis: The design or  model matrix</a></li>
<li class="chapter" data-level="8.3.4" data-path="ch-contr.html"><a href="ch-contr.html#polynomialContrasts"><i class="fa fa-check"></i><b>8.3.4</b>  Polynomial contrasts</a></li>
<li class="chapter" data-level="8.3.5" data-path="ch-contr.html"><a href="ch-contr.html#an-alternative-to-contrasts-monotonic-effects"><i class="fa fa-check"></i><b>8.3.5</b> An alternative to contrasts:  Monotonic effects</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="ch-contr.html"><a href="ch-contr.html#nonOrthogonal"><i class="fa fa-check"></i><b>8.4</b> What makes a good set of contrasts?</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="ch-contr.html"><a href="ch-contr.html#centered-contrasts"><i class="fa fa-check"></i><b>8.4.1</b>  Centered contrasts</a></li>
<li class="chapter" data-level="8.4.2" data-path="ch-contr.html"><a href="ch-contr.html#orthogonal-contrasts"><i class="fa fa-check"></i><b>8.4.2</b>  Orthogonal contrasts</a></li>
<li class="chapter" data-level="8.4.3" data-path="ch-contr.html"><a href="ch-contr.html#the-role-of-the-intercept-in-non-centered-contrasts"><i class="fa fa-check"></i><b>8.4.3</b> The role of the  intercept in  non-centered contrasts</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="ch-contr.html"><a href="ch-contr.html#computing-condition-means-from-estimated-contrasts"><i class="fa fa-check"></i><b>8.5</b> Computing condition means from estimated contrasts</a></li>
<li class="chapter" data-level="8.6" data-path="ch-contr.html"><a href="ch-contr.html#summary-6"><i class="fa fa-check"></i><b>8.6</b> Summary</a></li>
<li class="chapter" data-level="8.7" data-path="ch-contr.html"><a href="ch-contr.html#further-reading-5"><i class="fa fa-check"></i><b>8.7</b> Further reading</a></li>
<li class="chapter" data-level="8.8" data-path="ch-contr.html"><a href="ch-contr.html#sec-Contrastsexercises"><i class="fa fa-check"></i><b>8.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="ch-coding2x2.html"><a href="ch-coding2x2.html"><i class="fa fa-check"></i><b>9</b> Contrast coding for designs with two predictor variables</a>
<ul>
<li class="chapter" data-level="9.1" data-path="ch-coding2x2.html"><a href="ch-coding2x2.html#sec-MR-ANOVA"><i class="fa fa-check"></i><b>9.1</b> Contrast coding in a factorial  <span class="math inline">\(2 \times 2\)</span> design</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="ch-coding2x2.html"><a href="ch-coding2x2.html#nestedEffects"><i class="fa fa-check"></i><b>9.1.1</b>  Nested effects</a></li>
<li class="chapter" data-level="9.1.2" data-path="ch-coding2x2.html"><a href="ch-coding2x2.html#interactions-between-contrasts"><i class="fa fa-check"></i><b>9.1.2</b>  Interactions between contrasts</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="ch-coding2x2.html"><a href="ch-coding2x2.html#sec-contrast-covariate"><i class="fa fa-check"></i><b>9.2</b> One factor and one  covariate</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="ch-coding2x2.html"><a href="ch-coding2x2.html#estimating-a-group-difference-and-controlling-for-a-covariate"><i class="fa fa-check"></i><b>9.2.1</b> Estimating a  group difference and controlling for a covariate</a></li>
<li class="chapter" data-level="9.2.2" data-path="ch-coding2x2.html"><a href="ch-coding2x2.html#estimating-differences-in-slopes"><i class="fa fa-check"></i><b>9.2.2</b> Estimating differences in slopes</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="ch-coding2x2.html"><a href="ch-coding2x2.html#sec-interactions-NLM"><i class="fa fa-check"></i><b>9.3</b> Interactions in generalized linear models (with non-linear link functions) and non-linear models</a></li>
<li class="chapter" data-level="9.4" data-path="ch-coding2x2.html"><a href="ch-coding2x2.html#summary-7"><i class="fa fa-check"></i><b>9.4</b> Summary</a></li>
<li class="chapter" data-level="9.5" data-path="ch-coding2x2.html"><a href="ch-coding2x2.html#further-reading-6"><i class="fa fa-check"></i><b>9.5</b> Further reading</a></li>
<li class="chapter" data-level="9.6" data-path="ch-coding2x2.html"><a href="ch-coding2x2.html#sec-Contrasts2x2exercises"><i class="fa fa-check"></i><b>9.6</b> Exercises</a></li>
</ul></li>
<li class="part"><span><b>III Advanced models with Stan</b></span></li>
<li class="chapter" data-level="10" data-path="ch-introstan.html"><a href="ch-introstan.html"><i class="fa fa-check"></i><b>10</b> Introduction to the probabilistic programming language Stan</a>
<ul>
<li class="chapter" data-level="10.1" data-path="ch-introstan.html"><a href="ch-introstan.html#stan-syntax"><i class="fa fa-check"></i><b>10.1</b> Stan syntax</a></li>
<li class="chapter" data-level="10.2" data-path="ch-introstan.html"><a href="ch-introstan.html#sec-firststan"><i class="fa fa-check"></i><b>10.2</b> A first simple example with Stan:  Normal likelihood</a></li>
<li class="chapter" data-level="10.3" data-path="ch-introstan.html"><a href="ch-introstan.html#sec-clozestan"><i class="fa fa-check"></i><b>10.3</b> Another simple example:  Cloze probability with Stan with the  binomial likelihood</a></li>
<li class="chapter" data-level="10.4" data-path="ch-introstan.html"><a href="ch-introstan.html#regression-models-in-stan"><i class="fa fa-check"></i><b>10.4</b>  Regression models in Stan</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="ch-introstan.html"><a href="ch-introstan.html#sec-pupilstan"><i class="fa fa-check"></i><b>10.4.1</b> A first  linear regression in Stan: Does attentional load affect  pupil size?</a></li>
<li class="chapter" data-level="10.4.2" data-path="ch-introstan.html"><a href="ch-introstan.html#sec-interstan"><i class="fa fa-check"></i><b>10.4.2</b>  Interactions in Stan: Does attentional load interact with trial number affecting  pupil size?</a></li>
<li class="chapter" data-level="10.4.3" data-path="ch-introstan.html"><a href="ch-introstan.html#sec-logisticstan"><i class="fa fa-check"></i><b>10.4.3</b>  Logistic regression in Stan: Does set size and trial affect free recall?</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="ch-introstan.html"><a href="ch-introstan.html#summary-8"><i class="fa fa-check"></i><b>10.5</b> Summary</a></li>
<li class="chapter" data-level="10.6" data-path="ch-introstan.html"><a href="ch-introstan.html#further-reading-7"><i class="fa fa-check"></i><b>10.6</b> Further reading</a></li>
<li class="chapter" data-level="10.7" data-path="ch-introstan.html"><a href="ch-introstan.html#exercises"><i class="fa fa-check"></i><b>10.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="ch-complexstan.html"><a href="ch-complexstan.html"><i class="fa fa-check"></i><b>11</b> Hierarchical models and reparameterization </a>
<ul>
<li class="chapter" data-level="11.1" data-path="ch-complexstan.html"><a href="ch-complexstan.html#sec-hierstan"><i class="fa fa-check"></i><b>11.1</b> Hierarchical models with Stan</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="ch-complexstan.html"><a href="ch-complexstan.html#varying-intercept-model-with-stan"><i class="fa fa-check"></i><b>11.1.1</b> Varying intercept model with Stan</a></li>
<li class="chapter" data-level="11.1.2" data-path="ch-complexstan.html"><a href="ch-complexstan.html#sec-uncorrstan"><i class="fa fa-check"></i><b>11.1.2</b> Uncorrelated  varying intercept and slopes model with Stan</a></li>
<li class="chapter" data-level="11.1.3" data-path="ch-complexstan.html"><a href="ch-complexstan.html#sec-corrstan"><i class="fa fa-check"></i><b>11.1.3</b>  Correlated varying intercept varying slopes model</a></li>
<li class="chapter" data-level="11.1.4" data-path="ch-complexstan.html"><a href="ch-complexstan.html#sec-crosscorrstan"><i class="fa fa-check"></i><b>11.1.4</b> By-subject and by-items correlated varying intercept varying slopes model</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="ch-complexstan.html"><a href="ch-complexstan.html#summary-9"><i class="fa fa-check"></i><b>11.2</b> Summary</a></li>
<li class="chapter" data-level="11.3" data-path="ch-complexstan.html"><a href="ch-complexstan.html#further-reading-8"><i class="fa fa-check"></i><b>11.3</b> Further reading</a></li>
<li class="chapter" data-level="11.4" data-path="ch-complexstan.html"><a href="ch-complexstan.html#exercises-1"><i class="fa fa-check"></i><b>11.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="ch-custom.html"><a href="ch-custom.html"><i class="fa fa-check"></i><b>12</b> Custom distributions in Stan</a>
<ul>
<li class="chapter" data-level="12.1" data-path="ch-custom.html"><a href="ch-custom.html#sec-change"><i class="fa fa-check"></i><b>12.1</b> A change of variables with the reciprocal normal distribution</a>
<ul>
<li class="chapter" data-level="12.1.1" data-path="ch-custom.html"><a href="ch-custom.html#scaling-a-probability-density-with-the-jacobian-adjustment"><i class="fa fa-check"></i><b>12.1.1</b> Scaling a probability density with the Jacobian adjustment</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="ch-custom.html"><a href="ch-custom.html#sec-validSBC"><i class="fa fa-check"></i><b>12.2</b>  Validation of a computed posterior distribution</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="ch-custom.html"><a href="ch-custom.html#the-simulation-based-calibration-procedure"><i class="fa fa-check"></i><b>12.2.1</b> The  simulation-based calibration procedure</a></li>
<li class="chapter" data-level="12.2.2" data-path="ch-custom.html"><a href="ch-custom.html#an-example-where-simulation-based-calibration-reveals-a-problem"><i class="fa fa-check"></i><b>12.2.2</b> An example where simulation-based calibration reveals a problem</a></li>
<li class="chapter" data-level="12.2.3" data-path="ch-custom.html"><a href="ch-custom.html#issues-with-and-limitations-of-simulation-based-calibration"><i class="fa fa-check"></i><b>12.2.3</b> Issues with and limitations of simulation-based calibration</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="ch-custom.html"><a href="ch-custom.html#another-custom-distribution-the-exponential-distribution-implemented-manually"><i class="fa fa-check"></i><b>12.3</b> Another  custom distribution: The exponential distribution  implemented manually</a></li>
<li class="chapter" data-level="12.4" data-path="ch-custom.html"><a href="ch-custom.html#summary-10"><i class="fa fa-check"></i><b>12.4</b> Summary</a></li>
<li class="chapter" data-level="12.5" data-path="ch-custom.html"><a href="ch-custom.html#further-reading-9"><i class="fa fa-check"></i><b>12.5</b> Further reading</a></li>
<li class="chapter" data-level="12.6" data-path="ch-custom.html"><a href="ch-custom.html#sec-customexercises"><i class="fa fa-check"></i><b>12.6</b> Exercises</a></li>
</ul></li>
<li class="part"><span><b>IV Evidence synthesis and measurements with error</b></span></li>
<li class="chapter" data-level="13" data-path="ch-remame.html"><a href="ch-remame.html"><i class="fa fa-check"></i><b>13</b>  Meta-analysis and  measurement error models</a>
<ul>
<li class="chapter" data-level="13.1" data-path="ch-remame.html"><a href="ch-remame.html#meta-analysis"><i class="fa fa-check"></i><b>13.1</b> Meta-analysis</a>
<ul>
<li class="chapter" data-level="13.1.1" data-path="ch-remame.html"><a href="ch-remame.html#a-meta-analysis-of-similarity-based-interference-in-sentence-comprehension"><i class="fa fa-check"></i><b>13.1.1</b> A meta-analysis of similarity-based interference in sentence comprehension</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="ch-remame.html"><a href="ch-remame.html#measurement-error-models"><i class="fa fa-check"></i><b>13.2</b>  Measurement-error models</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="ch-remame.html"><a href="ch-remame.html#accounting-for-measurement-error-in-individual-differences-in-working-memory-capacity-and-reading-fluency"><i class="fa fa-check"></i><b>13.2.1</b> Accounting for measurement error in individual differences in working memory capacity and reading fluency</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="ch-remame.html"><a href="ch-remame.html#summary-11"><i class="fa fa-check"></i><b>13.3</b> Summary</a></li>
<li class="chapter" data-level="13.4" data-path="ch-remame.html"><a href="ch-remame.html#further-reading-10"><i class="fa fa-check"></i><b>13.4</b> Further reading</a></li>
<li class="chapter" data-level="13.5" data-path="ch-remame.html"><a href="ch-remame.html#sec-REMAMEexercises"><i class="fa fa-check"></i><b>13.5</b> Exercises</a></li>
</ul></li>
<li class="part"><span><b>V Model comparison</b></span></li>
<li class="chapter" data-level="14" data-path="ch-comparison.html"><a href="ch-comparison.html"><i class="fa fa-check"></i><b>14</b> Introduction to model comparison</a>
<ul>
<li class="chapter" data-level="14.1" data-path="ch-comparison.html"><a href="ch-comparison.html#prior-predictive-vs.-posterior-predictive-model-comparison"><i class="fa fa-check"></i><b>14.1</b> Prior predictive vs. posterior predictive model comparison</a></li>
<li class="chapter" data-level="14.2" data-path="ch-comparison.html"><a href="ch-comparison.html#some-important-points-to-consider-when-comparing-models"><i class="fa fa-check"></i><b>14.2</b> Some important points to consider when comparing models</a></li>
<li class="chapter" data-level="14.3" data-path="ch-comparison.html"><a href="ch-comparison.html#further-reading-11"><i class="fa fa-check"></i><b>14.3</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="ch-bf.html"><a href="ch-bf.html"><i class="fa fa-check"></i><b>15</b> Bayes factors</a>
<ul>
<li class="chapter" data-level="15.1" data-path="ch-bf.html"><a href="ch-bf.html#hypothesis-testing-using-the-bayes-factor"><i class="fa fa-check"></i><b>15.1</b> Hypothesis testing using the Bayes factor</a>
<ul>
<li class="chapter" data-level="15.1.1" data-path="ch-bf.html"><a href="ch-bf.html#marginal-likelihood"><i class="fa fa-check"></i><b>15.1.1</b> Marginal likelihood</a></li>
<li class="chapter" data-level="15.1.2" data-path="ch-bf.html"><a href="ch-bf.html#bayes-factor"><i class="fa fa-check"></i><b>15.1.2</b> Bayes factor</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="ch-bf.html"><a href="ch-bf.html#sec-N400BF"><i class="fa fa-check"></i><b>15.2</b> Examining the N400 effect with Bayes factor</a>
<ul>
<li class="chapter" data-level="15.2.1" data-path="ch-bf.html"><a href="ch-bf.html#sensitivity-analysis-1"><i class="fa fa-check"></i><b>15.2.1</b> Sensitivity analysis</a></li>
<li class="chapter" data-level="15.2.2" data-path="ch-bf.html"><a href="ch-bf.html#sec-BFnonnested"><i class="fa fa-check"></i><b>15.2.2</b>  Non-nested models</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="ch-bf.html"><a href="ch-bf.html#the-influence-of-the-priors-on-bayes-factors-beyond-the-effect-of-interest"><i class="fa fa-check"></i><b>15.3</b> The influence of the priors on Bayes factors: beyond the effect of interest</a></li>
<li class="chapter" data-level="15.4" data-path="ch-bf.html"><a href="ch-bf.html#sec-stanBF"><i class="fa fa-check"></i><b>15.4</b>  Bayes factor in Stan</a></li>
<li class="chapter" data-level="15.5" data-path="ch-bf.html"><a href="ch-bf.html#bayes-factors-in-theory-and-in-practice"><i class="fa fa-check"></i><b>15.5</b> Bayes factors in theory and in practice</a>
<ul>
<li class="chapter" data-level="15.5.1" data-path="ch-bf.html"><a href="ch-bf.html#bayes-factors-in-theory-stability-and-accuracy"><i class="fa fa-check"></i><b>15.5.1</b> Bayes factors in theory: Stability and  accuracy</a></li>
<li class="chapter" data-level="15.5.2" data-path="ch-bf.html"><a href="ch-bf.html#sec-BFvar"><i class="fa fa-check"></i><b>15.5.2</b> Bayes factors in practice: Variability with the data</a></li>
<li class="chapter" data-level="15.5.3" data-path="ch-bf.html"><a href="ch-bf.html#sec-caution"><i class="fa fa-check"></i><b>15.5.3</b> A cautionary note about Bayes factors</a></li>
</ul></li>
<li class="chapter" data-level="15.6" data-path="ch-bf.html"><a href="ch-bf.html#sample-size-determination-using-bayes-factors"><i class="fa fa-check"></i><b>15.6</b> Sample size determination using Bayes factors</a></li>
<li class="chapter" data-level="15.7" data-path="ch-bf.html"><a href="ch-bf.html#summary-12"><i class="fa fa-check"></i><b>15.7</b> Summary</a></li>
<li class="chapter" data-level="15.8" data-path="ch-bf.html"><a href="ch-bf.html#further-reading-12"><i class="fa fa-check"></i><b>15.8</b> Further reading</a></li>
<li class="chapter" data-level="15.9" data-path="ch-bf.html"><a href="ch-bf.html#exercises-2"><i class="fa fa-check"></i><b>15.9</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="ch-cv.html"><a href="ch-cv.html"><i class="fa fa-check"></i><b>16</b> Cross-validation</a>
<ul>
<li class="chapter" data-level="16.1" data-path="ch-cv.html"><a href="ch-cv.html#the-expected-log-predictive-density-of-a-model"><i class="fa fa-check"></i><b>16.1</b> The expected log predictive density of a model</a></li>
<li class="chapter" data-level="16.2" data-path="ch-cv.html"><a href="ch-cv.html#k-fold-and-leave-one-out-cross-validation"><i class="fa fa-check"></i><b>16.2</b> K-fold and leave-one-out cross-validation</a></li>
<li class="chapter" data-level="16.3" data-path="ch-cv.html"><a href="ch-cv.html#testing-the-n400-effect-using-cross-validation"><i class="fa fa-check"></i><b>16.3</b> Testing the N400 effect using cross-validation</a>
<ul>
<li class="chapter" data-level="16.3.1" data-path="ch-cv.html"><a href="ch-cv.html#cross-validation-with-psis-loo"><i class="fa fa-check"></i><b>16.3.1</b> Cross-validation with PSIS-LOO</a></li>
<li class="chapter" data-level="16.3.2" data-path="ch-cv.html"><a href="ch-cv.html#cross-validation-with-k-fold"><i class="fa fa-check"></i><b>16.3.2</b> Cross-validation with K-fold</a></li>
<li class="chapter" data-level="16.3.3" data-path="ch-cv.html"><a href="ch-cv.html#leave-one-group-out-cross-validation"><i class="fa fa-check"></i><b>16.3.3</b> Leave-one-group-out cross-validation</a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="ch-cv.html"><a href="ch-cv.html#sec-logcv"><i class="fa fa-check"></i><b>16.4</b>  Comparing different likelihoods with cross-validation</a></li>
<li class="chapter" data-level="16.5" data-path="ch-cv.html"><a href="ch-cv.html#sec-issuesCV"><i class="fa fa-check"></i><b>16.5</b> Issues with cross-validation</a></li>
<li class="chapter" data-level="16.6" data-path="ch-cv.html"><a href="ch-cv.html#cross-validation-in-stan"><i class="fa fa-check"></i><b>16.6</b> Cross-validation in Stan</a>
<ul>
<li class="chapter" data-level="16.6.1" data-path="ch-cv.html"><a href="ch-cv.html#psis-loo-cv-in-stan"><i class="fa fa-check"></i><b>16.6.1</b>  PSIS-LOO-CV in Stan</a></li>
</ul></li>
<li class="chapter" data-level="16.7" data-path="ch-cv.html"><a href="ch-cv.html#summary-13"><i class="fa fa-check"></i><b>16.7</b> Summary</a></li>
<li class="chapter" data-level="16.8" data-path="ch-cv.html"><a href="ch-cv.html#further-reading-13"><i class="fa fa-check"></i><b>16.8</b> Further reading</a></li>
<li class="chapter" data-level="16.9" data-path="ch-cv.html"><a href="ch-cv.html#exercises-3"><i class="fa fa-check"></i><b>16.9</b> Exercises</a></li>
</ul></li>
<li class="part"><span><b>VI Cognitive modeling with Stan</b></span></li>
<li class="chapter" data-level="17" data-path="ch-cogmod.html"><a href="ch-cogmod.html"><i class="fa fa-check"></i><b>17</b> Introduction to cognitive modeling</a>
<ul>
<li class="chapter" data-level="17.1" data-path="ch-cogmod.html"><a href="ch-cogmod.html#what-characterizes-a-computational-cognitive-model"><i class="fa fa-check"></i><b>17.1</b> What characterizes a computational cognitive model?</a></li>
<li class="chapter" data-level="17.2" data-path="ch-cogmod.html"><a href="ch-cogmod.html#some-advantages-of-taking-the-latent-variable-modeling-approach"><i class="fa fa-check"></i><b>17.2</b> Some advantages of taking the latent-variable modeling approach</a></li>
<li class="chapter" data-level="17.3" data-path="ch-cogmod.html"><a href="ch-cogmod.html#types-of-computational-cognitive-model"><i class="fa fa-check"></i><b>17.3</b> Types of computational cognitive model</a></li>
<li class="chapter" data-level="17.4" data-path="ch-cogmod.html"><a href="ch-cogmod.html#summary-14"><i class="fa fa-check"></i><b>17.4</b> Summary</a></li>
<li class="chapter" data-level="17.5" data-path="ch-cogmod.html"><a href="ch-cogmod.html#further-reading-14"><i class="fa fa-check"></i><b>17.5</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="ch-MPT.html"><a href="ch-MPT.html"><i class="fa fa-check"></i><b>18</b> Multinomial processing trees</a>
<ul>
<li class="chapter" data-level="18.1" data-path="ch-MPT.html"><a href="ch-MPT.html#modeling-multiple-categorical-responses"><i class="fa fa-check"></i><b>18.1</b> Modeling  multiple categorical responses</a>
<ul>
<li class="chapter" data-level="18.1.1" data-path="ch-MPT.html"><a href="ch-MPT.html#sec-mult"><i class="fa fa-check"></i><b>18.1.1</b> A model for multiple responses using the multinomial likelihood</a></li>
<li class="chapter" data-level="18.1.2" data-path="ch-MPT.html"><a href="ch-MPT.html#sec-cat"><i class="fa fa-check"></i><b>18.1.2</b> A model for multiple responses using the categorical distribution</a></li>
</ul></li>
<li class="chapter" data-level="18.2" data-path="ch-MPT.html"><a href="ch-MPT.html#modeling-picture-naming-abilities-in-aphasia-with-mpt-models"><i class="fa fa-check"></i><b>18.2</b> Modeling picture naming abilities in aphasia with MPT models</a>
<ul>
<li class="chapter" data-level="18.2.1" data-path="ch-MPT.html"><a href="ch-MPT.html#calculation-of-the-probabilities-in-the-mpt-branches"><i class="fa fa-check"></i><b>18.2.1</b> Calculation of the probabilities in the MPT branches</a></li>
<li class="chapter" data-level="18.2.2" data-path="ch-MPT.html"><a href="ch-MPT.html#sec-mpt-data"><i class="fa fa-check"></i><b>18.2.2</b> A simple MPT model</a></li>
<li class="chapter" data-level="18.2.3" data-path="ch-MPT.html"><a href="ch-MPT.html#sec-MPT-reg"><i class="fa fa-check"></i><b>18.2.3</b> An MPT model assuming by-item variability</a></li>
<li class="chapter" data-level="18.2.4" data-path="ch-MPT.html"><a href="ch-MPT.html#sec-MPT-h"><i class="fa fa-check"></i><b>18.2.4</b> A  hierarchical MPT</a></li>
</ul></li>
<li class="chapter" data-level="18.3" data-path="ch-MPT.html"><a href="ch-MPT.html#summary-15"><i class="fa fa-check"></i><b>18.3</b> Summary</a></li>
<li class="chapter" data-level="18.4" data-path="ch-MPT.html"><a href="ch-MPT.html#further-reading-15"><i class="fa fa-check"></i><b>18.4</b> Further reading</a></li>
<li class="chapter" data-level="18.5" data-path="ch-MPT.html"><a href="ch-MPT.html#exercises-4"><i class="fa fa-check"></i><b>18.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="ch-mixture.html"><a href="ch-mixture.html"><i class="fa fa-check"></i><b>19</b> Mixture models</a>
<ul>
<li class="chapter" data-level="19.1" data-path="ch-mixture.html"><a href="ch-mixture.html#a-mixture-model-of-the-speed-accuracy-trade-off-the-fast-guess-model-account"><i class="fa fa-check"></i><b>19.1</b> A mixture model of the speed-accuracy trade-off: The fast-guess model account</a>
<ul>
<li class="chapter" data-level="19.1.1" data-path="ch-mixture.html"><a href="ch-mixture.html#the-global-motion-detection-task"><i class="fa fa-check"></i><b>19.1.1</b> The global motion detection task</a></li>
<li class="chapter" data-level="19.1.2" data-path="ch-mixture.html"><a href="ch-mixture.html#sec-simplefastguess"><i class="fa fa-check"></i><b>19.1.2</b> A very simple implementation of the fast-guess model</a></li>
<li class="chapter" data-level="19.1.3" data-path="ch-mixture.html"><a href="ch-mixture.html#sec-multmix"><i class="fa fa-check"></i><b>19.1.3</b> A  multivariate implementation of the fast-guess model</a></li>
<li class="chapter" data-level="19.1.4" data-path="ch-mixture.html"><a href="ch-mixture.html#an-implementation-of-the-fast-guess-model-that-takes-instructions-into-account"><i class="fa fa-check"></i><b>19.1.4</b> An implementation of the fast-guess model that takes instructions into account</a></li>
<li class="chapter" data-level="19.1.5" data-path="ch-mixture.html"><a href="ch-mixture.html#sec-fastguessh"><i class="fa fa-check"></i><b>19.1.5</b> A  hierarchical implementation of the fast-guess model</a></li>
</ul></li>
<li class="chapter" data-level="19.2" data-path="ch-mixture.html"><a href="ch-mixture.html#summary-16"><i class="fa fa-check"></i><b>19.2</b> Summary</a></li>
<li class="chapter" data-level="19.3" data-path="ch-mixture.html"><a href="ch-mixture.html#further-reading-16"><i class="fa fa-check"></i><b>19.3</b> Further reading</a></li>
<li class="chapter" data-level="19.4" data-path="ch-mixture.html"><a href="ch-mixture.html#exercises-5"><i class="fa fa-check"></i><b>19.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="ch-lognormalrace.html"><a href="ch-lognormalrace.html"><i class="fa fa-check"></i><b>20</b> A simple accumulator model to account for choice response time</a>
<ul>
<li class="chapter" data-level="20.1" data-path="ch-lognormalrace.html"><a href="ch-lognormalrace.html#modeling-a-lexical-decision-task"><i class="fa fa-check"></i><b>20.1</b> Modeling a lexical decision task</a>
<ul>
<li class="chapter" data-level="20.1.1" data-path="ch-lognormalrace.html"><a href="ch-lognormalrace.html#sec-acccoding"><i class="fa fa-check"></i><b>20.1.1</b> Modeling the lexical decision task with the log-normal race model</a></li>
<li class="chapter" data-level="20.1.2" data-path="ch-lognormalrace.html"><a href="ch-lognormalrace.html#sec-genaccum"><i class="fa fa-check"></i><b>20.1.2</b> A generative model for a race between accumulators</a></li>
<li class="chapter" data-level="20.1.3" data-path="ch-lognormalrace.html"><a href="ch-lognormalrace.html#fitting-the-log-normal-race-model"><i class="fa fa-check"></i><b>20.1.3</b> Fitting the log-normal race model</a></li>
<li class="chapter" data-level="20.1.4" data-path="ch-lognormalrace.html"><a href="ch-lognormalrace.html#sec-lognormalh"><i class="fa fa-check"></i><b>20.1.4</b> A hierarchical implementation of the log-normal race model</a></li>
<li class="chapter" data-level="20.1.5" data-path="ch-lognormalrace.html"><a href="ch-lognormalrace.html#sec-contaminant"><i class="fa fa-check"></i><b>20.1.5</b> Dealing with  contaminant responses</a></li>
</ul></li>
<li class="chapter" data-level="20.2" data-path="ch-lognormalrace.html"><a href="ch-lognormalrace.html#posterior-predictive-check-with-the-quantile-probability-plots"><i class="fa fa-check"></i><b>20.2</b> Posterior predictive check with the quantile probability plots</a></li>
<li class="chapter" data-level="20.3" data-path="ch-lognormalrace.html"><a href="ch-lognormalrace.html#summary-17"><i class="fa fa-check"></i><b>20.3</b> Summary</a></li>
<li class="chapter" data-level="20.4" data-path="ch-lognormalrace.html"><a href="ch-lognormalrace.html#further-reading-17"><i class="fa fa-check"></i><b>20.4</b> Further reading</a></li>
<li class="chapter" data-level="20.5" data-path="ch-lognormalrace.html"><a href="ch-lognormalrace.html#exercises-6"><i class="fa fa-check"></i><b>20.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="ch-closing.html"><a href="ch-closing.html"><i class="fa fa-check"></i><b>21</b> In closing</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="_blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">An Introduction to Bayesian Data Analysis for Cognitive Science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="ch-coding2x2" class="section level1 hasAnchor" number="9">
<h1><span class="header-section-number">Chapter 9</span> Contrast coding for designs with two predictor variables<a href="ch-coding2x2.html#ch-coding2x2" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Chapter <a href="ch-contr.html#ch-contr">8</a> provides a basic introduction into contrast coding in situations where there is one predictor variable, i.e., one factor, for which its effect can be estimated using a specified contrast matrix. Here, we will investigate how contrast coding generalizes to situations where there is more than one predictor variable. This could either be a situation where two factors are present or where one factor is paired with a continuous predictor variable, i.e., a covariate. We first discuss contrast coding for the case of two factors (for <span class="math inline">\(2 \times 2\)</span> designs; section <a href="ch-coding2x2.html#sec-MR-ANOVA">9.1</a>) and then go on to investigate situations where one predictor is a factor and the other predictor is a covariate (section <a href="ch-coding2x2.html#sec-contrast-covariate">9.2</a>). Moreover, one problem in the analysis of interactions occurs in situations where the model is not linear, but has some non-linear link function, such as e.g., in logistic models or when assuming a log-normally distributed dependent variable. In these situations, the model makes predictions for each condition (i.e., design cell) at the latent level of the linear model. Sometimes it is important to translate these model predictions to the level of the observations (e.g., to probabilities in a logistic regression model). We will discuss how this can be implemented in section <a href="ch-coding2x2.html#sec-interactions-NLM">9.3</a>. We begin by treating contrast coding in a factorial <span class="math inline">\(2 \times 2\)</span> design.</p>
<div id="sec-MR-ANOVA" class="section level2 hasAnchor" number="9.1">
<h2><span class="header-section-number">9.1</span> Contrast coding in a factorial  <span class="math inline">\(2 \times 2\)</span> design<a href="ch-coding2x2.html#sec-MR-ANOVA" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In chapter <a href="ch-contr.html#ch-contr">8</a> in section <a href="ch-contr.html#sec-4levelFactor">8.3</a>, we used a data set with one 4-level factor. Here, we assume that the same four means come from an <span class="math inline">\(A(2) \times B(2)\)</span> between-subject-factor design rather than an F(4) between-subject-factor design. Load the simulated data and show summary statistics in Table <a href="ch-coding2x2.html#tab:cTab4Means">9.1</a> and in Figure <a href="ch-coding2x2.html#fig:twobytwosimdatFig">9.1</a>. The means and standard deviations are exactly the same as in Figure <a href="ch-contr.html#fig:helmertsimdatFig">8.2</a> and in Table <a href="ch-contr.html#tab:cTab3Means">8.3</a>.</p>
<div class="figure"><span style="display:block;" id="fig:twobytwosimdatFig"></span>
<img src="bookdown_files/figure-html/twobytwosimdatFig-1.svg" alt="Means and error bars (showing standard errors) for a simulated data set with a two-by-two  between-subjects factorial design." width="480" />
<p class="caption">
FIGURE 9.1: Means and error bars (showing standard errors) for a simulated data set with a two-by-two between-subjects factorial design.
</p>
</div>
<table>
<caption><span id="tab:cTab4Means">TABLE 9.1: </span>Summary statistics per condition for the simulated data.</caption>
<thead>
<tr class="header">
<th align="left">Factor A</th>
<th align="left">Factor B</th>
<th align="left">N data</th>
<th align="left">Means</th>
<th align="left">Std. dev.</th>
<th align="left">Std. errors</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">A1</td>
<td align="left">B1</td>
<td align="left"><span class="math inline">\(5\)</span></td>
<td align="left"><span class="math inline">\(10\)</span></td>
<td align="left"><span class="math inline">\(10\)</span></td>
<td align="left"><span class="math inline">\(4.5\)</span></td>
</tr>
<tr class="even">
<td align="left">A1</td>
<td align="left">B2</td>
<td align="left"><span class="math inline">\(5\)</span></td>
<td align="left"><span class="math inline">\(20\)</span></td>
<td align="left"><span class="math inline">\(10\)</span></td>
<td align="left"><span class="math inline">\(4.5\)</span></td>
</tr>
<tr class="odd">
<td align="left">A2</td>
<td align="left">B1</td>
<td align="left"><span class="math inline">\(5\)</span></td>
<td align="left"><span class="math inline">\(10\)</span></td>
<td align="left"><span class="math inline">\(10\)</span></td>
<td align="left"><span class="math inline">\(4.5\)</span></td>
</tr>
<tr class="even">
<td align="left">A2</td>
<td align="left">B2</td>
<td align="left"><span class="math inline">\(5\)</span></td>
<td align="left"><span class="math inline">\(40\)</span></td>
<td align="left"><span class="math inline">\(10\)</span></td>
<td align="left"><span class="math inline">\(4.5\)</span></td>
</tr>
</tbody>
</table>
<p>In order to carry out a <span class="math inline">\(2\times 2\)</span>  ANOVA-type  (main effects and  interaction) analysis, one needs  sum contrasts in the linear model. (This is true for factors with two levels, but does not generalize to factors with more levels.) The results of such an analysis are shown in Table <a href="ch-coding2x2.html#tab:table18b">9.2</a>. (This analysis uses sum contrasts: <span class="math inline">\(-1\)</span>/<span class="math inline">\(+1\)</span>; however, scaled sum contrasts <span class="math inline">\(-0.5\)</span>/<span class="math inline">\(+0.5\)</span> could also be used; in this case, the priors would need to be adapted to the respective scale.)</p>
<div class="sourceCode" id="cb499"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb499-1"><a href="ch-coding2x2.html#cb499-1" aria-hidden="true"></a><span class="kw">contrasts</span>(df_contrasts4<span class="op">$</span>A) &lt;-<span class="st"> </span><span class="kw">contr.sum</span>(<span class="dv">2</span>)</span>
<span id="cb499-2"><a href="ch-coding2x2.html#cb499-2" aria-hidden="true"></a><span class="kw">contrasts</span>(df_contrasts4<span class="op">$</span>B) &lt;-<span class="st"> </span><span class="kw">contr.sum</span>(<span class="dv">2</span>)</span></code></pre></div>
<div class="sourceCode" id="cb500"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb500-1"><a href="ch-coding2x2.html#cb500-1" aria-hidden="true"></a>fit_AB.sum &lt;-<span class="st"> </span><span class="kw">brm</span>(DV <span class="op">~</span><span class="st"> </span>A <span class="op">*</span><span class="st"> </span>B,</span>
<span id="cb500-2"><a href="ch-coding2x2.html#cb500-2" aria-hidden="true"></a>                  <span class="dt">data =</span> df_contrasts4,</span>
<span id="cb500-3"><a href="ch-coding2x2.html#cb500-3" aria-hidden="true"></a>                  <span class="dt">family =</span> <span class="kw">gaussian</span>(),</span>
<span id="cb500-4"><a href="ch-coding2x2.html#cb500-4" aria-hidden="true"></a>                  <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">20</span>, <span class="dv">50</span>), <span class="dt">class =</span> Intercept),</span>
<span id="cb500-5"><a href="ch-coding2x2.html#cb500-5" aria-hidden="true"></a>                            <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">50</span>), <span class="dt">class =</span> sigma),</span>
<span id="cb500-6"><a href="ch-coding2x2.html#cb500-6" aria-hidden="true"></a>                            <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">50</span>), <span class="dt">class =</span> b)))</span></code></pre></div>
<table>
<caption><span id="tab:table18b">TABLE 9.2: </span>Bayesian linear model of a 2 x 2 design with sum contrasts.</caption>
<thead>
<tr class="header">
<th align="left">Predictor</th>
<th align="left">Estimate</th>
<th align="left">Est. Error</th>
<th align="left">2.5%</th>
<th align="left">97.5%</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Intercept</td>
<td align="left"><span class="math inline">\(20.02\)</span></td>
<td align="left"><span class="math inline">\(2.43\)</span></td>
<td align="left"><span class="math inline">\(15.25\)</span></td>
<td align="left"><span class="math inline">\(24.82\)</span></td>
</tr>
<tr class="even">
<td align="left">A1</td>
<td align="left"><span class="math inline">\(-4.94\)</span></td>
<td align="left"><span class="math inline">\(2.47\)</span></td>
<td align="left"><span class="math inline">\(-9.71\)</span></td>
<td align="left"><span class="math inline">\(0.16\)</span></td>
</tr>
<tr class="odd">
<td align="left">B1</td>
<td align="left"><span class="math inline">\(-9.99\)</span></td>
<td align="left"><span class="math inline">\(2.58\)</span></td>
<td align="left"><span class="math inline">\(-15.04\)</span></td>
<td align="left"><span class="math inline">\(-4.87\)</span></td>
</tr>
<tr class="even">
<td align="left">A1:B1</td>
<td align="left"><span class="math inline">\(4.98\)</span></td>
<td align="left"><span class="math inline">\(2.45\)</span></td>
<td align="left"><span class="math inline">\(0.16\)</span></td>
<td align="left"><span class="math inline">\(9.84\)</span></td>
</tr>
</tbody>
</table>
<p>Next, we reproduce the <span class="math inline">\(A(2) \times B(2)\)</span> - ANOVA with contrasts specified for the corresponding one-way <span class="math inline">\(F(4)\)</span> ANOVA, that is by treating the <span class="math inline">\(2 \times 2 = 4\)</span> condition means as four levels of a single factor <span class="math inline">\(F\)</span>. In other words, we go back to the data frame simulated for the analysis of repeated contrasts (see chapter <a href="ch-contr.html#ch-contr">8</a>, section <a href="ch-contr.html#sec-4levelFactor">8.3</a>). We first define weights for condition means according to our hypotheses, invert this matrix, and use it as the contrast matrix for factor <span class="math inline">\(F\)</span>. We define weights of <span class="math inline">\(1/4\)</span> and <span class="math inline">\(-1/4\)</span>. We do so because (a) we want to compare the mean of two conditions to the mean of two other conditions (e.g., factor <span class="math inline">\(A\)</span> compares <span class="math inline">\(\frac{F1 + F2}{2}\)</span> to <span class="math inline">\(\frac{F3 + F4}{2}\)</span>). Moreover, (b) we want coefficients to code half the difference between condition means, reflecting sum contrasts. Together <span class="math inline">\((a+b)\)</span>, this yields weights of <span class="math inline">\(1/2 \cdot 1/2 = 1/4\)</span>. The resulting contrast matrix contains contrast coefficients of <span class="math inline">\(+1\)</span> or <span class="math inline">\(-1\)</span>, showing that we successfully implemented sum contrasts. The results are identical to the previous models.</p>
<div class="sourceCode" id="cb501"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb501-1"><a href="ch-coding2x2.html#cb501-1" aria-hidden="true"></a>HcInt &lt;-</span>
<span id="cb501-2"><a href="ch-coding2x2.html#cb501-2" aria-hidden="true"></a><span class="st">  </span><span class="kw">rbind</span>(<span class="dt">A =</span> <span class="kw">c</span>(<span class="dt">F1 =</span> <span class="dv">1</span> <span class="op">/</span><span class="st"> </span><span class="dv">4</span>, <span class="dt">F2 =</span> <span class="dv">1</span> <span class="op">/</span><span class="st"> </span><span class="dv">4</span>, <span class="dt">F3 =</span> <span class="dv">-1</span> <span class="op">/</span><span class="st"> </span><span class="dv">4</span>, <span class="dt">F4 =</span> <span class="dv">-1</span> <span class="op">/</span><span class="st"> </span><span class="dv">4</span>),</span>
<span id="cb501-3"><a href="ch-coding2x2.html#cb501-3" aria-hidden="true"></a>        <span class="dt">B =</span> <span class="kw">c</span>(<span class="dt">F1 =</span> <span class="dv">1</span> <span class="op">/</span><span class="st"> </span><span class="dv">4</span>, <span class="dt">F2 =</span> <span class="dv">-1</span> <span class="op">/</span><span class="st"> </span><span class="dv">4</span>, <span class="dt">F3 =</span> <span class="dv">1</span> <span class="op">/</span><span class="st"> </span><span class="dv">4</span>, <span class="dt">F4 =</span> <span class="dv">-1</span> <span class="op">/</span><span class="st"> </span><span class="dv">4</span>),</span>
<span id="cb501-4"><a href="ch-coding2x2.html#cb501-4" aria-hidden="true"></a>        <span class="dt">AxB =</span> <span class="kw">c</span>(<span class="dt">F1 =</span> <span class="dv">1</span> <span class="op">/</span><span class="st"> </span><span class="dv">4</span>, <span class="dt">F2 =</span> <span class="dv">-1</span> <span class="op">/</span><span class="st"> </span><span class="dv">4</span>, <span class="dt">F3 =</span> <span class="dv">-1</span> <span class="op">/</span><span class="st"> </span><span class="dv">4</span>, <span class="dt">F4 =</span> <span class="dv">1</span> <span class="op">/</span><span class="st"> </span><span class="dv">4</span>))</span>
<span id="cb501-5"><a href="ch-coding2x2.html#cb501-5" aria-hidden="true"></a><span class="kw">t</span>(<span class="kw">fractions</span>(HcInt))</span></code></pre></div>
<pre><code>##    A    B    AxB 
## F1  1/4  1/4  1/4
## F2  1/4 -1/4 -1/4
## F3 -1/4  1/4 -1/4
## F4 -1/4 -1/4  1/4</code></pre>
<div class="sourceCode" id="cb503"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb503-1"><a href="ch-coding2x2.html#cb503-1" aria-hidden="true"></a>(XcInt &lt;-<span class="st"> </span><span class="kw">ginv2</span>(HcInt))</span></code></pre></div>
<pre><code>##    A  B  AxB
## F1  1  1  1 
## F2  1 -1 -1 
## F3 -1  1 -1 
## F4 -1 -1  1</code></pre>
<div class="sourceCode" id="cb505"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb505-1"><a href="ch-coding2x2.html#cb505-1" aria-hidden="true"></a><span class="kw">contrasts</span>(df_contrasts3<span class="op">$</span>F) &lt;-<span class="st"> </span>XcInt</span></code></pre></div>
<div class="sourceCode" id="cb506"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb506-1"><a href="ch-coding2x2.html#cb506-1" aria-hidden="true"></a>fit_F4.sum &lt;-<span class="st"> </span><span class="kw">brm</span>(DV <span class="op">~</span><span class="st"> </span>F,</span>
<span id="cb506-2"><a href="ch-coding2x2.html#cb506-2" aria-hidden="true"></a>                  <span class="dt">data =</span> df_contrasts3,</span>
<span id="cb506-3"><a href="ch-coding2x2.html#cb506-3" aria-hidden="true"></a>                  <span class="dt">family =</span> <span class="kw">gaussian</span>(),</span>
<span id="cb506-4"><a href="ch-coding2x2.html#cb506-4" aria-hidden="true"></a>                  <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">20</span>, <span class="dv">50</span>), <span class="dt">class =</span> Intercept),</span>
<span id="cb506-5"><a href="ch-coding2x2.html#cb506-5" aria-hidden="true"></a>                            <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">50</span>), <span class="dt">class =</span> sigma),</span>
<span id="cb506-6"><a href="ch-coding2x2.html#cb506-6" aria-hidden="true"></a>                            <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">50</span>), <span class="dt">class =</span> b)))</span></code></pre></div>
<div class="sourceCode" id="cb507"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb507-1"><a href="ch-coding2x2.html#cb507-1" aria-hidden="true"></a><span class="kw">fixef</span>(fit_F4.sum)</span></code></pre></div>
<pre><code>##           Estimate Est.Error   Q2.5 Q97.5
## Intercept    20.07      2.42  15.29 24.89
## FA           -4.96      2.46  -9.75 -0.09
## FB           -9.96      2.45 -14.92 -5.21
## FAxB          5.01      2.51   0.16 10.10</code></pre>
<p>This shows that it is possible to specify the contrasts not only for each factor (e.g., here in the <span class="math inline">\(2 \times 2\)</span> design) separately. Instead, one can also pool all experimental conditions (or design cells) into one large factor (here factor <span class="math inline">\(F\)</span> with <span class="math inline">\(4\)</span> levels), and specify the contrasts for the main effects and for the interactions in the resulting one large contrast matrix simultaneously.</p>
<p>In this approach, it can again be very useful to apply the  <code>hypr</code> package to construct contrasts for a  <span class="math inline">\(2 \times 2\)</span> design. The first parameter estimates the main effect <span class="math inline">\(A\)</span>, i.e., it compares the average of <span class="math inline">\(F1\)</span> and <span class="math inline">\(F2\)</span> to the average of <span class="math inline">\(F3\)</span> and <span class="math inline">\(F4\)</span>. The second parameter estimates the main effect <span class="math inline">\(B\)</span>, i.e., it compares the average of <span class="math inline">\(F1\)</span> and <span class="math inline">\(F3\)</span> to the average of <span class="math inline">\(F2\)</span> and <span class="math inline">\(F4\)</span>. We code direct differences between the averages, i.e., we implement scaled sum contrasts instead of sum contrasts. This is shown below: the contrast matrix contains coefficients of <span class="math inline">\(+1/2\)</span> and <span class="math inline">\(-1/2\)</span> instead of <span class="math inline">\(+1\)</span> and <span class="math inline">\(-1\)</span>. The  interaction term estimates the difference between differences, i.e., the difference between <span class="math inline">\(F1 - F2\)</span> and <span class="math inline">\(F3 - F4\)</span>.</p>
<div class="sourceCode" id="cb509"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb509-1"><a href="ch-coding2x2.html#cb509-1" aria-hidden="true"></a>hAxB &lt;-<span class="st"> </span><span class="kw">hypr</span>(<span class="dt">A =</span> (F1 <span class="op">+</span><span class="st"> </span>F2) <span class="op">/</span><span class="st"> </span><span class="dv">2</span> <span class="op">~</span><span class="st"> </span>(F3 <span class="op">+</span><span class="st"> </span>F4) <span class="op">/</span><span class="st"> </span><span class="dv">2</span>,</span>
<span id="cb509-2"><a href="ch-coding2x2.html#cb509-2" aria-hidden="true"></a>             <span class="dt">B =</span> (F1 <span class="op">+</span><span class="st"> </span>F3) <span class="op">/</span><span class="st"> </span><span class="dv">2</span> <span class="op">~</span><span class="st"> </span>(F2 <span class="op">+</span><span class="st"> </span>F4) <span class="op">/</span><span class="st"> </span><span class="dv">2</span>,</span>
<span id="cb509-3"><a href="ch-coding2x2.html#cb509-3" aria-hidden="true"></a>             <span class="dt">AxB =</span> (F1 <span class="op">-</span><span class="st"> </span>F2) <span class="op">~</span><span class="st"> </span>(F3 <span class="op">-</span><span class="st"> </span>F4))</span>
<span id="cb509-4"><a href="ch-coding2x2.html#cb509-4" aria-hidden="true"></a>hAxB</span></code></pre></div>
<pre><code>## hypr object containing 3 null hypotheses:
##   H0.A: 0 = (F1 + F2 - F3 - F4)/2
##   H0.B: 0 = (F1 + F3 - F2 - F4)/2
## H0.AxB: 0 = F1 - F2 - F3 + F4
## 
## Call:
## hypr(A = ~1/2 * F1 + 1/2 * F2 - 1/2 * F3 - 1/2 * F4, B = ~1/2 * 
##     F1 + 1/2 * F3 - 1/2 * F2 - 1/2 * F4, AxB = ~F1 - F2 - F3 + 
##     F4, levels = c(&quot;F1&quot;, &quot;F2&quot;, &quot;F3&quot;, &quot;F4&quot;))
## 
## Hypothesis matrix (transposed):
##    A    B    AxB 
## F1  1/2  1/2    1
## F2  1/2 -1/2   -1
## F3 -1/2  1/2   -1
## F4 -1/2 -1/2    1
## 
## Contrast matrix:
##    A    B    AxB 
## F1  1/2  1/2  1/4
## F2  1/2 -1/2 -1/4
## F3 -1/2  1/2 -1/4
## F4 -1/2 -1/2  1/4</code></pre>
<div class="sourceCode" id="cb511"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb511-1"><a href="ch-coding2x2.html#cb511-1" aria-hidden="true"></a><span class="kw">contrasts</span>(df_contrasts3<span class="op">$</span>F) &lt;-<span class="st"> </span><span class="kw">contr.hypothesis</span>(hAxB)</span></code></pre></div>
<div class="sourceCode" id="cb512"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb512-1"><a href="ch-coding2x2.html#cb512-1" aria-hidden="true"></a>fit_F4hypr &lt;-<span class="st"> </span><span class="kw">brm</span>(DV <span class="op">~</span><span class="st"> </span>F,</span>
<span id="cb512-2"><a href="ch-coding2x2.html#cb512-2" aria-hidden="true"></a>                  <span class="dt">data =</span> df_contrasts3,</span>
<span id="cb512-3"><a href="ch-coding2x2.html#cb512-3" aria-hidden="true"></a>                  <span class="dt">family =</span> <span class="kw">gaussian</span>(),</span>
<span id="cb512-4"><a href="ch-coding2x2.html#cb512-4" aria-hidden="true"></a>                  <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">20</span>, <span class="dv">50</span>), <span class="dt">class =</span> Intercept),</span>
<span id="cb512-5"><a href="ch-coding2x2.html#cb512-5" aria-hidden="true"></a>                            <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">50</span>), <span class="dt">class =</span> sigma),</span>
<span id="cb512-6"><a href="ch-coding2x2.html#cb512-6" aria-hidden="true"></a>                            <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">50</span>), <span class="dt">class =</span> b)))</span></code></pre></div>
<div class="sourceCode" id="cb513"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb513-1"><a href="ch-coding2x2.html#cb513-1" aria-hidden="true"></a><span class="kw">fixef</span>(fit_F4hypr)</span></code></pre></div>
<pre><code>##           Estimate Est.Error   Q2.5 Q97.5
## Intercept    20.08      2.53  15.28 25.19
## FA           -9.89      4.97 -19.65 -0.25
## FB          -19.86      5.03 -29.61 -9.98
## FAxB         19.23      9.88  -0.96 37.71</code></pre>
<p>The results show that the estimates for the main effects have double the size as compared to the sum contrasts–this is the result of the scaling that we applied. I.e., the main effects now directly estimate the difference between averages. The interaction estimates the difference between differences. Importantly, if we change the scaling of the contrasts, we also need to adapt the scaling of the priors. If adequate priors are used, then both contrasts would lead to the same hypothesis tests if one were doing hypothesis testing using Bayes factors. Thus, the <code>hypr</code> package can be used to code hypotheses in a <span class="math inline">\(2 \times 2\)</span> design.</p>
<p>An alternative way to code main effects and interactions is to use the <code>ifelse</code> command in R. For example, if we want to use <span class="math inline">\(\pm 1\)</span> sum contrasts in the above example, we can specify the contrasts for the main effects as vectors:</p>
<div class="sourceCode" id="cb515"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb515-1"><a href="ch-coding2x2.html#cb515-1" aria-hidden="true"></a>A &lt;-<span class="st"> </span><span class="kw">ifelse</span>(df_contrasts3<span class="op">$</span>F <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;F1&quot;</span>, <span class="st">&quot;F2&quot;</span>), <span class="dv">-1</span>, <span class="dv">1</span>)</span>
<span id="cb515-2"><a href="ch-coding2x2.html#cb515-2" aria-hidden="true"></a>B &lt;-<span class="st"> </span><span class="kw">ifelse</span>(df_contrasts3<span class="op">$</span>F <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;F1&quot;</span>, <span class="st">&quot;F3&quot;</span>), <span class="dv">-1</span>, <span class="dv">1</span>)</span></code></pre></div>
<p>Now, defining the interaction is simply a matter of multiplying the two vectors:</p>
<div class="sourceCode" id="cb516"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb516-1"><a href="ch-coding2x2.html#cb516-1" aria-hidden="true"></a>AxB &lt;-<span class="st"> </span>A <span class="op">*</span><span class="st"> </span>B</span></code></pre></div>
<p>An alternative is to use <span class="math inline">\(\pm 1/2\)</span> coding when using this approach:</p>
<div class="sourceCode" id="cb517"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb517-1"><a href="ch-coding2x2.html#cb517-1" aria-hidden="true"></a>A &lt;-<span class="st"> </span><span class="kw">ifelse</span>(df_contrasts3<span class="op">$</span>F <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;F1&quot;</span>, <span class="st">&quot;F2&quot;</span>), <span class="dv">-1</span> <span class="op">/</span><span class="st"> </span><span class="dv">2</span>, <span class="dv">1</span> <span class="op">/</span><span class="st"> </span><span class="dv">2</span>)</span>
<span id="cb517-2"><a href="ch-coding2x2.html#cb517-2" aria-hidden="true"></a>B &lt;-<span class="st"> </span><span class="kw">ifelse</span>(df_contrasts3<span class="op">$</span>F <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;F1&quot;</span>, <span class="st">&quot;F3&quot;</span>), <span class="dv">-1</span> <span class="op">/</span><span class="st"> </span><span class="dv">2</span>, <span class="dv">1</span> <span class="op">/</span><span class="st"> </span><span class="dv">2</span>)</span>
<span id="cb517-3"><a href="ch-coding2x2.html#cb517-3" aria-hidden="true"></a><span class="co">## interaction:</span></span>
<span id="cb517-4"><a href="ch-coding2x2.html#cb517-4" aria-hidden="true"></a>(AxB &lt;-<span class="st"> </span>A <span class="op">*</span><span class="st"> </span>B)</span></code></pre></div>
<pre><code>##  [1]  0.25  0.25  0.25  0.25  0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25
## [12] -0.25 -0.25 -0.25 -0.25  0.25  0.25  0.25  0.25  0.25</code></pre>
<p>Now the main effects and interaction can be directly interpreted as differences between averages and as differences between differences. If one wants the interaction term to be on the same scale as the main effects, it would need to be multiplied by 2, however, then its interpretation would not be straightforward (i.e., “the difference between differences”) any more, but a scaled variant of this.
Thus, putting the interaction on the same scale as the main effects has the advantage that it ensures that the prior has the same scaling across the different terms. However, it has the disadvantage that the interpretation of the interaction term is not straightforward.</p>
<div class="sourceCode" id="cb519"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb519-1"><a href="ch-coding2x2.html#cb519-1" aria-hidden="true"></a><span class="co">## rescale:</span></span>
<span id="cb519-2"><a href="ch-coding2x2.html#cb519-2" aria-hidden="true"></a>(AxB &lt;-<span class="st"> </span>A <span class="op">*</span><span class="st"> </span>B <span class="op">*</span><span class="st"> </span><span class="dv">2</span>)</span></code></pre></div>
<pre><code>##  [1]  0.5  0.5  0.5  0.5  0.5 -0.5 -0.5 -0.5 -0.5 -0.5 -0.5 -0.5 -0.5
## [14] -0.5 -0.5  0.5  0.5  0.5  0.5  0.5</code></pre>
<p>This kind of vector-based contrast coding is convenient for more complex designs, such as <span class="math inline">\(2\times 2\times 2\)</span> factorial designs.</p>
<div id="nestedEffects" class="section level3 hasAnchor" number="9.1.1">
<h3><span class="header-section-number">9.1.1</span>  Nested effects<a href="ch-coding2x2.html#nestedEffects" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>One can estimate effects that do not correspond directly to main effects and interaction of the traditional ANOVA. For example, in a <span class="math inline">\(2 \times 2\)</span> experimental design, where factor <span class="math inline">\(A\)</span> codes word frequency (low/high) and factor <span class="math inline">\(B\)</span> is part of speech (noun/verb), one can estimate the effect of word frequency within nouns and the effect of word frequency within verbs. Formally, <span class="math inline">\(A_{B1}\)</span> versus <span class="math inline">\(A_{B2}\)</span> are nested within levels of <span class="math inline">\(B\)</span>. Said differently,  simple effects of factor <span class="math inline">\(A\)</span> are estimated for each of the levels of factor <span class="math inline">\(B\)</span>.
In this version, we estimate the main effect of part of speech (<span class="math inline">\(B\)</span>; as in traditional ANOVA). Instead of also estimating the second main effect word frequency, <span class="math inline">\(A\)</span>, and the interaction, we estimate (1) the differences between the two levels of word frequency <span class="math inline">\(A\)</span> in the first level of <span class="math inline">\(B\)</span> (i.e., nouns), and (2) the difference between the two levels of word frequency <span class="math inline">\(A\)</span> in the second level of <span class="math inline">\(B\)</span> (i.e., verbs). In other words, we estimate the differences between the two levels of <span class="math inline">\(A\)</span> in each of the levels of <span class="math inline">\(B\)</span>. Often, researchers have hypotheses about these differences, and not about the interaction.</p>
<div class="sourceCode" id="cb521"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb521-1"><a href="ch-coding2x2.html#cb521-1" aria-hidden="true"></a>HcNes &lt;-</span>
<span id="cb521-2"><a href="ch-coding2x2.html#cb521-2" aria-hidden="true"></a><span class="st">  </span><span class="kw">rbind</span>(<span class="dt">B =</span> <span class="kw">c</span>(<span class="dt">F1 =</span> <span class="dv">1</span> <span class="op">/</span><span class="st"> </span><span class="dv">2</span>, <span class="dt">F2 =</span> <span class="dv">-1</span> <span class="op">/</span><span class="st"> </span><span class="dv">2</span>, <span class="dt">F3 =</span> <span class="dv">1</span> <span class="op">/</span><span class="st"> </span><span class="dv">2</span>, <span class="dt">F4 =</span> <span class="dv">-1</span> <span class="op">/</span><span class="st"> </span><span class="dv">2</span>),</span>
<span id="cb521-3"><a href="ch-coding2x2.html#cb521-3" aria-hidden="true"></a>        <span class="dt">B1xA =</span> <span class="kw">c</span>(<span class="dt">F1 =</span> <span class="dv">-1</span>, <span class="dt">F2 =</span> <span class="dv">0</span>, <span class="dt">F3 =</span> <span class="dv">1</span>, <span class="dt">F4 =</span> <span class="dv">0</span>),</span>
<span id="cb521-4"><a href="ch-coding2x2.html#cb521-4" aria-hidden="true"></a>        <span class="dt">B2xA =</span> <span class="kw">c</span>(<span class="dt">F1 =</span> <span class="dv">0</span>, <span class="dt">F2 =</span> <span class="dv">-1</span>, <span class="dt">F3 =</span> <span class="dv">0</span>, <span class="dt">F4 =</span> <span class="dv">1</span>))</span>
<span id="cb521-5"><a href="ch-coding2x2.html#cb521-5" aria-hidden="true"></a><span class="kw">t</span>(<span class="kw">fractions</span>(HcNes))</span></code></pre></div>
<pre><code>##    B    B1xA B2xA
## F1  1/2   -1    0
## F2 -1/2    0   -1
## F3  1/2    1    0
## F4 -1/2    0    1</code></pre>
<div class="sourceCode" id="cb523"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb523-1"><a href="ch-coding2x2.html#cb523-1" aria-hidden="true"></a>(XcNes &lt;-<span class="st"> </span><span class="kw">ginv2</span>(HcNes))</span></code></pre></div>
<pre><code>##    B    B1xA B2xA
## F1  1/2 -1/2    0
## F2 -1/2    0 -1/2
## F3  1/2  1/2    0
## F4 -1/2    0  1/2</code></pre>
<div class="sourceCode" id="cb525"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb525-1"><a href="ch-coding2x2.html#cb525-1" aria-hidden="true"></a><span class="kw">contrasts</span>(df_contrasts3<span class="op">$</span>F) &lt;-<span class="st"> </span>XcNes</span></code></pre></div>
<div class="sourceCode" id="cb526"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb526-1"><a href="ch-coding2x2.html#cb526-1" aria-hidden="true"></a>fit_Nest &lt;-<span class="st"> </span><span class="kw">brm</span>(DV <span class="op">~</span><span class="st"> </span>F,</span>
<span id="cb526-2"><a href="ch-coding2x2.html#cb526-2" aria-hidden="true"></a>                <span class="dt">data =</span> df_contrasts3,</span>
<span id="cb526-3"><a href="ch-coding2x2.html#cb526-3" aria-hidden="true"></a>                <span class="dt">family =</span> <span class="kw">gaussian</span>(),</span>
<span id="cb526-4"><a href="ch-coding2x2.html#cb526-4" aria-hidden="true"></a>                <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">20</span>, <span class="dv">50</span>), <span class="dt">class =</span> Intercept),</span>
<span id="cb526-5"><a href="ch-coding2x2.html#cb526-5" aria-hidden="true"></a>                          <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">50</span>), <span class="dt">class =</span> sigma),</span>
<span id="cb526-6"><a href="ch-coding2x2.html#cb526-6" aria-hidden="true"></a>                          <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">50</span>), <span class="dt">class =</span> b)))</span></code></pre></div>
<div class="sourceCode" id="cb527"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb527-1"><a href="ch-coding2x2.html#cb527-1" aria-hidden="true"></a><span class="kw">fixef</span>(fit_Nest)</span></code></pre></div>
<pre><code>##           Estimate Est.Error   Q2.5 Q97.5
## Intercept    20.09      2.53  15.11  25.2
## FB          -19.79      4.83 -29.27 -10.2
## FB1xA        -0.01      7.03 -13.95  13.8
## FB2xA        19.61      6.94   5.57  33.2</code></pre>
<p>The regression coefficients estimate the  grand mean, the difference for the  main effect of part of speech (<span class="math inline">\(B\)</span>) and the two differences (for <span class="math inline">\(A\)</span>; i.e., simple main effects) within the two levels (noun and verb) of part of speech (<span class="math inline">\(B\)</span>).</p>
<p>These  custom nested contrasts’ columns are scaled versions of the corresponding  hypothesis matrix. This is the case because the columns are orthogonal. It illustrates one advantage of  orthogonal contrasts for the interpretation of regression coefficients: the underlying comparisons being estimated are already clear from the contrast matrix.</p>
<p>There is also a built-in R formula specification for nested designs. The order of factors in the formula from left to right specifies a top-down order of nesting within levels, i.e., here factor <span class="math inline">\(A\)</span> (word frequency) is nested within levels of the factor <span class="math inline">\(B\)</span> (part of speech). This yields the same result as our previous result based on custom nested contrasts:</p>
<div class="sourceCode" id="cb529"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb529-1"><a href="ch-coding2x2.html#cb529-1" aria-hidden="true"></a><span class="kw">contrasts</span>(df_contrasts4<span class="op">$</span>A) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="op">-</span><span class="fl">0.5</span>, <span class="fl">+0.5</span>)</span>
<span id="cb529-2"><a href="ch-coding2x2.html#cb529-2" aria-hidden="true"></a><span class="kw">contrasts</span>(df_contrasts4<span class="op">$</span>B) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="op">+</span><span class="fl">0.5</span>, <span class="fl">-0.5</span>)</span>
<span id="cb529-3"><a href="ch-coding2x2.html#cb529-3" aria-hidden="true"></a>fit_Nest2 &lt;-<span class="st"> </span><span class="kw">brm</span>(DV <span class="op">~</span><span class="st"> </span>B <span class="op">/</span><span class="st"> </span>A,</span>
<span id="cb529-4"><a href="ch-coding2x2.html#cb529-4" aria-hidden="true"></a>                 <span class="dt">data =</span> df_contrasts4,</span>
<span id="cb529-5"><a href="ch-coding2x2.html#cb529-5" aria-hidden="true"></a>                 <span class="dt">family =</span> <span class="kw">gaussian</span>(),</span>
<span id="cb529-6"><a href="ch-coding2x2.html#cb529-6" aria-hidden="true"></a>                 <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">20</span>, <span class="dv">50</span>), <span class="dt">class =</span> Intercept),</span>
<span id="cb529-7"><a href="ch-coding2x2.html#cb529-7" aria-hidden="true"></a>                           <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">50</span>), <span class="dt">class =</span> sigma),</span>
<span id="cb529-8"><a href="ch-coding2x2.html#cb529-8" aria-hidden="true"></a>                           <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">50</span>), <span class="dt">class =</span> b)))</span></code></pre></div>
<div class="sourceCode" id="cb530"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb530-1"><a href="ch-coding2x2.html#cb530-1" aria-hidden="true"></a><span class="kw">fixef</span>(fit_Nest2)</span></code></pre></div>
<pre><code>##           Estimate Est.Error   Q2.5 Q97.5
## Intercept    19.98      2.45  15.12  24.9
## B1          -19.87      4.95 -29.83 -10.0
## BB1:A1        0.02      6.75 -13.17  13.7
## BB2:A1       19.45      7.09   5.01  33.8</code></pre>
<p>In cases such as these, where <span class="math inline">\(A_{B1}\)</span> vs. <span class="math inline">\(A_{B2}\)</span> are nested within levels of <span class="math inline">\(B\)</span>, it is necessary to include the effect of <span class="math inline">\(B\)</span> (part of speech) in the model, even if one is only interested in the effect of <span class="math inline">\(A\)</span> (word frequency) within levels of <span class="math inline">\(B\)</span> (part of speech). Leaving out factor <span class="math inline">\(B\)</span> in this case would increase posterior uncertainty if the data are fully balanced, and could lead to biases in parameter estimation if the data are not fully balanced.</p>
<p>Again, we show how nested contrasts can be easily implemented using  <code>hypr</code>:</p>
<div class="sourceCode" id="cb532"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb532-1"><a href="ch-coding2x2.html#cb532-1" aria-hidden="true"></a>hNest &lt;-<span class="st"> </span><span class="kw">hypr</span>(<span class="dt">B =</span> (F1 <span class="op">+</span><span class="st"> </span>F3) <span class="op">/</span><span class="st"> </span><span class="dv">2</span> <span class="op">~</span><span class="st"> </span>(F2 <span class="op">+</span><span class="st"> </span>F4) <span class="op">/</span><span class="st"> </span><span class="dv">2</span>,</span>
<span id="cb532-2"><a href="ch-coding2x2.html#cb532-2" aria-hidden="true"></a>              <span class="dt">B1xA =</span> F3 <span class="op">~</span><span class="st"> </span>F1,</span>
<span id="cb532-3"><a href="ch-coding2x2.html#cb532-3" aria-hidden="true"></a>              <span class="dt">B2xA =</span> F4 <span class="op">~</span><span class="st"> </span>F2)</span>
<span id="cb532-4"><a href="ch-coding2x2.html#cb532-4" aria-hidden="true"></a>hNest</span></code></pre></div>
<pre><code>## hypr object containing 3 null hypotheses:
##    H0.B: 0 = (F1 + F3 - F2 - F4)/2
## H0.B1xA: 0 = F3 - F1
## H0.B2xA: 0 = F4 - F2
## 
## Call:
## hypr(B = ~1/2 * F1 + 1/2 * F3 - 1/2 * F2 - 1/2 * F4, B1xA = ~F3 - 
##     F1, B2xA = ~F4 - F2, levels = c(&quot;F1&quot;, &quot;F2&quot;, &quot;F3&quot;, &quot;F4&quot;))
## 
## Hypothesis matrix (transposed):
##    B    B1xA B2xA
## F1  1/2   -1    0
## F2 -1/2    0   -1
## F3  1/2    1    0
## F4 -1/2    0    1
## 
## Contrast matrix:
##    B    B1xA B2xA
## F1  1/2 -1/2    0
## F2 -1/2    0 -1/2
## F3  1/2  1/2    0
## F4 -1/2    0  1/2</code></pre>
<div class="sourceCode" id="cb534"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb534-1"><a href="ch-coding2x2.html#cb534-1" aria-hidden="true"></a><span class="kw">contrasts</span>(df_contrasts3<span class="op">$</span>F) &lt;-<span class="st"> </span><span class="kw">contr.hypothesis</span>(hNest)</span></code></pre></div>
<div class="sourceCode" id="cb535"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb535-1"><a href="ch-coding2x2.html#cb535-1" aria-hidden="true"></a>fit_NestHypr &lt;-</span>
<span id="cb535-2"><a href="ch-coding2x2.html#cb535-2" aria-hidden="true"></a><span class="st">  </span><span class="kw">brm</span>(DV <span class="op">~</span><span class="st"> </span>F,</span>
<span id="cb535-3"><a href="ch-coding2x2.html#cb535-3" aria-hidden="true"></a>      <span class="dt">data =</span> df_contrasts3,</span>
<span id="cb535-4"><a href="ch-coding2x2.html#cb535-4" aria-hidden="true"></a>      <span class="dt">family =</span> <span class="kw">gaussian</span>(),</span>
<span id="cb535-5"><a href="ch-coding2x2.html#cb535-5" aria-hidden="true"></a>      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">20</span>, <span class="dv">50</span>), <span class="dt">class =</span> Intercept),</span>
<span id="cb535-6"><a href="ch-coding2x2.html#cb535-6" aria-hidden="true"></a>                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">50</span>), <span class="dt">class =</span> sigma),</span>
<span id="cb535-7"><a href="ch-coding2x2.html#cb535-7" aria-hidden="true"></a>                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">50</span>), <span class="dt">class =</span> b)))</span></code></pre></div>
<div class="sourceCode" id="cb536"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb536-1"><a href="ch-coding2x2.html#cb536-1" aria-hidden="true"></a><span class="kw">fixef</span>(fit_NestHypr)</span></code></pre></div>
<pre><code>##           Estimate Est.Error   Q2.5 Q97.5
## Intercept    19.98      2.47  15.01  24.9
## FB          -19.86      4.83 -29.30 -10.1
## FB1xA         0.01      6.58 -12.71  13.4
## FB2xA        19.56      6.79   5.93  32.9</code></pre>
<p>Of course, we can also ask the reverse question: Are there differences for part of speech (<span class="math inline">\(B\)</span>) in the levels of word frequency (<span class="math inline">\(A\)</span>; in addition to estimating the main effect of word frequency, <span class="math inline">\(A\)</span>)? That is, do nouns differ from verbs for low-frequency words (<span class="math inline">\(B_{A1}\)</span>) and do nouns differ from verbs for high-frequency words (<span class="math inline">\(B_{A2}\)</span>)?</p>
<div class="sourceCode" id="cb538"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb538-1"><a href="ch-coding2x2.html#cb538-1" aria-hidden="true"></a>hNest2 &lt;-<span class="st"> </span><span class="kw">hypr</span>(<span class="dt">A =</span> (F1 <span class="op">+</span><span class="st"> </span>F2) <span class="op">/</span><span class="st"> </span><span class="dv">2</span> <span class="op">~</span><span class="st"> </span>(F3 <span class="op">+</span><span class="st"> </span>F4) <span class="op">/</span><span class="st"> </span><span class="dv">2</span>,</span>
<span id="cb538-2"><a href="ch-coding2x2.html#cb538-2" aria-hidden="true"></a>               <span class="dt">A1xB =</span> F2 <span class="op">~</span><span class="st"> </span>F1,</span>
<span id="cb538-3"><a href="ch-coding2x2.html#cb538-3" aria-hidden="true"></a>               <span class="dt">A2xB =</span> F4 <span class="op">~</span><span class="st"> </span>F3)</span>
<span id="cb538-4"><a href="ch-coding2x2.html#cb538-4" aria-hidden="true"></a>hNest2</span></code></pre></div>
<pre><code>## hypr object containing 3 null hypotheses:
##    H0.A: 0 = (F1 + F2 - F3 - F4)/2
## H0.A1xB: 0 = F2 - F1
## H0.A2xB: 0 = F4 - F3
## 
## Call:
## hypr(A = ~1/2 * F1 + 1/2 * F2 - 1/2 * F3 - 1/2 * F4, A1xB = ~F2 - 
##     F1, A2xB = ~F4 - F3, levels = c(&quot;F1&quot;, &quot;F2&quot;, &quot;F3&quot;, &quot;F4&quot;))
## 
## Hypothesis matrix (transposed):
##    A    A1xB A2xB
## F1  1/2   -1    0
## F2  1/2    1    0
## F3 -1/2    0   -1
## F4 -1/2    0    1
## 
## Contrast matrix:
##    A    A1xB A2xB
## F1  1/2 -1/2    0
## F2  1/2  1/2    0
## F3 -1/2    0 -1/2
## F4 -1/2    0  1/2</code></pre>
<div class="sourceCode" id="cb540"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb540-1"><a href="ch-coding2x2.html#cb540-1" aria-hidden="true"></a><span class="kw">contrasts</span>(df_contrasts3<span class="op">$</span>F) &lt;-<span class="st"> </span><span class="kw">contr.hypothesis</span>(hNest2)</span></code></pre></div>
<div class="sourceCode" id="cb541"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb541-1"><a href="ch-coding2x2.html#cb541-1" aria-hidden="true"></a>fit_Nest2Hypr &lt;-</span>
<span id="cb541-2"><a href="ch-coding2x2.html#cb541-2" aria-hidden="true"></a><span class="st">  </span><span class="kw">brm</span>(DV <span class="op">~</span><span class="st"> </span>F,</span>
<span id="cb541-3"><a href="ch-coding2x2.html#cb541-3" aria-hidden="true"></a>      <span class="dt">data =</span> df_contrasts3,</span>
<span id="cb541-4"><a href="ch-coding2x2.html#cb541-4" aria-hidden="true"></a>      <span class="dt">family =</span> <span class="kw">gaussian</span>(),</span>
<span id="cb541-5"><a href="ch-coding2x2.html#cb541-5" aria-hidden="true"></a>      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">20</span>, <span class="dv">50</span>), <span class="dt">class =</span> Intercept),</span>
<span id="cb541-6"><a href="ch-coding2x2.html#cb541-6" aria-hidden="true"></a>                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">50</span>), <span class="dt">class =</span> sigma),</span>
<span id="cb541-7"><a href="ch-coding2x2.html#cb541-7" aria-hidden="true"></a>                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">50</span>), <span class="dt">class =</span> b)))</span></code></pre></div>
<div class="sourceCode" id="cb542"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb542-1"><a href="ch-coding2x2.html#cb542-1" aria-hidden="true"></a><span class="kw">fixef</span>(fit_Nest2Hypr)</span></code></pre></div>
<pre><code>##           Estimate Est.Error   Q2.5 Q97.5
## Intercept    20.04      2.50  15.05 25.09
## FA           -9.98      5.00 -19.92 -0.04
## FA1xB         9.80      6.89  -4.12 23.42
## FA2xB        29.55      6.97  15.58 43.38</code></pre>
<p>Regression coefficients estimate the  grand mean, the difference for the  main effect of word frequency (<span class="math inline">\(A\)</span>) and the two part of speech effects (for <span class="math inline">\(B\)</span>; i.e.,  simple main effects) within levels of word frequency (<span class="math inline">\(A\)</span>).</p>
</div>
<div id="interactions-between-contrasts" class="section level3 hasAnchor" number="9.1.2">
<h3><span class="header-section-number">9.1.2</span>  Interactions between contrasts<a href="ch-coding2x2.html#interactions-between-contrasts" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In a <span class="math inline">\(2 \times 2\)</span> experimental design, the results from sum contrasts are equivalent to typical ANOVA results that we see in frequentist analyses. This means that sum contrasts assess the main effects and the interactions. One interesting question that arises here is: what would happen in a  <span class="math inline">\(2 \times 2\)</span> design if we had used  treatment contrasts instead of sum contrasts? Is it still possible to meaningfully interpret the results from the treatment contrasts in a simple <span class="math inline">\(2 \times 2\)</span> design?</p>
<p>This leads us to a very important principle in interpreting results from contrasts: When interactions between contrasts are included in a model, then the results for one contrast actually depend on the specification of the other contrast(s) in the analysis! This may be counter-intuitive at first, but it is very important and essential to keep in mind when interpreting results from contrasts. How does this work in detail?</p>
<p>The general rule to remember is that the effect of one contrast measures its effect at the location <span class="math inline">\(0\)</span> of the other contrast(s) in the analysis. This can be seen in the regression equation of a <span class="math inline">\(2 \times 2\)</span> design with factors <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>:</p>
<p><span class="math display">\[\begin{equation}
E[Y] = \alpha + \beta_A A + \beta_B B + \beta_{A \times B} A \times B
\end{equation}\]</span></p>
<p>If we set the predictor <span class="math inline">\(B\)</span> to zero, then the equation simplifies to:</p>
<p><span class="math display">\[\begin{equation}
E[Y] = \alpha + \beta_A A
\end{equation}\]</span></p>
<p>Thus, now we can see the “pure” effect of <span class="math inline">\(A\)</span>.</p>
<p>What does that mean practically? Let us consider the example that we use two treatment contrasts in a <span class="math inline">\(2 \times 2\)</span> design. Here are the results from the linear model</p>
<div class="sourceCode" id="cb544"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb544-1"><a href="ch-coding2x2.html#cb544-1" aria-hidden="true"></a><span class="kw">contrasts</span>(df_contrasts4<span class="op">$</span>A) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb544-2"><a href="ch-coding2x2.html#cb544-2" aria-hidden="true"></a><span class="kw">contrasts</span>(df_contrasts4<span class="op">$</span>B) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb544-3"><a href="ch-coding2x2.html#cb544-3" aria-hidden="true"></a>fit_treatm &lt;-<span class="st"> </span><span class="kw">brm</span>(DV <span class="op">~</span><span class="st"> </span>B <span class="op">*</span><span class="st"> </span>A,</span>
<span id="cb544-4"><a href="ch-coding2x2.html#cb544-4" aria-hidden="true"></a>                  <span class="dt">data =</span> df_contrasts4,</span>
<span id="cb544-5"><a href="ch-coding2x2.html#cb544-5" aria-hidden="true"></a>                  <span class="dt">family =</span> <span class="kw">gaussian</span>(),</span>
<span id="cb544-6"><a href="ch-coding2x2.html#cb544-6" aria-hidden="true"></a>                  <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">20</span>, <span class="dv">50</span>), <span class="dt">class =</span> Intercept),</span>
<span id="cb544-7"><a href="ch-coding2x2.html#cb544-7" aria-hidden="true"></a>                            <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">50</span>), <span class="dt">class =</span> sigma),</span>
<span id="cb544-8"><a href="ch-coding2x2.html#cb544-8" aria-hidden="true"></a>                            <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">50</span>), <span class="dt">class =</span> b)))</span></code></pre></div>
<div class="sourceCode" id="cb545"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb545-1"><a href="ch-coding2x2.html#cb545-1" aria-hidden="true"></a><span class="kw">fixef</span>(fit_treatm)</span></code></pre></div>
<pre><code>##           Estimate Est.Error   Q2.5 Q97.5
## Intercept     9.95      4.84   0.13  19.4
## B1           10.08      6.93  -3.09  24.1
## A1            0.15      6.91 -13.52  14.0
## B1:A1        19.60      9.79  -0.09  38.8</code></pre>
<p>Let’s take a look at the effect of factor <span class="math inline">\(A\)</span>. How can we interpret what this measures? This effect actually estimates the effect of factor <span class="math inline">\(A\)</span> at the “location” where factor <span class="math inline">\(B\)</span> is coded as <span class="math inline">\(0\)</span>. Factor <span class="math inline">\(B\)</span> is coded as a treatment contrast, that is, it codes a zero at its baseline condition, which is <span class="math inline">\(B1\)</span>. Thus, the effect of factor <span class="math inline">\(A\)</span> estimates the effect of <span class="math inline">\(A\)</span> nested within the baseline condition of <span class="math inline">\(B\)</span>, i.e., a  simple effect. We take a look at the data presented in Figure <a href="ch-coding2x2.html#fig:twobytwosimdatFig">9.1</a>, what this  nested effect should be. Figure <a href="ch-coding2x2.html#fig:twobytwosimdatFig">9.1</a> shows that the effect of factor <span class="math inline">\(A\)</span> nested in <span class="math inline">\(B1\)</span> is <span class="math inline">\(0\)</span>. If we now compare this to the results from the linear model, it is indeed clear that the effect of factor <span class="math inline">\(A\)</span> is exactly estimated as <span class="math inline">\(0\)</span>. As expected, when factor <span class="math inline">\(B\)</span> is coded as a treatment contrast, the effect of factor <span class="math inline">\(A\)</span> estimates the effect of <span class="math inline">\(A\)</span> nested within the baseline level of factor <span class="math inline">\(B\)</span>.</p>
<p>Next, consider the effect of factor <span class="math inline">\(B\)</span>. According to the same logic, this effect estimates the effect of factor <span class="math inline">\(B\)</span> at the “location” where factor <span class="math inline">\(A\)</span> is <span class="math inline">\(0\)</span>. Factor <span class="math inline">\(A\)</span> is also coded as a treatment contrast, that is, it codes its baseline condition <span class="math inline">\(A1\)</span> as <span class="math inline">\(0\)</span>. The effect of factor <span class="math inline">\(B\)</span> estimates the effect of <span class="math inline">\(B\)</span> nested within the baseline condition of <span class="math inline">\(A\)</span>. Figure <a href="ch-coding2x2.html#fig:twobytwosimdatFig">9.1</a> shows that this effect should be <span class="math inline">\(10\)</span>.</p>
<p>How do we know what the “location” is, where a contrast applies? For the treatment contrasts discussed here, it is possible to reason this through because all contrasts are coded as <span class="math inline">\(0\)</span> or <span class="math inline">\(1\)</span>. How can one derive the “location” in general? What we can do is to look at the comparisons that are estimated when using the treatment contrasts (or in case we use Bayes factors, which  hypotheses are tested) in the presence of an interaction between them by using the  generalized matrix inverse. We go back to the default treatment contrasts. Then we extract the contrast matrix from the design matrix:</p>
<div class="sourceCode" id="cb547"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb547-1"><a href="ch-coding2x2.html#cb547-1" aria-hidden="true"></a><span class="kw">contrasts</span>(df_contrasts4<span class="op">$</span>A) &lt;-<span class="st"> </span><span class="kw">contr.treatment</span>(<span class="dv">2</span>)</span>
<span id="cb547-2"><a href="ch-coding2x2.html#cb547-2" aria-hidden="true"></a><span class="kw">contrasts</span>(df_contrasts4<span class="op">$</span>B) &lt;-<span class="st"> </span><span class="kw">contr.treatment</span>(<span class="dv">2</span>)</span>
<span id="cb547-3"><a href="ch-coding2x2.html#cb547-3" aria-hidden="true"></a>XcTr &lt;-<span class="st"> </span>df_contrasts4 <span class="op">%&gt;%</span></span>
<span id="cb547-4"><a href="ch-coding2x2.html#cb547-4" aria-hidden="true"></a><span class="st">  </span><span class="kw">group_by</span>(A, B) <span class="op">%&gt;%</span></span>
<span id="cb547-5"><a href="ch-coding2x2.html#cb547-5" aria-hidden="true"></a><span class="st">  </span><span class="kw">summarise</span>() <span class="op">%&gt;%</span></span>
<span id="cb547-6"><a href="ch-coding2x2.html#cb547-6" aria-hidden="true"></a><span class="st">  </span><span class="kw">model.matrix</span>(<span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>A <span class="op">*</span><span class="st"> </span>B, .) <span class="op">%&gt;%</span></span>
<span id="cb547-7"><a href="ch-coding2x2.html#cb547-7" aria-hidden="true"></a><span class="st">  </span><span class="kw">as.data.frame</span>() <span class="op">%&gt;%</span></span>
<span id="cb547-8"><a href="ch-coding2x2.html#cb547-8" aria-hidden="true"></a><span class="st">  </span><span class="kw">as.matrix</span>()</span>
<span id="cb547-9"><a href="ch-coding2x2.html#cb547-9" aria-hidden="true"></a><span class="kw">rownames</span>(XcTr) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;A1_B1&quot;</span>, <span class="st">&quot;A1_B2&quot;</span>, <span class="st">&quot;A2_B1&quot;</span>, <span class="st">&quot;A2_B2&quot;</span>)</span>
<span id="cb547-10"><a href="ch-coding2x2.html#cb547-10" aria-hidden="true"></a>XcTr</span></code></pre></div>
<pre><code>##       (Intercept) A2 B2 A2:B2
## A1_B1           1  0  0     0
## A1_B2           1  0  1     0
## A2_B1           1  1  0     0
## A2_B2           1  1  1     1</code></pre>
<p>This shows the treatment contrast for factors <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>, and their interaction. We can now assign this  contrast matrix to a  <code>hypr</code> object. <code>hypr</code> automatically converts the contrast matrix into a  hypothesis matrix, such that we can read from the hypothesis matrix which comparison are being estimated by the different contrasts.</p>
<div class="sourceCode" id="cb549"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb549-1"><a href="ch-coding2x2.html#cb549-1" aria-hidden="true"></a>htr &lt;-<span class="st"> </span><span class="kw">hypr</span>() <span class="co"># initialize empty hypr object</span></span>
<span id="cb549-2"><a href="ch-coding2x2.html#cb549-2" aria-hidden="true"></a><span class="kw">cmat</span>(htr) &lt;-<span class="st"> </span>XcTr <span class="co"># assign contrast matrix to hypr object</span></span>
<span id="cb549-3"><a href="ch-coding2x2.html#cb549-3" aria-hidden="true"></a>htr <span class="co"># look at the resulting hypothesis matrix</span></span></code></pre></div>
<pre><code>## hypr object containing 4 null hypotheses:
## H0.(Intercept): 0 = A1_B1                          (Intercept)
##          H0.A2: 0 = -A1_B1 + A2_B1
##          H0.B2: 0 = -A1_B1 + A1_B2
##       H0.A2:B2: 0 = A1_B1 - A1_B2 - A2_B1 + A2_B2
## 
## Call:
## hypr(`(Intercept)` = ~A1_B1, A2 = ~-A1_B1 + A2_B1, B2 = ~-A1_B1 + 
##     A1_B2, `A2:B2` = ~A1_B1 - A1_B2 - A2_B1 + A2_B2, levels = c(&quot;A1_B1&quot;, 
## &quot;A1_B2&quot;, &quot;A2_B1&quot;, &quot;A2_B2&quot;))
## 
## Hypothesis matrix (transposed):
##       (Intercept) A2 B2 A2:B2
## A1_B1  1          -1 -1  1   
## A1_B2  0           0  1 -1   
## A2_B1  0           1  0 -1   
## A2_B2  0           0  0  1   
## 
## Contrast matrix:
##       (Intercept) A2 B2 A2:B2
## A1_B1 1           0  0  0    
## A1_B2 1           0  1  0    
## A2_B1 1           1  0  0    
## A2_B2 1           1  1  1</code></pre>
<p>The same result is obtained by applying the generalized inverse to the contrast matrix (this is what <code>hypr()</code> does as well). An important fact is that when we apply the generalized inverse to the contrast matrix, we obtain the corresponding hypothesis matrix <span class="citation">(for details, see Schad et al. <a href="#ref-schadHowCapitalizePriori2020" role="doc-biblioref">2020</a>)</span>.</p>
<div class="sourceCode" id="cb551"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb551-1"><a href="ch-coding2x2.html#cb551-1" aria-hidden="true"></a><span class="kw">t</span>(<span class="kw">ginv2</span>(XcTr))</span></code></pre></div>
<pre><code>##       (Intercept) A2 B2 A2:B2
## A1_B1  1          -1 -1  1   
## A1_B2  0           0  1 -1   
## A2_B1  0           1  0 -1   
## A2_B2  0           0  0  1</code></pre>
<p>As discussed above, the effect of factor <span class="math inline">\(A\)</span> estimates its effect nested within the baseline level of factor <span class="math inline">\(B\)</span>. Likewise, the effect of factor <span class="math inline">\(B\)</span> estimates its effect nested within the baseline level of factor <span class="math inline">\(A\)</span>. The term <span class="math inline">\(A:B\)</span> always tests the interaction between both factors, irrespective of the centering of <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>.</p>
<p>How does this work for  sum contrasts? They do not have a baseline condition that is coded as <span class="math inline">\(0\)</span>. In sum contrasts, the average of the contrast coefficients is <span class="math inline">\(0\)</span>. Therefore, effects estimate the average effect across factor levels, i.e., they estimate a  main effect. This is what is typically also tested in standard  ANOVA. Let’s look at the example shown in Table <a href="ch-coding2x2.html#tab:table18b">9.2</a>: given that factor <span class="math inline">\(B\)</span> has a sum contrast, the main effect of factor <span class="math inline">\(A\)</span> is estimated as the average across levels of factor <span class="math inline">\(B\)</span>. Figure <a href="ch-coding2x2.html#fig:twobytwosimdatFig">9.1</a> shows that the effect of factor <span class="math inline">\(A\)</span> in level B1 is <span class="math inline">\(10 - 10 = 0\)</span>, and in level <span class="math inline">\(B2\)</span> it is <span class="math inline">\(20 - 40 = -20\)</span>. The average effect across both levels is <span class="math inline">\((0 - 20)/2 = -10\)</span>. Due to the sum contrast coding, we have to divide this by two, yielding an expected effect of <span class="math inline">\(-10 / 2 = -5\)</span>. This is exactly what the effect of factor <span class="math inline">\(A\)</span> measures (see Table <a href="ch-coding2x2.html#tab:table18b">9.2</a>, <em>Estimate</em> for <span class="math inline">\(A1\)</span>).</p>
<p>Similarly, factor <span class="math inline">\(B\)</span> estimates its effect at the location <span class="math inline">\(0\)</span> of factor <span class="math inline">\(A\)</span>. Again, <span class="math inline">\(0\)</span> is exactly the mean of the contrast coefficients from factor <span class="math inline">\(A\)</span>, which is coded as a sum contrast. Therefore, factor <span class="math inline">\(B\)</span> estimates the effect of <span class="math inline">\(B\)</span> averaged across factor levels of <span class="math inline">\(A\)</span>, i.e., the main effect of <span class="math inline">\(B\)</span>. For factor level <span class="math inline">\(A1\)</span>, factor <span class="math inline">\(B\)</span> has an effect of <span class="math inline">\(10 - 20 = -10\)</span>. For factor level <span class="math inline">\(A2\)</span>, factor <span class="math inline">\(B\)</span> has an effect of <span class="math inline">\(10 - 40 = -30\)</span>. The average effect is <span class="math inline">\((-10 - 30)/2 = -20\)</span>, which again needs to be divided by <span class="math inline">\(2\)</span> due to the sum contrast. This yields exactly the estimate of <span class="math inline">\(-10\)</span> that is also reported in Table <a href="ch-coding2x2.html#tab:table18b">9.2</a> (<em>Estimate</em> for B1).</p>
<p>Again, we look at the hypothesis matrix for the main effects and the interaction:</p>
<div class="sourceCode" id="cb553"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb553-1"><a href="ch-coding2x2.html#cb553-1" aria-hidden="true"></a><span class="kw">contrasts</span>(df_contrasts4<span class="op">$</span>A) &lt;-<span class="st"> </span><span class="kw">contr.sum</span>(<span class="dv">2</span>)</span>
<span id="cb553-2"><a href="ch-coding2x2.html#cb553-2" aria-hidden="true"></a><span class="kw">contrasts</span>(df_contrasts4<span class="op">$</span>B) &lt;-<span class="st"> </span><span class="kw">contr.sum</span>(<span class="dv">2</span>)</span>
<span id="cb553-3"><a href="ch-coding2x2.html#cb553-3" aria-hidden="true"></a>XcSum &lt;-<span class="st"> </span>df_contrasts4 <span class="op">%&gt;%</span></span>
<span id="cb553-4"><a href="ch-coding2x2.html#cb553-4" aria-hidden="true"></a><span class="st">  </span><span class="kw">group_by</span>(A, B) <span class="op">%&gt;%</span></span>
<span id="cb553-5"><a href="ch-coding2x2.html#cb553-5" aria-hidden="true"></a><span class="st">  </span><span class="kw">summarise</span>() <span class="op">%&gt;%</span></span>
<span id="cb553-6"><a href="ch-coding2x2.html#cb553-6" aria-hidden="true"></a><span class="st">  </span><span class="kw">model.matrix</span>(<span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>A <span class="op">*</span><span class="st"> </span>B, .) <span class="op">%&gt;%</span></span>
<span id="cb553-7"><a href="ch-coding2x2.html#cb553-7" aria-hidden="true"></a><span class="st">  </span><span class="kw">as.data.frame</span>() <span class="op">%&gt;%</span></span>
<span id="cb553-8"><a href="ch-coding2x2.html#cb553-8" aria-hidden="true"></a><span class="st">  </span><span class="kw">as.matrix</span>()</span>
<span id="cb553-9"><a href="ch-coding2x2.html#cb553-9" aria-hidden="true"></a><span class="kw">rownames</span>(XcSum) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;A1_B1&quot;</span>, <span class="st">&quot;A1_B2&quot;</span>, <span class="st">&quot;A2_B1&quot;</span>, <span class="st">&quot;A2_B2&quot;</span>)</span>
<span id="cb553-10"><a href="ch-coding2x2.html#cb553-10" aria-hidden="true"></a></span>
<span id="cb553-11"><a href="ch-coding2x2.html#cb553-11" aria-hidden="true"></a>hsum &lt;-<span class="st"> </span><span class="kw">hypr</span>() <span class="co"># initialize empty hypr object</span></span>
<span id="cb553-12"><a href="ch-coding2x2.html#cb553-12" aria-hidden="true"></a><span class="kw">cmat</span>(hsum) &lt;-<span class="st"> </span>XcSum <span class="co"># assign contrast matrix to hypr object</span></span>
<span id="cb553-13"><a href="ch-coding2x2.html#cb553-13" aria-hidden="true"></a>hsum <span class="co"># look at the resulting hypothesis matrix</span></span></code></pre></div>
<pre><code>## hypr object containing 4 null hypotheses:
## H0.(Intercept): 0 = (A1_B1 + A1_B2 + A2_B1 + A2_B2)/4  (Intercept)
##          H0.A1: 0 = (A1_B1 + A1_B2 - A2_B1 - A2_B2)/4
##          H0.B1: 0 = (A1_B1 - A1_B2 + A2_B1 - A2_B2)/4
##       H0.A1:B1: 0 = (A1_B1 - A1_B2 - A2_B1 + A2_B2)/4
## 
## Call:
## hypr(`(Intercept)` = ~1/4 * A1_B1 + 1/4 * A1_B2 + 1/4 * A2_B1 + 
##     1/4 * A2_B2, A1 = ~1/4 * A1_B1 + 1/4 * A1_B2 - 1/4 * A2_B1 - 
##     1/4 * A2_B2, B1 = ~1/4 * A1_B1 - 1/4 * A1_B2 + 1/4 * A2_B1 - 
##     1/4 * A2_B2, `A1:B1` = ~1/4 * A1_B1 - 1/4 * A1_B2 - 1/4 * 
##     A2_B1 + 1/4 * A2_B2, levels = c(&quot;A1_B1&quot;, &quot;A1_B2&quot;, &quot;A2_B1&quot;, 
## &quot;A2_B2&quot;))
## 
## Hypothesis matrix (transposed):
##       (Intercept) A1   B1   A1:B1
## A1_B1  1/4         1/4  1/4  1/4 
## A1_B2  1/4         1/4 -1/4 -1/4 
## A2_B1  1/4        -1/4  1/4 -1/4 
## A2_B2  1/4        -1/4 -1/4  1/4 
## 
## Contrast matrix:
##       (Intercept) A1 B1 A1:B1
## A1_B1  1           1  1  1   
## A1_B2  1           1 -1 -1   
## A2_B1  1          -1  1 -1   
## A2_B2  1          -1 -1  1</code></pre>
<p>This shows that each of the effects now does not compute nested comparisons any more, but that they rather estimate their effect averaged across conditions of the other factor. The averaging involves using weights of <span class="math inline">\(1/2\)</span> in the hypothesis matrix. Moreover, the regression coefficients in the sum contrast measure half the distance between conditions, leading to weights of <span class="math inline">\(1/2 \cdot 1/2 = 1/4\)</span> in the hypothesis matrix.</p>
<p>The general rule to remember from these examples is that when  interactions between contrasts are estimated, what an effect of a factor estimates depends on the contrast coding of the other factors in the design! The effect of a factor estimates the effect nested within the location zero of the other contrast(s) in an analysis. If another contrast is centered, and zero is the average of this other contrasts’ coefficients, then the contrast of interest estimates the average or  main effect, averaged across the levels of the other factor. Importantly, this property, that the coding of the other factor determines the estimates of one factor, holds only when the interaction between two contrasts is included into a model. If the interaction is omitted and only effects are estimated, then there is no such influence.</p>
<p>This may be a very surprising result for interactions of contrasts. However, it is also essential to interpreting contrast coefficients involved in interactions. It is particularly relevant for the analysis of the default treatment contrast, where the main effects estimate  nested effects rather than average effects.</p>
</div>
</div>
<div id="sec-contrast-covariate" class="section level2 hasAnchor" number="9.2">
<h2><span class="header-section-number">9.2</span> One factor and one  covariate<a href="ch-coding2x2.html#sec-contrast-covariate" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="estimating-a-group-difference-and-controlling-for-a-covariate" class="section level3 hasAnchor" number="9.2.1">
<h3><span class="header-section-number">9.2.1</span> Estimating a  group difference and controlling for a covariate<a href="ch-coding2x2.html#estimating-a-group-difference-and-controlling-for-a-covariate" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In this section we treat the case where there are again two predictor variables for one dependent variable, but where one predictor variable is a discrete factor, and the other is a continuous covariate. Let’s assume we have measured some response time (RT), e.g., in a lexical decision task. We want to predict the response time based on each subject’s IQ, and we expect that higher IQ leads to shorter response times. Moreover, we have two groups of each 30 subjects. These are coded as factor <span class="math inline">\(F\)</span>, with factor levels <span class="math inline">\(F1\)</span> and <span class="math inline">\(F2\)</span>. We assume that these two groups have obtained different training programs to optimize their response times on the task. Group <span class="math inline">\(F1\)</span> obtained a control training, whereas group <span class="math inline">\(F2\)</span> obtained training to improve lexical decisions. We want to estimate in how far the training for better lexical decisions in group <span class="math inline">\(F2\)</span> leads to shorter response times compared to the control group <span class="math inline">\(F1\)</span>. This is our main question of interest here, i.e., in how far the training program in F2 leads to faster response times compared to the control group <span class="math inline">\(F1\)</span>. We load the data, which is a simulated data set.</p>
<div class="sourceCode" id="cb555"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb555-1"><a href="ch-coding2x2.html#cb555-1" aria-hidden="true"></a><span class="kw">data</span>(<span class="st">&quot;df_contrasts5&quot;</span>)</span></code></pre></div>
<p>Our main effect of interest is the factor <span class="math inline">\(F\)</span>. We want to estimate its effect on response times and code it using scaled sum contrasts, such that negative parameter estimates would yield support for our hypothesis that response times are faster in the training group <span class="math inline">\(F2\)</span>:</p>
<div class="sourceCode" id="cb556"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb556-1"><a href="ch-coding2x2.html#cb556-1" aria-hidden="true"></a>(<span class="kw">contrasts</span>(df_contrasts5<span class="op">$</span>F) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="op">-</span><span class="fl">0.5</span>, <span class="fl">+0.5</span>))</span></code></pre></div>
<pre><code>## [1] -0.5  0.5</code></pre>
<p>We run a <code>brms</code> model to estimate the effect of factor <span class="math inline">\(F\)</span>, i.e., how strongly the response times in the two groups differ from each other.</p>
<div class="sourceCode" id="cb558"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb558-1"><a href="ch-coding2x2.html#cb558-1" aria-hidden="true"></a>fit_RT_F &lt;-<span class="st"> </span><span class="kw">brm</span>(RT <span class="op">~</span><span class="st"> </span>F,</span>
<span id="cb558-2"><a href="ch-coding2x2.html#cb558-2" aria-hidden="true"></a>                <span class="dt">data =</span> df_contrasts5,</span>
<span id="cb558-3"><a href="ch-coding2x2.html#cb558-3" aria-hidden="true"></a>                <span class="dt">family =</span> <span class="kw">gaussian</span>(),</span>
<span id="cb558-4"><a href="ch-coding2x2.html#cb558-4" aria-hidden="true"></a>                <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">200</span>, <span class="dv">50</span>), <span class="dt">class =</span> Intercept),</span>
<span id="cb558-5"><a href="ch-coding2x2.html#cb558-5" aria-hidden="true"></a>                          <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">50</span>), <span class="dt">class =</span> sigma),</span>
<span id="cb558-6"><a href="ch-coding2x2.html#cb558-6" aria-hidden="true"></a>                          <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">50</span>), <span class="dt">class =</span> b)))</span></code></pre></div>
<div class="sourceCode" id="cb559"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb559-1"><a href="ch-coding2x2.html#cb559-1" aria-hidden="true"></a><span class="kw">fixef</span>(fit_RT_F)</span></code></pre></div>
<pre><code>##           Estimate Est.Error  Q2.5  Q97.5
## Intercept    212.3       5.3 202.1 222.75
## F1           -23.8      10.1 -43.5  -4.21</code></pre>

<div class="figure"><span style="display:block;" id="fig:figRTF"></span>
<img src="bookdown_files/figure-html/figRTF-1.svg" alt="Means and error bars (showing standard errors) for a simulated data set of response times for two different groups of subjects, who have obtained a training in lexical decisions (\(F2\)) versus have obtained a control training (\(F1\))." width="240" />
<p class="caption">
FIGURE 9.2: Means and error bars (showing standard errors) for a simulated data set of response times for two different groups of subjects, who have obtained a training in lexical decisions (<span class="math inline">\(F2\)</span>) versus have obtained a control training (<span class="math inline">\(F1\)</span>).
</p>
</div>
<p>We find (see model estimates and data shown in Figure <a href="ch-coding2x2.html#fig:figRTF">9.2</a>) that response times in group <span class="math inline">\(F2\)</span> are roughly <span class="math inline">\(25\)</span> ms faster than in group <span class="math inline">\(F1\)</span> (Estimate of <span class="math inline">\(-24\)</span>). This suggests that as expected, the training program that group <span class="math inline">\(F2\)</span> obtained seems to be successful in speeding up response times. Recall that one cannot just look at the 95% credible interval and check whether zero is outside the interval to declare that we have found an effect. To make a discovery claim, we need to run a Bayes factor analysis on this data set to directly test this hypothesis, and this may or may not provide evidence for a difference in response times between groups.</p>
<p>Let’s assume we have allocated subjects to the two groups randomly. Let’s say that we also measured the IQ of each person using an IQ test. We did so because we expected that IQ could have a strong influence on response times, and we wanted to control for this influence. We now can check whether the two groups had the same average IQ.</p>
<div class="sourceCode" id="cb561"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb561-1"><a href="ch-coding2x2.html#cb561-1" aria-hidden="true"></a>df_contrasts5 <span class="op">%&gt;%</span></span>
<span id="cb561-2"><a href="ch-coding2x2.html#cb561-2" aria-hidden="true"></a><span class="st">  </span><span class="kw">group_by</span>(F) <span class="op">%&gt;%</span></span>
<span id="cb561-3"><a href="ch-coding2x2.html#cb561-3" aria-hidden="true"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">M.IQ =</span> <span class="kw">mean</span>(IQ))</span></code></pre></div>
<pre><code>## # A tibble: 2 × 2
##   F      M.IQ
##   &lt;fct&gt; &lt;dbl&gt;
## 1 F1       85
## 2 F2      115</code></pre>
<p>Group <span class="math inline">\(F2\)</span> not only obtained additional training and had faster response times, group <span class="math inline">\(F2\)</span> also had a higher IQ (mean of 115) on average than group <span class="math inline">\(F1\)</span> (mean IQ = 85). Thus, the random allocation of subjects to the two groups seems to have created–by chance–a difference in IQs. Now we can ask the question: why might response times in group <span class="math inline">\(F2\)</span> be faster than in group <span class="math inline">\(F1\)</span>? Is this because of the training program in <span class="math inline">\(F2\)</span>? Or is this simply because the average IQ in group <span class="math inline">\(F2\)</span> was higher than in group <span class="math inline">\(F1\)</span>? To investigate this question, we add both predictor variables simultaneously in a <code>brms</code> model. Before we enter the continuous IQ variable, we center it, by subtracting its mean. Centering covariates is generally good practice. Moreover, it is often important to  <span class="math inline">\(z\)</span>-transform the covariate, i.e., to not only subtract the mean, but also to divide by its standard deviation (this can be done as follows: <code>df_contrasts5$IQ.s &lt;- scale(df_contrasts5$IQ)</code>). The reason why this is often important is that the sampler doesn’t work well if predictors have different scales. For the simple models we use here, the sampler works without <span class="math inline">\(z\)</span>-transformation. However, for more realistic and more complex models, <span class="math inline">\(z\)</span>-transformation of covariates is often very important. Importantly, when changing the scale of the predictor, then the scale of the prior has to be changed accordingly. Here, we set the same priors for the contrast and for the covariate IQ for convenience. In realistic models, these priors have to be set separately.</p>
<div class="sourceCode" id="cb563"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb563-1"><a href="ch-coding2x2.html#cb563-1" aria-hidden="true"></a>df_contrasts5 &lt;-<span class="st"> </span>df_contrasts5 <span class="op">%&gt;%</span></span>
<span id="cb563-2"><a href="ch-coding2x2.html#cb563-2" aria-hidden="true"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">c_IQ =</span> IQ <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(IQ))</span>
<span id="cb563-3"><a href="ch-coding2x2.html#cb563-3" aria-hidden="true"></a>fit_RT_F_IQ &lt;-<span class="st"> </span><span class="kw">brm</span>(RT <span class="op">~</span><span class="st"> </span>F <span class="op">+</span><span class="st"> </span>c_IQ,</span>
<span id="cb563-4"><a href="ch-coding2x2.html#cb563-4" aria-hidden="true"></a>                   <span class="dt">data =</span> df_contrasts5,</span>
<span id="cb563-5"><a href="ch-coding2x2.html#cb563-5" aria-hidden="true"></a>                   <span class="dt">family =</span> <span class="kw">gaussian</span>(),</span>
<span id="cb563-6"><a href="ch-coding2x2.html#cb563-6" aria-hidden="true"></a>                   <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">200</span>, <span class="dv">50</span>), <span class="dt">class =</span> Intercept),</span>
<span id="cb563-7"><a href="ch-coding2x2.html#cb563-7" aria-hidden="true"></a>                             <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">50</span>), <span class="dt">class =</span> sigma),</span>
<span id="cb563-8"><a href="ch-coding2x2.html#cb563-8" aria-hidden="true"></a>                             <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">50</span>), <span class="dt">class =</span> b)))</span></code></pre></div>
<div class="sourceCode" id="cb564"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb564-1"><a href="ch-coding2x2.html#cb564-1" aria-hidden="true"></a><span class="kw">fixef</span>(fit_RT_F_IQ)</span></code></pre></div>
<pre><code>##           Estimate Est.Error  Q2.5  Q97.5
## Intercept   212.42      4.79 202.9 221.95
## F1            6.43     13.84 -20.5  33.93
## c_IQ         -1.06      0.33  -1.7  -0.42</code></pre>
<p>The results from the <code>brms</code> model now show that the difference in response times between groups (i.e., factor <span class="math inline">\(F\)</span>) is not estimated to be <span class="math inline">\(-25\)</span> ms any more, but instead, the estimate is about <span class="math inline">\(+7\)</span> ms, and the 95% credible interval spans the range <span class="math inline">\(-20\)</span> to <span class="math inline">\(33\)</span>. Thus, there doesn’t seem to be much reason to believe any more that the groups would differ. At the same time, we see that the predictor variable IQ shows a negative effect (Estimate = <span class="math inline">\(-1\)</span> with 95% credible interval: <span class="math inline">\(-1.7\)</span> to <span class="math inline">\(-0.4\)</span>), suggesting that–as expected–response times seem to be faster in subjects with higher IQ.</p>

<div class="figure"><span style="display:block;" id="fig:figRTFIQ"></span>
<img src="bookdown_files/figure-html/figRTFIQ-1.svg" alt="Response times as a function of individual IQ for two groups with a lexical decision training (\(F2\)) versus a control training (\(F1\)). Points indicate individual subjects, and lines with error bands indicate linear regression lines." width="432" />
<p class="caption">
FIGURE 9.3: Response times as a function of individual IQ for two groups with a lexical decision training (<span class="math inline">\(F2\)</span>) versus a control training (<span class="math inline">\(F1\)</span>). Points indicate individual subjects, and lines with error bands indicate linear regression lines.
</p>
</div>
<p>This result can also be seen in Figure <a href="ch-coding2x2.html#fig:figRTFIQ">9.3</a>, which shows that response times decrease with increasing IQ, as suggested by the <code>brms</code> model. However, the heights of the two  regression lines do not differ from each other, consistent with the observation in the <code>brms</code> model that the effect of factor <span class="math inline">\(F\)</span> did not seem to differ from zero. That is, factor <span class="math inline">\(F\)</span> in the <code>brms</code> model estimates the difference in height of the regression line between both groups.
That the height does not differ and the effect of <span class="math inline">\(F\)</span> is estimated to be close to zero suggests that in fact group <span class="math inline">\(F2\)</span> showed faster response times not because of their additional training program. Instead, they had faster response times simply because their IQ was by chance higher on average compared to the control group <span class="math inline">\(F1\)</span>. This analysis is the Bayesian equivalence of the frequentist  “analysis of covariance” (ANCOVA), where it’s possible to estimate a group difference after “controlling for” the influence of a covariate.</p>
<p>We can also see in Figure <a href="ch-coding2x2.html#fig:figRTFIQ">9.3</a> that the two regression lines for the two groups are exactly parallel to each other. That is, the influence of IQ on response times seems to be exactly the same in both groups. This is actually an assumption in the ANCOVA analysis that needs to be checked in the data. That is, if we want to estimate the difference between groups after controlling for a covariate (here IQ), we have to investigate whether the influence of the covariate is the same in both groups. We can estimate this by including an  interaction term between the factor and the covariate in the <code>brms</code> model:</p>
<div class="sourceCode" id="cb566"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb566-1"><a href="ch-coding2x2.html#cb566-1" aria-hidden="true"></a>fit_RT_FxIQ &lt;-</span>
<span id="cb566-2"><a href="ch-coding2x2.html#cb566-2" aria-hidden="true"></a><span class="st">  </span><span class="kw">brm</span>(RT <span class="op">~</span><span class="st"> </span>F <span class="op">*</span><span class="st"> </span>c_IQ,</span>
<span id="cb566-3"><a href="ch-coding2x2.html#cb566-3" aria-hidden="true"></a>      <span class="dt">data =</span> df_contrasts5,</span>
<span id="cb566-4"><a href="ch-coding2x2.html#cb566-4" aria-hidden="true"></a>      <span class="dt">family =</span> <span class="kw">gaussian</span>(),</span>
<span id="cb566-5"><a href="ch-coding2x2.html#cb566-5" aria-hidden="true"></a>      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">200</span>, <span class="dv">50</span>), <span class="dt">class =</span> Intercept),</span>
<span id="cb566-6"><a href="ch-coding2x2.html#cb566-6" aria-hidden="true"></a>                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">50</span>), <span class="dt">class =</span> sigma),</span>
<span id="cb566-7"><a href="ch-coding2x2.html#cb566-7" aria-hidden="true"></a>                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">50</span>), <span class="dt">class =</span> b)))</span></code></pre></div>
<div class="sourceCode" id="cb567"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb567-1"><a href="ch-coding2x2.html#cb567-1" aria-hidden="true"></a><span class="kw">fixef</span>(fit_RT_FxIQ)</span></code></pre></div>
<pre><code>##           Estimate Est.Error   Q2.5  Q97.5
## Intercept   212.29      7.05 198.54 225.91
## F1            6.57     13.15 -18.76  32.66
## c_IQ         -1.06      0.32  -1.67  -0.43
## F1:c_IQ       0.00      0.68  -1.30   1.34</code></pre>
<p>The estimate for the interaction (the term <code>F1:c_IQ</code>) is very small here (close to <span class="math inline">\(0\)</span>) and the 95% credible intervals clearly overlap with zero, showing that the two regression lines are estimated to be very similar, or parallel, to each other. If this is the case, then it is possible to correct for IQ when estimating the group difference. (From the perspective of causal inference, one might need additional requirements to draw strong conclusions here, such as measuring the covariate before the dependent variable or theoretical plausibility.)</p>
</div>
<div id="estimating-differences-in-slopes" class="section level3 hasAnchor" number="9.2.2">
<h3><span class="header-section-number">9.2.2</span> Estimating differences in slopes<a href="ch-coding2x2.html#estimating-differences-in-slopes" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We now take a look at a different data set.</p>
<div class="sourceCode" id="cb569"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb569-1"><a href="ch-coding2x2.html#cb569-1" aria-hidden="true"></a><span class="kw">data</span>(<span class="st">&quot;df_contrasts6&quot;</span>)</span>
<span id="cb569-2"><a href="ch-coding2x2.html#cb569-2" aria-hidden="true"></a><span class="kw">levels</span>(df_contrasts6<span class="op">$</span>F) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;simple&quot;</span>, <span class="st">&quot;complex&quot;</span>)</span></code></pre></div>
<p>This again contains data from response times (RT) in two groups. Let’s assume the two groups have performed two different response time tasks, where one simple RT task doesn’t rely on much cognitive processing (group “simple”), whereas the other task is more complex and depends on complex cognitive operations (group “complex”). We therefore expect that RTs in the simple task should be independent of IQ, whereas in the complex task, individuals with a high IQ should be faster in responding compared to individuals with low IQ. Thus, our primary hypothesis of interest states that the influence of IQ on RT differs between conditions. This means that we are interested in the difference between slopes. A slope in a linear regression assesses how strongly the dependent variable (here RT) changes with an increase of one unit on the covariate (here IQ), it thus assesses how “steep” the regression line is. Our hypothesis thus states that the  regression lines differ between groups.</p>
<div class="figure"><span style="display:block;" id="fig:figRTFxIQ"></span>
<img src="bookdown_files/figure-html/figRTFxIQ-1.svg" alt="Response times as a function of individual IQ for two groups performing a simple versus a complex task. Points indicate individual subjects' responses, and lines with error bands show the fitted linear regression lines." width="432" />
<p class="caption">
FIGURE 9.4: Response times as a function of individual IQ for two groups performing a simple versus a complex task. Points indicate individual subjects’ responses, and lines with error bands show the fitted linear regression lines.
</p>
</div>
<p>The results, displayed in Figure <a href="ch-coding2x2.html#fig:figRTFxIQ">9.4</a>, suggest that the data seem to support our hypothesis. For the subjects performing the complex task, response times seem to decrease with increasing IQ, whereas for subjects performing the simple task, response times seem to be independent of IQ. As stated before, our primary hypothesis relates to the difference in slopes. Statistically speaking, this is assessed in the  interaction between the factor and the covariate. Thus, we run a <code>brms</code> model where the interaction is included. Importantly, we first use scaled  sum contrasts for the group effect, and again center the  covariate IQ.</p>
<div class="sourceCode" id="cb570"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb570-1"><a href="ch-coding2x2.html#cb570-1" aria-hidden="true"></a><span class="kw">contrasts</span>(df_contrasts6<span class="op">$</span>F) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="op">-</span><span class="fl">0.5</span>, <span class="fl">+0.5</span>)</span>
<span id="cb570-2"><a href="ch-coding2x2.html#cb570-2" aria-hidden="true"></a>df_contrasts6<span class="op">$</span>c_IQ &lt;-<span class="st"> </span>df_contrasts6<span class="op">$</span>IQ <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(df_contrasts6<span class="op">$</span>IQ)</span>
<span id="cb570-3"><a href="ch-coding2x2.html#cb570-3" aria-hidden="true"></a>fit_RT_FxIQ2 &lt;-<span class="st"> </span><span class="kw">brm</span>(RT <span class="op">~</span><span class="st">  </span>F <span class="op">*</span><span class="st"> </span>c_IQ,</span>
<span id="cb570-4"><a href="ch-coding2x2.html#cb570-4" aria-hidden="true"></a>                    <span class="dt">data =</span> df_contrasts6,</span>
<span id="cb570-5"><a href="ch-coding2x2.html#cb570-5" aria-hidden="true"></a>                    <span class="dt">family =</span> <span class="kw">gaussian</span>(),</span>
<span id="cb570-6"><a href="ch-coding2x2.html#cb570-6" aria-hidden="true"></a>                    <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">200</span>, <span class="dv">50</span>), <span class="dt">class =</span> Intercept),</span>
<span id="cb570-7"><a href="ch-coding2x2.html#cb570-7" aria-hidden="true"></a>                              <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">50</span>), <span class="dt">class =</span> sigma),</span>
<span id="cb570-8"><a href="ch-coding2x2.html#cb570-8" aria-hidden="true"></a>                              <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">50</span>), <span class="dt">class =</span> b)))</span></code></pre></div>
<div class="sourceCode" id="cb571"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb571-1"><a href="ch-coding2x2.html#cb571-1" aria-hidden="true"></a><span class="kw">fixef</span>(fit_RT_FxIQ2)</span></code></pre></div>
<pre><code>##           Estimate Est.Error   Q2.5  Q97.5
## Intercept   209.92      4.82 200.37 219.40
## F1           19.23      9.51   0.52  38.31
## c_IQ         -0.80      0.33  -1.44  -0.17
## F1:c_IQ      -1.58      0.66  -2.88  -0.33</code></pre>
<p>We can see that the main effect of IQ (term <code>c_IQ</code>) is negative (<span class="math inline">\(-0.8\)</span>) with 95% credible intervals <span class="math inline">\(-1.5\)</span> to <span class="math inline">\(-0.2\)</span>, suggesting that overall response times decrease with increasing IQ. This is qualified by the interaction term, which is estimated to be negative (<span class="math inline">\(-1.6\)</span>), with 95% credible intervals <span class="math inline">\(-2.9\)</span> to <span class="math inline">\(-0.3\)</span>. This suggests that the slope in the complex group (which was coded as <span class="math inline">\(+0.5\)</span> in the scaled sum contrast) is more negative than the slope in the simple group (which was coded as <span class="math inline">\(-0.5\)</span> in the scaled sum contrast). Thus, the interaction assesses the difference between slopes.</p>
<p>We can also run a model, where the  nested slopes are estimated, i.e., the slope of IQ in the simple group and the slope of IQ in the complex group. This can be implemented by using the nested coding that we learned about in the previous section:</p>
<div class="sourceCode" id="cb573"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb573-1"><a href="ch-coding2x2.html#cb573-1" aria-hidden="true"></a>fit_RT_FnIQ2 &lt;-</span>
<span id="cb573-2"><a href="ch-coding2x2.html#cb573-2" aria-hidden="true"></a><span class="st">  </span><span class="kw">brm</span>(RT <span class="op">~</span><span class="st"> </span>F <span class="op">/</span><span class="st"> </span>c_IQ,</span>
<span id="cb573-3"><a href="ch-coding2x2.html#cb573-3" aria-hidden="true"></a>      <span class="dt">data =</span> df_contrasts6,</span>
<span id="cb573-4"><a href="ch-coding2x2.html#cb573-4" aria-hidden="true"></a>      <span class="dt">family =</span> <span class="kw">gaussian</span>(),</span>
<span id="cb573-5"><a href="ch-coding2x2.html#cb573-5" aria-hidden="true"></a>      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">200</span>, <span class="dv">50</span>), <span class="dt">class =</span> Intercept),</span>
<span id="cb573-6"><a href="ch-coding2x2.html#cb573-6" aria-hidden="true"></a>                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">50</span>), <span class="dt">class =</span> sigma),</span>
<span id="cb573-7"><a href="ch-coding2x2.html#cb573-7" aria-hidden="true"></a>                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">50</span>), <span class="dt">class =</span> b)))</span></code></pre></div>
<div class="sourceCode" id="cb574"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb574-1"><a href="ch-coding2x2.html#cb574-1" aria-hidden="true"></a><span class="kw">fixef</span>(fit_RT_FnIQ2)</span></code></pre></div>
<pre><code>##               Estimate Est.Error   Q2.5  Q97.5
## Intercept       209.85      4.86 200.59 219.35
## F1               19.21      9.40   1.06  37.65
## Fsimple:c_IQ      0.01      0.47  -0.92   0.95
## Fcomplex:c_IQ    -1.60      0.46  -2.51  -0.69</code></pre>
<p>Now we see that the slope of IQ in the simple group (<code>Fsimple:c_IQ</code>) is estimated to be <span class="math inline">\(0\)</span>, with credible intervals clearly including zero. By contrast, the slope in the complex group (<code>Fcomplex:c_IQ</code>) is estimated as <span class="math inline">\(-1.6\)</span> (95% CrI = <span class="math inline">\([-2.5,-0.7]\)</span>). This is consistent with our hypothesis that high IQ speeds up response times for the complex but not for the simple task. (To obtain evidence for this effect, we need Bayes factors, see chapter <a href="ch-bf.html#ch-bf">15</a>.)
We can also see from the  nested analysis that the difference in slopes between conditions is <span class="math inline">\(-1.6 - 0.0 = -1.6\)</span>. This is exactly the value for the interaction term that we estimated in the previous model, demonstrating that  interaction terms assess the difference between slopes; i.e., they estimate in how far the regression lines in the two conditions are parallel, with an estimate of <span class="math inline">\(0\)</span> indicating perfectly parallel lines.</p>
<p>Notice that we can compute posterior samples for the nested slopes from the model with the interaction. That is, we can take the model that estimates main effects and the interaction, and compute posterior samples for the slope of IQ in the simple task and the slope of IQ in the complex task. First, we extract the posterior samples from the model.</p>
<div class="sourceCode" id="cb576"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb576-1"><a href="ch-coding2x2.html#cb576-1" aria-hidden="true"></a>df_postSamp_RT_FxIQ2 &lt;-<span class="st"> </span><span class="kw">as_draws_df</span>(fit_RT_FxIQ2)</span></code></pre></div>
<p>Then, we take a look at the contrast coefficients for the group factor:</p>
<div class="sourceCode" id="cb577"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb577-1"><a href="ch-coding2x2.html#cb577-1" aria-hidden="true"></a><span class="kw">contrasts</span>(df_contrasts6<span class="op">$</span>F)</span></code></pre></div>
<pre><code>##         [,1]
## simple  -0.5
## complex  0.5</code></pre>
<p>They show a value of <span class="math inline">\(-0.5\)</span> for the simple group. Thus, to compute the slope for the simple group we have to take the overall slope for <code>c_IQ</code> and subtract <span class="math inline">\(-0.5\)</span> times the estimate for the interaction:</p>
<div class="sourceCode" id="cb579"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb579-1"><a href="ch-coding2x2.html#cb579-1" aria-hidden="true"></a>df_postSamp_RT_FxIQ2 &lt;-<span class="st"> </span>df_postSamp_RT_FxIQ2 <span class="op">%&gt;%</span></span>
<span id="cb579-2"><a href="ch-coding2x2.html#cb579-2" aria-hidden="true"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">b_c_IQ_simple =</span> b_c_IQ <span class="op">-</span><span class="st"> </span><span class="fl">0.5</span> <span class="op">*</span><span class="st"> `</span><span class="dt">b_F1:c_IQ</span><span class="st">`</span>)</span></code></pre></div>
<p>Likewise, to estimate the slope for the complex group we have to take the overall slope for <code>c_IQ</code> and add <span class="math inline">\(+0.5\)</span> times the estimate for the interaction:</p>
<div class="sourceCode" id="cb580"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb580-1"><a href="ch-coding2x2.html#cb580-1" aria-hidden="true"></a>df_postSamp_RT_FxIQ2 &lt;-<span class="st"> </span>df_postSamp_RT_FxIQ2 <span class="op">%&gt;%</span></span>
<span id="cb580-2"><a href="ch-coding2x2.html#cb580-2" aria-hidden="true"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">b_c_IQ_complex =</span> b_c_IQ <span class="op">+</span><span class="st"> </span><span class="fl">0.5</span> <span class="op">*</span><span class="st"> `</span><span class="dt">b_F1:c_IQ</span><span class="st">`</span>)</span></code></pre></div>
<div class="sourceCode" id="cb581"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb581-1"><a href="ch-coding2x2.html#cb581-1" aria-hidden="true"></a><span class="kw">c</span>(<span class="dt">IQc.c_simple =</span> <span class="kw">mean</span>(df_postSamp_RT_FxIQ2<span class="op">$</span>b_c_IQ_simple),</span>
<span id="cb581-2"><a href="ch-coding2x2.html#cb581-2" aria-hidden="true"></a>  <span class="dt">IQc.c_complex =</span> <span class="kw">mean</span>(df_postSamp_RT_FxIQ2<span class="op">$</span>b_c_IQ_complex))</span></code></pre></div>
<pre><code>##  IQc.c_simple IQc.c_complex 
##      -0.00878      -1.59182</code></pre>
<p>The results show that the posterior means for the slope of <code>c_IQ</code> are <span class="math inline">\(0\)</span> and <span class="math inline">\(-1.6\)</span> for the simple and the complex groups, as we had found above in the nested analysis. This is the case because the data are sufficiently informative compared to the data. When the data are sparse or when working with Bayes factors, priors will have to be set carefully for each specific analysis.</p>
<p>In most situations one should always center  covariates before including them into a model. If covariates are not centered, then the effects (here the effect for the factor) cannot be interpreted as main effects any more.</p>
<p>One can also do analyses with  interactions between a  covariate and a factor, but by using different contrast codings. For example, if we use  treatment contrasts for the factor, then the main effect of <code>c_IQ</code> assesses not the average slope of <code>c_IQ</code> across conditions, but instead the  nested slope of <code>c_IQ</code> within the baseline group of the treatment contrast. The interaction still assesses the difference in slopes between groups. In a situation where there are more than two groups, when one estimates the interaction of contrasts with a covariate, then the contrasts define which slopes are compared with each other in the interaction terms. For example, when using sum contrasts in an example where the influence of IQ is measured on response times for nouns, verbs, and adjectives, then there are two interaction terms: these assess (1) whether the slope of IQ for nouns is different from the average slope across conditions, and (2) whether the slope of IQ for verbs is different from the average slope across conditions. If one uses repeated contrasts in a situation where the influence of IQ on response times is estimated for word frequency conditions “low”, “medium-low”, “medium-high”, and “high”, then there are three interaction terms (one for each contrast). The first interaction term estimates the difference in slopes between “low” and “medium-low” word frequencies, the second interaction term estimates the difference in slopes between “medium-low” and “medium-high” word frequencies, and the third interaction term estimates the difference in slopes between “medium-high” and “high” word frequency conditions. Thus, the logic of how contrasts specify certain comparisons between conditions extends directly to the situation where differences in slopes are estimated.</p>
</div>
</div>
<div id="sec-interactions-NLM" class="section level2 hasAnchor" number="9.3">
<h2><span class="header-section-number">9.3</span> Interactions in generalized linear models (with non-linear link functions) and non-linear models<a href="ch-coding2x2.html#sec-interactions-NLM" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Next, we look at  generalized linear models, where a linear predictor is passed through a non-linear  link function to predict the dependent variable. Examples for generalized linear models include  logistic regression models and models assuming a Poisson distribution. Even though a log-normal model is a linear model on a log-transformed dependent variable, the same techniques apply to this type of model since the logarithm transform is not linear. Here, we treat an example with a logistic model in a <span class="math inline">\(2 \times 2\)</span> factorial between-subject design. The logistic model has the following non-linear link function called the  logistic function: <span class="math inline">\(P(y=1 \mid \eta) = \frac{1}{1 + \exp(-\eta)}\)</span>, where <span class="math inline">\(\eta\)</span> is the latent linear predictor. For example, in our <span class="math inline">\(2 \times 2\)</span> factorial design with main effects A and B and their interaction, <span class="math inline">\(\eta\)</span> is computed as a linear combination of the intercept plus the main effects and their interaction: <span class="math inline">\(\eta = 1 + \beta_A x_A + \beta_B x_B + \beta_{A \times B} x_{A \times B}\)</span>.</p>
<p>Thus, there is a latent level of linear predictions (<span class="math inline">\(\eta\)</span>), which are then passed through a non-linear link function to predict the probability that the observed data is a success (<span class="math inline">\(P(y = 1)\)</span>). We will use this logistic model to analyze an example data set where the dependent variable is dichotomous, coded as either a <span class="math inline">\(1\)</span> (indicating success) or a <span class="math inline">\(0\)</span> (indicating failure).</p>
<p>We load a simulated data set where the dependent variable codes whether a subject performed a task successfully (<span class="math inline">\(pDV = 1\)</span>) or not (<span class="math inline">\(pDV = 0\)</span>). Moreover, the data set has two between-subject factors A and B. The means for each of the four conditions are shown in Table <a href="ch-coding2x2.html#tab:cTab7Means">9.3</a>.</p>
<div class="sourceCode" id="cb583"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb583-1"><a href="ch-coding2x2.html#cb583-1" aria-hidden="true"></a><span class="kw">data</span>(<span class="st">&quot;df_contrasts7&quot;</span>)</span></code></pre></div>
<table>
<caption><span id="tab:cTab7Means">TABLE 9.3: </span>Summary statistics per condition for the simulated data.</caption>
<thead>
<tr class="header">
<th align="left">Factor A</th>
<th align="left">Factor B</th>
<th align="left">N data</th>
<th align="left">Means</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">A1</td>
<td align="left">B1</td>
<td align="left"><span class="math inline">\(50\)</span></td>
<td align="left"><span class="math inline">\(0.2\)</span></td>
</tr>
<tr class="even">
<td align="left">A1</td>
<td align="left">B2</td>
<td align="left"><span class="math inline">\(50\)</span></td>
<td align="left"><span class="math inline">\(0.5\)</span></td>
</tr>
<tr class="odd">
<td align="left">A2</td>
<td align="left">B1</td>
<td align="left"><span class="math inline">\(50\)</span></td>
<td align="left"><span class="math inline">\(0.2\)</span></td>
</tr>
<tr class="even">
<td align="left">A2</td>
<td align="left">B2</td>
<td align="left"><span class="math inline">\(50\)</span></td>
<td align="left"><span class="math inline">\(0.8\)</span></td>
</tr>
</tbody>
</table>
<p>To analyze this data, we use scaled  sum contrasts, as we had done above for the  <span class="math inline">\(2 \times 2\)</span> design with response times as the dependent variable; this allows us to interpret the coefficients directly as  main effects. Next, we fit a <code>brms</code> model. The model specification is the same as the model with response times–with two differences: First, the  <code>family</code> argument is now specified as   <code>family = bernoulli(link = "logit")</code> to indicate the logistic model. We do not specify a prior for <code>sigma</code>, since there is no residual standard deviation in a logistic model.</p>
<div class="sourceCode" id="cb584"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb584-1"><a href="ch-coding2x2.html#cb584-1" aria-hidden="true"></a><span class="kw">contrasts</span>(df_contrasts7<span class="op">$</span>A) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="op">-</span><span class="fl">0.5</span>, <span class="fl">+0.5</span>)</span>
<span id="cb584-2"><a href="ch-coding2x2.html#cb584-2" aria-hidden="true"></a><span class="kw">contrasts</span>(df_contrasts7<span class="op">$</span>B) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="op">-</span><span class="fl">0.5</span>, <span class="fl">+0.5</span>)</span>
<span id="cb584-3"><a href="ch-coding2x2.html#cb584-3" aria-hidden="true"></a>fit_pDV_AB.sum &lt;-<span class="st"> </span><span class="kw">brm</span>(pDV <span class="op">~</span><span class="st"> </span>A <span class="op">*</span><span class="st"> </span>B,</span>
<span id="cb584-4"><a href="ch-coding2x2.html#cb584-4" aria-hidden="true"></a>                      <span class="dt">data =</span> df_contrasts7,</span>
<span id="cb584-5"><a href="ch-coding2x2.html#cb584-5" aria-hidden="true"></a>                      <span class="dt">family =</span> <span class="kw">bernoulli</span>(<span class="dt">link =</span> <span class="st">&quot;logit&quot;</span>),</span>
<span id="cb584-6"><a href="ch-coding2x2.html#cb584-6" aria-hidden="true"></a>                      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">3</span>), <span class="dt">class =</span> Intercept),</span>
<span id="cb584-7"><a href="ch-coding2x2.html#cb584-7" aria-hidden="true"></a>                                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">3</span>), <span class="dt">class =</span> b)))</span></code></pre></div>
<div class="sourceCode" id="cb585"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb585-1"><a href="ch-coding2x2.html#cb585-1" aria-hidden="true"></a><span class="kw">fixef</span>(fit_pDV_AB.sum)</span></code></pre></div>
<pre><code>##           Estimate Est.Error  Q2.5 Q97.5
## Intercept    -0.36      0.17 -0.70 -0.03
## A1            0.71      0.35  0.05  1.41
## B1            2.11      0.34  1.44  2.80
## A1:B1         1.35      0.67  0.07  2.65</code></pre>
<p>The results from this analysis show that the estimates for the two main effects (<span class="math inline">\(A1\)</span> and <span class="math inline">\(B1\)</span>) as well as the interaction (<span class="math inline">\(A1:B1\)</span>) are positive and the 95% credible intervals do not include zero. If we want to make a discovery claim, we would need to perform Bayes factor analyses to investigate the evidence that there is for each of the effects.</p>
<p>Next, we discuss how we can obtain  model predictions for each of the four experimental conditions for this generalized linear model. To obtain such predictions, we first take a look at the  contrast matrix. We simultaneously have contrasts for two main effects and one interaction:</p>
<p>We obtain the posterior samples for the estimates from the model:</p>
<div class="sourceCode" id="cb587"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb587-1"><a href="ch-coding2x2.html#cb587-1" aria-hidden="true"></a>df_postSamp_pDV &lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(fit_pDV_AB.sum)</span></code></pre></div>
<p>From these, we can compute the posterior samples for the linear predictions for each group. We see in the contrast matrix how we have to combine the posterior samples for the intercept, main effects, and interaction to obtain  latent linear predictions for each condition. The first condition (design cell <span class="math inline">\(A1\)</span>, <span class="math inline">\(B1\)</span>) has a weight of <span class="math inline">\(1\)</span> for the intercept, and then weights of <span class="math inline">\(-0.5\)</span> (for the main effect of <span class="math inline">\(A\)</span>), <span class="math inline">\(-0.5\)</span> (for the main effect of <span class="math inline">\(B\)</span>), and <span class="math inline">\(0.25\)</span> (for the interaction). The posterior samples for the other conditions are computed accordingly.</p>
<div class="sourceCode" id="cb588"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb588-1"><a href="ch-coding2x2.html#cb588-1" aria-hidden="true"></a>df_postSamp_pDV &lt;-<span class="st"> </span>df_postSamp_pDV <span class="op">%&gt;%</span></span>
<span id="cb588-2"><a href="ch-coding2x2.html#cb588-2" aria-hidden="true"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">A1_B1 =</span> b_Intercept <span class="op">-</span><span class="st"> </span><span class="fl">0.5</span> <span class="op">*</span><span class="st"> </span>b_A1 <span class="op">-</span><span class="st"> </span><span class="fl">0.5</span> <span class="op">*</span><span class="st"> </span>b_B1 <span class="op">+</span></span>
<span id="cb588-3"><a href="ch-coding2x2.html#cb588-3" aria-hidden="true"></a><span class="st">           </span><span class="fl">0.25</span> <span class="op">*</span><span class="st"> `</span><span class="dt">b_A1:B1</span><span class="st">`</span>,</span>
<span id="cb588-4"><a href="ch-coding2x2.html#cb588-4" aria-hidden="true"></a>         <span class="dt">A1_B2 =</span> b_Intercept <span class="op">-</span><span class="st"> </span><span class="fl">0.5</span> <span class="op">*</span><span class="st"> </span>b_A1 <span class="op">+</span><span class="st"> </span><span class="fl">0.5</span> <span class="op">*</span><span class="st"> </span>b_B1 <span class="op">-</span></span>
<span id="cb588-5"><a href="ch-coding2x2.html#cb588-5" aria-hidden="true"></a><span class="st">           </span><span class="fl">0.25</span> <span class="op">*</span><span class="st"> `</span><span class="dt">b_A1:B1</span><span class="st">`</span>,</span>
<span id="cb588-6"><a href="ch-coding2x2.html#cb588-6" aria-hidden="true"></a>         <span class="dt">A2_B1 =</span> b_Intercept <span class="op">+</span><span class="st"> </span><span class="fl">0.5</span> <span class="op">*</span><span class="st"> </span>b_A1 <span class="op">-</span><span class="st"> </span><span class="fl">0.5</span> <span class="op">*</span><span class="st"> </span>b_B1 <span class="op">-</span></span>
<span id="cb588-7"><a href="ch-coding2x2.html#cb588-7" aria-hidden="true"></a><span class="st">           </span><span class="fl">0.25</span> <span class="op">*</span><span class="st"> `</span><span class="dt">b_A1:B1</span><span class="st">`</span>,</span>
<span id="cb588-8"><a href="ch-coding2x2.html#cb588-8" aria-hidden="true"></a>         <span class="dt">A2_B2 =</span> b_Intercept <span class="op">+</span><span class="st"> </span><span class="fl">0.5</span> <span class="op">*</span><span class="st"> </span>b_A1 <span class="op">+</span><span class="st"> </span><span class="fl">0.5</span> <span class="op">*</span><span class="st"> </span>b_B1 <span class="op">+</span></span>
<span id="cb588-9"><a href="ch-coding2x2.html#cb588-9" aria-hidden="true"></a><span class="st">           </span><span class="fl">0.25</span> <span class="op">*</span><span class="st"> `</span><span class="dt">b_A1:B1</span><span class="st">`</span>)</span></code></pre></div>
<p>Now, we have computed posterior samples for estimates of the latent linear predictor <span class="math inline">\(\eta\)</span> for each experimental condition. We can look at the posterior means:</p>
<div class="sourceCode" id="cb589"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb589-1"><a href="ch-coding2x2.html#cb589-1" aria-hidden="true"></a>df_postSamp_pDV <span class="op">%&gt;%</span></span>
<span id="cb589-2"><a href="ch-coding2x2.html#cb589-2" aria-hidden="true"></a><span class="st">  </span><span class="kw">select</span>(A1_B1, A1_B2, A2_B1, A2_B2) <span class="op">%&gt;%</span></span>
<span id="cb589-3"><a href="ch-coding2x2.html#cb589-3" aria-hidden="true"></a><span class="st">  </span><span class="kw">colMeans</span>()</span></code></pre></div>
<pre><code>##    A1_B1    A1_B2    A2_B1    A2_B2 
## -1.42951  0.00225 -1.38931  1.38938</code></pre>
<p>This shows that these values are not on the probability scale. Instead, they are on the  (log-odds) scale of the latent linear predictor <span class="math inline">\(\eta\)</span>. For presentation and interpretation of the results, it might be much more informative to look at the condition means in terms of the probabilities of success in each of the four conditions. Given that we have the linear predictions for each condition, this can be easily computed by sending all posterior samples for the linear predictions through the link function. Applying the  logistic function  (<code>plogis()</code> in R) transforms the linear predictors to the  probability scale:<a href="#fn33" class="footnote-ref" id="fnref33"><sup>33</sup></a></p>
<div class="sourceCode" id="cb591"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb591-1"><a href="ch-coding2x2.html#cb591-1" aria-hidden="true"></a>df_postSamp_pDV &lt;-<span class="st"> </span>df_postSamp_pDV <span class="op">%&gt;%</span></span>
<span id="cb591-2"><a href="ch-coding2x2.html#cb591-2" aria-hidden="true"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">p_A1_B1 =</span> <span class="kw">plogis</span>(A1_B1),</span>
<span id="cb591-3"><a href="ch-coding2x2.html#cb591-3" aria-hidden="true"></a>         <span class="dt">p_A1_B2 =</span> <span class="kw">plogis</span>(A1_B2),</span>
<span id="cb591-4"><a href="ch-coding2x2.html#cb591-4" aria-hidden="true"></a>         <span class="dt">p_A2_B1 =</span> <span class="kw">plogis</span>(A2_B1),</span>
<span id="cb591-5"><a href="ch-coding2x2.html#cb591-5" aria-hidden="true"></a>         <span class="dt">p_A2_B2 =</span> <span class="kw">plogis</span>(A2_B2))</span></code></pre></div>
<p>Now, we have posterior samples for each condition on the probability scale. We can take a look at the posterior means, and see that these closely correspond to the probabilities in the data that we have seen above in Table <a href="ch-coding2x2.html#tab:cTab7Means">9.3</a>.</p>
<div class="sourceCode" id="cb592"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb592-1"><a href="ch-coding2x2.html#cb592-1" aria-hidden="true"></a>df_postSamp_pDV <span class="op">%&gt;%</span></span>
<span id="cb592-2"><a href="ch-coding2x2.html#cb592-2" aria-hidden="true"></a><span class="st">  </span><span class="kw">select</span>(p_A1_B1, p_A1_B2, p_A2_B1, p_A2_B2) <span class="op">%&gt;%</span></span>
<span id="cb592-3"><a href="ch-coding2x2.html#cb592-3" aria-hidden="true"></a><span class="st">  </span><span class="kw">colMeans</span>()</span></code></pre></div>
<pre><code>## p_A1_B1 p_A1_B2 p_A2_B1 p_A2_B2 
##   0.200   0.501   0.205   0.795</code></pre>
<p>Of course, the advantage is that we now have posterior samples for these conditions available, and can compute posterior 95% credible intervals (also see Figure <a href="ch-coding2x2.html#fig:figpDV">9.5</a>). Rather than do it manually, the function  <code>conditional_effects()</code> can do this for us. By default, all main effects and two-way interactions estimated in the model are shown (this can be changed by including, for example, <code>effects = "A:B"</code>).</p>
<div class="sourceCode" id="cb594"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb594-1"><a href="ch-coding2x2.html#cb594-1" aria-hidden="true"></a><span class="kw">conditional_effects</span>(fit_pDV_AB.sum, <span class="dt">robust =</span> <span class="ot">FALSE</span>)[]</span></code></pre></div>
<pre><code>## $A
##    A   pDV  B cond__ effect1__ estimate__   se__ lower__ upper__
## 1 A1 0.425 B1      1        A1      0.200 0.0579  0.0971   0.322
## 2 A2 0.425 B1      1        A2      0.205 0.0565  0.1081   0.327
## 
## $B
##    B   pDV  A cond__ effect1__ estimate__   se__ lower__ upper__
## 1 B1 0.425 A1      1        B1      0.200 0.0579  0.0971   0.322
## 2 B2 0.425 A1      1        B2      0.501 0.0684  0.3625   0.633
## 
## $`A:B`
##    A  B   pDV cond__ effect1__ effect2__ estimate__   se__ lower__
## 1 A1 B1 0.425      1        A1        B1      0.200 0.0579  0.0971
## 2 A1 B2 0.425      1        A1        B2      0.501 0.0684  0.3625
## 3 A2 B1 0.425      1        A2        B1      0.205 0.0565  0.1081
## 4 A2 B2 0.425      1        A2        B2      0.795 0.0563  0.6753
##   upper__
## 1   0.322
## 2   0.633
## 3   0.327
## 4   0.894</code></pre>
<p>We plot the two-way  interaction using <code>brms</code> embedding the <code>conditional_effects()</code> call in <code>plot(.)[[1]]</code>. This allows us to select the first (and here the only) <code>ggplot2</code> element and to customize it.</p>

<div class="sourceCode" id="cb596"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb596-1"><a href="ch-coding2x2.html#cb596-1" aria-hidden="true"></a><span class="kw">plot</span>(<span class="kw">conditional_effects</span>(fit_pDV_AB.sum,</span>
<span id="cb596-2"><a href="ch-coding2x2.html#cb596-2" aria-hidden="true"></a>                         <span class="dt">effects =</span> <span class="st">&quot;A:B&quot;</span>,</span>
<span id="cb596-3"><a href="ch-coding2x2.html#cb596-3" aria-hidden="true"></a>                         <span class="dt">robust =</span> <span class="ot">FALSE</span>),</span>
<span id="cb596-4"><a href="ch-coding2x2.html#cb596-4" aria-hidden="true"></a>     <span class="dt">plot =</span> <span class="ot">FALSE</span>)[[<span class="dv">1</span>]] <span class="op">+</span></span>
<span id="cb596-5"><a href="ch-coding2x2.html#cb596-5" aria-hidden="true"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">y =</span> <span class="st">&quot;Success probability&quot;</span>)</span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:figpDV"></span>
<img src="bookdown_files/figure-html/figpDV-1.svg" alt="Means and 95 percent posterior credible intervals for a simulated data set of successful task performance in a \(2 \times 2\) design." width="336" />
<p class="caption">
FIGURE 9.5: Means and 95 percent posterior credible intervals for a simulated data set of successful task performance in a <span class="math inline">\(2 \times 2\)</span> design.
</p>
</div>
<p>As a final remark, we warn that certain types of interactions might be present at the probability scale, but not at the logit scale (or other way round), which can happen for any non-linear transformation <span class="citation">(see Loftus <a href="#ref-loftus1978interpretation" role="doc-biblioref">1978</a>; Wagenmakers et al. <a href="#ref-wagenmakers2012interpretation" role="doc-biblioref">2012</a>)</span>.</p>
</div>
<div id="summary-7" class="section level2 hasAnchor" number="9.4">
<h2><span class="header-section-number">9.4</span> Summary<a href="ch-coding2x2.html#summary-7" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>To summarize, we have seen interesting results for contrasts in the context of <span class="math inline">\(2 \times 2\)</span> designs, where depending on the contrast coding, the factors estimated nested effects (treatment contrasts) or main effects (sum contrasts). We also saw that it is possible to code contrasts for a <span class="math inline">\(2 \times 2\)</span> design, by creating one factor comprising all design cells, and by specifying all effects of interest in one large contrast matrix. In designs with one factor and one covariate it is possible to control group-differences for differences in the covariate (ANCOVA), or to estimate in how far regression slopes are parallel in different experimental conditions. Last, in generalized linear models with non-linear link functions it is possible to obtain posterior samples not only on the latent scale of linear predictors, but also on the scale of the response.</p>
</div>
<div id="further-reading-6" class="section level2 hasAnchor" number="9.5">
<h2><span class="header-section-number">9.5</span> Further reading<a href="ch-coding2x2.html#further-reading-6" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Analysis of variance is discussed in detail in <span class="citation">Maxwell, Delaney, and Kelley (<a href="#ref-dead" role="doc-biblioref">2017</a>)</span>. A practical book on ANOVA using R is <span class="citation">Faraway (<a href="#ref-faraway2002practical" role="doc-biblioref">2002</a>)</span>.</p>
</div>
<div id="sec-Contrasts2x2exercises" class="section level2 hasAnchor" number="9.6">
<h2><span class="header-section-number">9.6</span> Exercises<a href="ch-coding2x2.html#sec-Contrasts2x2exercises" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="exercise">
<p><span id="exr:ContrastsPersianANOVA" class="exercise"><strong>Exercise 9.1  </strong></span>ANOVA coding for a four-condition design.</p>
</div>
<p>Load the following data. These data are from Experiment 1 in a set of reading studies on Persian <span class="citation">(Safavi, Husain, and Vasishth <a href="#ref-SafaviEtAlFrontiers2016" role="doc-biblioref">2016</a>)</span>; we encountered these data in the preceding chapter’s exercises.</p>
<div class="sourceCode" id="cb597"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb597-1"><a href="ch-coding2x2.html#cb597-1" aria-hidden="true"></a><span class="kw">library</span>(bcogsci)</span>
<span id="cb597-2"><a href="ch-coding2x2.html#cb597-2" aria-hidden="true"></a><span class="kw">data</span>(<span class="st">&quot;df_persianE1&quot;</span>)</span>
<span id="cb597-3"><a href="ch-coding2x2.html#cb597-3" aria-hidden="true"></a>dat1 &lt;-<span class="st"> </span>df_persianE1</span>
<span id="cb597-4"><a href="ch-coding2x2.html#cb597-4" aria-hidden="true"></a><span class="kw">head</span>(dat1)</span></code></pre></div>
<pre><code>##     subj item   rt distance   predability
## 60     4    6  568    short   predictable
## 94     4   17  517     long unpredictable
## 146    4   22  675    short   predictable
## 185    4    5  575     long unpredictable
## 215    4    3  581     long   predictable
## 285    4    7 1171     long   predictable</code></pre>
<p>The four conditions are:</p>
<ul>
<li>Distance=short and Predictability=unpredictable</li>
<li>Distance=short and Predictability=predictable</li>
<li>Distance=long and Predictability=unpredictable</li>
<li>Distance=long and Predictability=predictable</li>
</ul>
<p>For the data given above, define an ANOVA-style contrast coding, and compute main effects and interactions. Check with <code>hypr</code> what the estimated comparisons are with an ANOVA coding.</p>
<div class="exercise">
<p><span id="exr:Contrasts2x2x2Dillon2013" class="exercise"><strong>Exercise 9.2  </strong></span>ANOVA and nested comparisons in a <span class="math inline">\(2\times 2\times 2\)</span> design</p>
</div>
<p>Load the following data set. This is a <span class="math inline">\(2\times 2\times 2\)</span> design from <span class="citation">Jäger et al. (<a href="#ref-JaegerMertzenVanDykeVasishth2019" role="doc-biblioref">2020</a>)</span>, with the factors Grammaticality (grammatical vs. ungrammatical), Dependency (Agreement vs. Reflexives), and Interference (Interference vs. no interference). The experiment is a replication attempt of Experiment 1 reported in <span class="citation">Dillon et al. (<a href="#ref-Dillon-EtAl-2013" role="doc-biblioref">2013</a>)</span>.</p>
<div class="sourceCode" id="cb599"><pre class="sourceCode r fold-show"><code class="sourceCode r"><span id="cb599-1"><a href="ch-coding2x2.html#cb599-1" aria-hidden="true"></a><span class="kw">library</span>(bcogsci)</span>
<span id="cb599-2"><a href="ch-coding2x2.html#cb599-2" aria-hidden="true"></a><span class="kw">data</span>(<span class="st">&quot;df_dillonrep&quot;</span>)</span></code></pre></div>
<ul>
<li>The grammatical conditions are a,b,e,f. The rest of the conditions are ungrammatical.</li>
<li>The agreement conditions are a,b,c,d. The other conditions are reflexives.</li>
<li>The interference conditions are a,d,e,h, and the others are the no-interference conditions.</li>
</ul>
<p>The dependent measure of interest is TFT (total fixation time, in milliseconds).</p>
<p>Using a linear model, do a main effects and interactions ANOVA contrast coding, and obtain an estimate of the main effects of Grammaticality, Dependency, and Interference, and all interactions. You may find it easier to code the contrasts coding the main effects as +1, -1, using <code>ifelse()</code> in R to code vectors corresponding to each main effect. This will make the specification of the interactions easy.</p>
<p>The researchers had a further research hypothesis: in ungrammatical sentences only, agreement would show an interference effect but reflexives would not. In grammatical sentences, both agreement and reflexives are expected to show interference effects. This kind of research question can be answered with nested contrast coding.</p>
<p>To carry out the relevant nested contrasts, define contrasts that estimate the effects of</p>
<ul>
<li>grammaticality</li>
<li>dependency type</li>
<li>the interaction between grammaticality and dependency type</li>
<li>reflexives interference within grammatical conditions</li>
<li>agreement interference within grammatical conditions</li>
<li>reflexives interference within ungrammatical conditions</li>
<li>agreement interference within ungrammatical conditions</li>
</ul>
<p>Do the estimates match expectations? Check this by computing the condition means and checking that the estimates from the models match the relevant differences between conditions or clusters of conditions.</p>

</div>
</div>



<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references hanging-indent">
<div id="ref-Dillon-EtAl-2013">
<p>Dillon, Brian W., Alan Mishler, Shayne Sloggett, and Colin Phillips. 2013. “Contrasting Intrusion Profiles for Agreement and Anaphora: Experimental and Modeling Evidence.” <em>Journal of Memory and Language</em> 69 (2): 85–103. <a href="https://doi.org/https://doi.org/10.1016/j.jml.2013.04.003">https://doi.org/https://doi.org/10.1016/j.jml.2013.04.003</a>.</p>
</div>
<div id="ref-faraway2002practical">
<p>Faraway, Julian James. 2002. <em>Practical Regression and ANOVA using R</em>. Vol. 168. Citeseer.</p>
</div>
<div id="ref-JaegerMertzenVanDykeVasishth2019">
<p>Jäger, Lena A., Daniela Mertzen, Julie A. Van Dyke, and Shravan Vasishth. 2020. “Interference Patterns in Subject-Verb Agreement and Reflexives Revisited: A Large-Sample Study.” <em>Journal of Memory and Language</em> 111. <a href="https://doi.org/https://doi.org/10.1016/j.jml.2019.104063">https://doi.org/https://doi.org/10.1016/j.jml.2019.104063</a>.</p>
</div>
<div id="ref-loftus1978interpretation">
<p>Loftus, Geoffrey R. 1978. “On Interpretation of Interactions.” <em>Memory &amp; Cognition</em> 6 (3): 312–19.</p>
</div>
<div id="ref-dead">
<p>Maxwell, Scott E, Harold D Delaney, and Ken Kelley. 2017. <em>Designing Experiments and Analyzing Data: A Model Comparison Perspective</em>. New York, NY: Routledge.</p>
</div>
<div id="ref-SafaviEtAlFrontiers2016">
<p>Safavi, Molood Sadat, Samar Husain, and Shravan Vasishth. 2016. “Dependency Resolution Difficulty Increases with Distance in Persian Separable Complex Predicates: Implications for Expectation and Memory-Based Accounts.” <em>Frontiers in Psychology</em> 7 (403). <a href="https://doi.org/10.3389/fpsyg.2016.00403">https://doi.org/10.3389/fpsyg.2016.00403</a>.</p>
</div>
<div id="ref-schadHowCapitalizePriori2020">
<p>Schad, Daniel J., Shravan Vasishth, Sven Hohenstein, and Reinhold Kliegl. 2019. “How to Capitalize on a Priori Contrasts in Linear (Mixed) Models: A Tutorial.” <em>Journal of Memory and Language</em> 110. <a href="https://doi.org/10.1016/j.jml.2019.104038">https://doi.org/10.1016/j.jml.2019.104038</a>.</p> 2020. “How to Capitalize on a Priori Contrasts in Linear (Mixed) Models: A Tutorial.” <em>Journal of Memory and Language</em> 110 (February): 104038. <a href="https://doi.org/10/gf9tjp">https://doi.org/10/gf9tjp</a>.</p>
</div>
<div id="ref-wagenmakers2012interpretation">
<p>Wagenmakers, Eric-Jan, Angelos-Miltiadis Krypotos, Amy H Criss, and Geoffrey Iverson. 2012. “On the Interpretation of Removable Interactions: A Survey of the Field 33 Years After Loftus.” <em>Memory &amp; Cognition</em> 40: 145–60.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="33">
<li id="fn33"><p>The same (with lower precision) can be achieved using <code>1/(1+exp(-.))</code>.<a href="ch-coding2x2.html#fnref33" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="ch-contr.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="ch-introstan.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/clipboard.min.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script src="libs/gitbook/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "none"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
